import json
import hashlib
import sqlite3
from pathlib import Path
from datetime import datetime
from typing import Dict, Set

class CacheManager:
    def __init__(self, cache_dir: Path):
        self.cache_dir = cache_dir
        self.cache_dir.mkdir(exist_ok=True)
        self.processed_files_cache = self.cache_dir / "processed_files.json"

    def get_file_hash(self, filepath: str) -> str:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ö–µ—à —Ñ–∞–π–ª–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
        try:
            with open(filepath, 'rb') as f:
                content = f.read()
                return hashlib.md5(content).hexdigest()
        except Exception:
            return ""

    def save_processed_files_cache(self, processed_files: Dict):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–µ—à –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        try:
            with open(self.processed_files_cache, 'w', encoding='utf-8') as f:
                json.dump(processed_files, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–µ—à–∞: {e}")

    def load_processed_files_cache(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–µ—à –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        try:
            if self.processed_files_cache.exists():
                with open(self.processed_files_cache, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–µ—à–∞: {e}")
        return {}

    def load_already_processed_emails(self) -> Set[str]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ email –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
        """
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–µ—à (—Ö–µ—à–∏) ‚≠ê –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø
        optimized_cache = self.cache_dir / "processing_cache_optimized.db"
        if optimized_cache.exists():
            try:
                conn = sqlite3.connect(optimized_cache)
                cursor = conn.cursor()

                # –ü–æ–ª—É—á–∞–µ–º —Ö–µ—à–∏ –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
                cursor.execute('SELECT hash FROM email_hashes')
                processed_hashes = {row[0].hex() for row in cursor.fetchall()}

                conn.close()

                print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(processed_hashes):,} —Ö–µ—à–µ–π –∏–∑ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–µ—à–∞")
                print(f"   üíæ –≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏: 95% | –ë–∞–∑–∞: {optimized_cache.name}")
                return processed_hashes

            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–µ—à–∞: {e}")

        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: SQLite –∫–µ—à —Å –ø–æ–ª–Ω—ã–º–∏ email
        sqlite_cache_paths = [
            self.cache_dir / "processing_cache_final.db",
            self.cache_dir / "processing_cache.db"
        ]

        for sqlite_cache_path in sqlite_cache_paths:
            if sqlite_cache_path.exists():
                try:
                    conn = sqlite3.connect(sqlite_cache_path)
                    cursor = conn.cursor()

                    cursor.execute('SELECT DISTINCT email_normalized FROM processed_emails')
                    processed_emails = {row[0] for row in cursor.fetchall()}

                    conn.close()

                    print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(processed_emails):,} email –∏–∑ SQLite –∫–µ—à–∞")
                    print(f"   –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {sqlite_cache_path.name}")
                    print(f"   üí° –°–æ–≤–µ—Ç: –ó–∞–ø—É—Å—Ç–∏—Ç–µ migrate_to_optimized_cache.py –¥–ª—è 95% —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏")
                    return processed_emails

                except Exception as e:
                    print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑ {sqlite_cache_path.name}: {e}")
                    continue

        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3: JSON –∫–µ—à (legacy)
        processed_emails = set()
        cache_data = self.load_processed_files_cache()

        for filename, file_info in cache_data.items():
            if 'result_data' in file_info:
                result_data = file_info['result_data']
                results = result_data.get('results', {})
                for category in ['clean', 'blocked_email', 'blocked_domain', 'invalid']:
                    if category in results:
                        processed_emails.update(results[category])

        print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(processed_emails):,} email –∏–∑ JSON –∫–µ—à–∞ (legacy)")
        print("   üí° –°–æ–≤–µ—Ç: –ó–∞–ø—É—Å—Ç–∏—Ç–µ migrate_to_optimized_cache.py –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è")
        return processed_emails
