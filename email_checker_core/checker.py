import time
import json
from pathlib import Path
from datetime import datetime
from typing import Set, List, Tuple, Dict, Union
from collections import defaultdict

from .validation import EmailValidator
from .blocklist import BlocklistManager
from .config import ConfigManager
from .reporting import ReportGenerator
from .cache import CacheManager

# Import from root directory modules
import sys
sys.path.append(str(Path(__file__).parent.parent))
from email_metadata import EmailMetadataManager, EmailWithMetadata
from metadata_integration import MetadataIntegrator, EnrichedEmailResult

class EmailChecker:
    def __init__(self, base_dir: str = "."):
        self.base_dir = Path(base_dir)
        self.input_dir = self.base_dir / "input"
        self.blocklists_dir = self.base_dir / "blocklists"
        self.output_dir = self.base_dir / "output"
        self.cache_dir = self.base_dir / ".cache"
        self.cache_dir.mkdir(exist_ok=True)

        # Components
        self.validator = EmailValidator()
        self.blocklist_manager = BlocklistManager(self.blocklists_dir)
        self.config_manager = ConfigManager(self.base_dir)
        self.report_generator = ReportGenerator(self.output_dir)
        self.cache_manager = CacheManager(self.cache_dir)
        self.metadata_manager = EmailMetadataManager(str(self.base_dir))
        self.metadata_integrator = MetadataIntegrator(str(self.base_dir))

        # State
        self.stats = defaultdict(int)

    def load_emails_from_file(self, filepath: str) -> Set[str]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç email –∞–¥—Ä–µ—Å–∞ –∏–∑ txt —Ñ–∞–π–ª–∞ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π"""
        emails = set()
        invalid_count = 0
        normalized_count = 0

        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                for line in f:
                    email = line.strip().lower()
                    if not email:
                        continue

                    normalized = self.validator.normalize_email(email)

                    if normalized:
                        emails.add(normalized)
                        if normalized != email:
                            normalized_count += 1
                    else:
                        invalid_count += 1

            print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(emails)} –≤–∞–ª–∏–¥–Ω—ã—Ö email –∏–∑ {filepath}")
            if normalized_count > 0:
                print(f"  üîß –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ: {normalized_count} email")
            if invalid_count > 0:
                print(f"  ‚ö†Ô∏è  –û—Ç–∫–ª–æ–Ω–µ–Ω–æ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö: {invalid_count} email")
        except FileNotFoundError:
            print(f"‚ùå –§–∞–π–ª {filepath} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {filepath}: {e}")

        return emails

    def load_emails_with_metadata(self, filepath: str) -> List[EmailWithMetadata]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ (LVP, JSON, CSV, TXT)"""
        return self.metadata_manager.load_emails_from_file(filepath)

    def check_email_against_blocklists(self, emails: Set[str]) -> Dict[str, List[str]]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç email –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏: clean, blocked_email, blocked_domain
        """
        self.blocklist_manager.load_blocklists()

        result = {
            'clean': [],
            'blocked_email': [],
            'blocked_domain': [],
            'invalid': []
        }

        print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ email –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤...")
        start_time = time.time()

        for email in emails:
            if not self.validator.is_valid_email(email):
                result['invalid'].append(email)
                continue

            domain = self.validator.get_domain(email)

            if self.blocklist_manager.is_blocked_email(email):
                result['blocked_email'].append(email)
            elif self.blocklist_manager.is_blocked_domain(domain):
                result['blocked_domain'].append(email)
            else:
                result['clean'].append(email)

        check_time = time.time() - start_time

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.stats['total_checked'] = len(emails)
        self.stats['clean'] = len(result['clean'])
        self.stats['blocked_email'] = len(result['blocked_email'])
        self.stats['blocked_domain'] = len(result['blocked_domain'])
        self.stats['invalid'] = len(result['invalid'])
        self.stats['check_time'] = check_time

        return result

    def check_emails_with_enrichment(self, emails: List[str], list_name: str = "unknown") -> Dict[str, List[EnrichedEmailResult]]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç email –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–±–æ–≥–∞—â–µ–Ω–∏–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–∑ LVP —Ñ–∞–π–ª–æ–≤
        """
        print(f"\nüöÄ –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –° –ò–ù–¢–ï–ì–†–ê–¶–ò–ï–ô –ú–ï–¢–ê–î–ê–ù–ù–´–•")
        print(f"üìß –°–ø–∏—Å–æ–∫: {list_name}")
        print(f"üìä Email –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏: {len(emails)}")

        # –®–∞–≥ 1: –û–±–æ–≥–∞—â–∞–µ–º email –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–∑ LVP —Ñ–∞–π–ª–æ–≤
        enriched_emails = self.metadata_integrator.enrich_email_list(emails, list_name)

        # –®–∞–≥ 2: –ó–∞–≥—Ä—É–∂–∞–µ–º –±–ª–æ–∫-–ª–∏—Å—Ç—ã
        self.blocklist_manager.load_blocklists()

        # –®–∞–≥ 3: –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤
        result = {
            'clean': [],
            'blocked_email': [],
            'blocked_domain': [],
            'invalid': []
        }

        print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã—Ö email –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤...")
        start_time = time.time()

        for enriched_email in enriched_emails:
            email = enriched_email.email

            if not self.validator.is_valid_email(email):
                enriched_email.is_clean = False
                enriched_email.blocked_reason = "Invalid email format"
                result['invalid'].append(enriched_email)
                continue

            domain = self.validator.get_domain(email)

            if self.blocklist_manager.is_blocked_email(email):
                enriched_email.is_clean = False
                enriched_email.blocked_reason = "Email in blocklist"
                result['blocked_email'].append(enriched_email)
            elif self.blocklist_manager.is_blocked_domain(domain):
                enriched_email.is_clean = False
                enriched_email.blocked_reason = "Domain in blocklist"
                result['blocked_domain'].append(enriched_email)
            else:
                enriched_email.is_clean = True
                result['clean'].append(enriched_email)

        check_time = time.time() - start_time

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ–±–æ–≥–∞—â–µ–Ω–∏—é
        total_with_metadata = sum(1 for enriched in enriched_emails if enriched.has_metadata)
        enrichment_rate = (total_with_metadata / len(enriched_emails)) * 100 if enriched_emails else 0

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.stats['total_checked'] = len(emails)
        self.stats['clean'] = len(result['clean'])
        self.stats['blocked_email'] = len(result['blocked_email'])
        self.stats['blocked_domain'] = len(result['blocked_domain'])
        self.stats['invalid'] = len(result['invalid'])
        self.stats['check_time'] = check_time
        self.stats['emails_with_metadata'] = total_with_metadata
        self.stats['enrichment_rate'] = enrichment_rate

        print(f"‚ú® –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è {total_with_metadata} email ({enrichment_rate:.1f}%)")

        return result

    def check_emails_with_metadata(self, emails_with_metadata: List[EmailWithMetadata]) -> Dict[str, List[EmailWithMetadata]]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤
        """
        self.blocklist_manager.load_blocklists()

        result = {
            'clean': [],
            'blocked_email': [],
            'blocked_domain': [],
            'invalid': []
        }

        # –î–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –±–ª–æ–∫-–ª–∏—Å—Ç
        emails_to_block_from_status = set()

        print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤...")
        start_time = time.time()

        for email_obj in emails_with_metadata:
            email = email_obj.email

            if not self.validator.is_valid_email(email):
                result['invalid'].append(email_obj)
                continue

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ validation_status –∏–∑ LVP —Ñ–∞–π–ª–∞
            if email_obj.validation_status:
                status = email_obj.validation_status.lower()
                if status == 'invalid':
                    result['invalid'].append(email_obj)
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
                    emails_to_block_from_status.add(email)
                    continue
                elif status in ['temp', 'notsure', 'notchecked']:
                    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ –Ω–µ–Ω–∞–¥—ë–∂–Ω—ã–µ email –±–ª–æ–∫–∏—Ä—É–µ–º
                    result['blocked_email'].append(email_obj)
                    continue

            domain = self.validator.get_domain(email)

            if self.blocklist_manager.is_blocked_email(email):
                result['blocked_email'].append(email_obj)
            elif self.blocklist_manager.is_blocked_domain(domain):
                result['blocked_domain'].append(email_obj)
            else:
                result['clean'].append(email_obj)

        check_time = time.time() - start_time

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º Invalid email –≤ –±–ª–æ–∫-–ª–∏—Å—Ç
        if emails_to_block_from_status:
            self.blocklist_manager.save_blocked_emails_to_file(emails_to_block_from_status, reason="LVP status=Invalid")

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        total_emails = len(emails_with_metadata)
        self.stats['total_checked'] = total_emails
        self.stats['clean'] = len(result['clean'])
        self.stats['blocked_email'] = len(result['blocked_email'])
        self.stats['blocked_domain'] = len(result['blocked_domain'])
        self.stats['invalid'] = len(result['invalid'])
        self.stats['check_time'] = check_time

        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(result['clean'])} —á–∏—Å—Ç—ã—Ö email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏")

        return result

    def check_single_list(self, input_file: str):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫ email"""
        if not Path(input_file).exists():
            print(f"‚ùå –§–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return

        emails = self.load_emails_from_file(input_file)
        if not emails:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö email –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
            return

        # –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20'
        original_count = len(emails)
        emails, removed_count = self.clean_prefix_duplicates(emails)
        if removed_count > 0:
            print(f"üßπ –û—á–∏—â–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20' (–±—ã–ª–æ {original_count}, —Å—Ç–∞–ª–æ {len(emails)})")

        results = self.check_email_against_blocklists(emails)

        filename_base = Path(input_file).stem
        self.report_generator.save_results(filename_base, results)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –æ—Ç—á–µ—Ç–∞
        result_data = {
            'filename': filename_base,
            'stats': dict(self.stats),
            'results': results,
            'duplicates_removed': 0,
            'prefix_duplicates_removed': removed_count,
            'timestamp': datetime.now().isoformat()
        }
        self.report_generator.add_result(result_data)

    def check_single_list_with_metadata(self, input_file: str):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ (LVP, JSON, CSV, TXT)"""
        if not Path(input_file).exists():
            print(f"‚ùå –§–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return

        filename_base = Path(input_file).stem
        print(f"\nüìß –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏: {filename_base}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        emails_with_metadata = self.load_emails_with_metadata(input_file)

        if not emails_with_metadata:
            print(f"‚ùå –§–∞–π–ª {input_file} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö email")
            return

        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤
        results = self.check_emails_with_metadata(emails_with_metadata)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        self.save_results_with_metadata(filename_base, results)

        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.print_statistics()

        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å—Ç–∞—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        old_format_results = {
            'clean': [obj.email for obj in results['clean']],
            'blocked_email': [obj.email for obj in results['blocked_email']],
            'blocked_domain': [obj.email for obj in results['blocked_domain']],
            'invalid': [obj.email for obj in results['invalid']]
        }
        
        result_data = {
            'filename': filename_base,
            'stats': dict(self.stats),
            'results': old_format_results,
            'duplicates_removed': 0,
            'prefix_duplicates_removed': 0,
            'timestamp': datetime.now().isoformat()
        }
        self.report_generator.add_result(result_data)

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        filename = Path(input_file).name
        self.config_manager.update_list_processed_status(filename, processed=True)

        self.print_statistics()

    def check_single_list_enriched(self, input_file: str):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫ email —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–±–æ–≥–∞—â–µ–Ω–∏–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–∑ LVP —Ñ–∞–π–ª–æ–≤"""
        if not Path(input_file).exists():
            print(f"‚ùå –§–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return

        filename_base = Path(input_file).stem
        print(f"\nüìß –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –°–ü–ò–°–ö–ê: {filename_base}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º email –∏–∑ —Ñ–∞–π–ª–∞
        emails = self.load_emails_from_file(input_file)
        if not emails:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö email –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
            return

        # –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20'
        original_count = len(emails)
        emails, removed_count = self.clean_prefix_duplicates(emails)
        if removed_count > 0:
            print(f"üßπ –û—á–∏—â–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20' (–±—ã–ª–æ {original_count}, —Å—Ç–∞–ª–æ {len(emails)})")

        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —Å –æ–±–æ–≥–∞—â–µ–Ω–∏–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        enriched_results = self.check_emails_with_enrichment(list(emails), filename_base)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.save_enriched_results(filename_base, enriched_results)

        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.print_enriched_statistics()

        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å—Ç–∞—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        old_format_results = {
            'clean': [obj.email for obj in enriched_results['clean']],
            'blocked_email': [obj.email for obj in enriched_results['blocked_email']],
            'blocked_domain': [obj.email for obj in enriched_results['blocked_domain']],
            'invalid': [obj.email for obj in enriched_results['invalid']]
        }
        
        result_data = {
            'filename': filename_base,
            'stats': dict(self.stats),
            'results': old_format_results,
            'duplicates_removed': 0,
            'prefix_duplicates_removed': removed_count,
            'timestamp': datetime.now().isoformat()
        }
        self.report_generator.add_result(result_data)

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        filename = Path(input_file).name
        self.config_manager.update_list_processed_status(filename, processed=True)

    def save_results_with_metadata(self, filename_base: str, results: Dict[str, List[EmailWithMetadata]]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –≤ JSON –∏ CSV —Ñ–æ—Ä–º–∞—Ç–∞—Ö"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        for category, emails_objs in results.items():
            if not emails_objs:
                continue

            # SAFETY NET: –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –≤–Ω—É—Ç—Ä–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ email –∞–¥—Ä–µ—Å—É
            seen_emails = {}
            unique_emails_objs = []
            duplicates_found = 0

            for email_obj in emails_objs:
                email_key = email_obj.email.lower()
                if email_key not in seen_emails:
                    seen_emails[email_key] = True
                    unique_emails_objs.append(email_obj)
                else:
                    duplicates_found += 1

            if duplicates_found > 0:
                print(f"   üßπ –£–¥–∞–ª–µ–Ω–æ {duplicates_found} –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'")

            emails_objs = unique_emails_objs

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON —Å –ø–æ–ª–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
            output_json = self.output_dir / f"{filename_base}_{category}_metadata_{timestamp}.json"
            self.metadata_manager.save_emails_to_json(emails_objs, str(output_json))

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ CSV –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
            output_csv = self.output_dir / f"{filename_base}_{category}_metadata_{timestamp}.csv"
            self.metadata_manager.save_emails_to_csv(emails_objs, str(output_csv))

            # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ã—á–Ω—ã–π TXT —Ñ–∞–π–ª (—Ç–æ–ª—å–∫–æ email) –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            output_txt = self.output_dir / f"{filename_base}_{category}_{timestamp}.txt"
            try:
                with open(output_txt, 'w', encoding='utf-8') as f:
                    for email_obj in sorted(emails_objs, key=lambda x: x.email):
                        f.write(f"{email_obj.email}\n")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ {output_txt}: {e}")

            print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(emails_objs)} email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏:")
            print(f"  üìÑ JSON: {output_json.name}")
            print(f"  üìä CSV: {output_csv.name}")
            print(f"  üìù TXT: {output_txt.name}")

    def save_enriched_results(self, filename_base: str, results: Dict[str, List[EnrichedEmailResult]]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON –∏ CSV —Ñ–æ—Ä–º–∞—Ç–∞—Ö"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        for category, enriched_emails in results.items():
            if not enriched_emails:
                continue

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON
            output_json = self.output_dir / f"{filename_base}_{category}_enriched_{timestamp}.json"
            enriched_data = {
                "metadata": {
                    "generated_date": datetime.now().isoformat(),
                    "total_emails": len(enriched_emails),
                    "emails_with_metadata": sum(1 for e in enriched_emails if e.has_metadata),
                    "enrichment_rate": f"{sum(1 for e in enriched_emails if e.has_metadata)/len(enriched_emails)*100:.1f}%" if enriched_emails else "0%",
                    "category": category,
                    "source_file": filename_base
                },
                "emails": [
                    {
                        "email": e.email,
                        "is_clean": e.is_clean,
                        "blocked_reason": e.blocked_reason,
                        "has_metadata": e.has_metadata,
                        "metadata_source": e.metadata_source,
                        "source_url": e.source_url,
                        "page_title": e.page_title,
                        "company_name": e.company_name,
                        "phone": e.phone,
                        "country": e.country,
                        "city": e.city,
                        "address": e.address,
                        "category": e.category,
                        "domain": e.domain,
                        "keywords": e.keywords,
                        "meta_description": e.meta_description,
                        "meta_keywords": e.meta_keywords,
                        "validation_status": e.validation_status,
                        "validation_date": e.validation_date
                    } for e in enriched_emails
                ]
            }

            try:
                with open(output_json, 'w', encoding='utf-8') as f:
                    json.dump(enriched_data, f, ensure_ascii=False, indent=2)
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ {output_json}: {e}")

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ CSV –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
            output_csv = self.output_dir / f"{filename_base}_{category}_enriched_{timestamp}.csv"
            try:
                with open(output_csv, 'w', encoding='utf-8') as f:
                    f.write("email,is_clean,blocked_reason,has_metadata,metadata_source,source_url,page_title,company_name,phone,country,city,address,category,domain,keywords,validation_status\n")
                    for e in enriched_emails:
                        f.write(f'"{e.email}",{e.is_clean},"{e.blocked_reason or ""}",{e.has_metadata},"{e.metadata_source or ""}","{e.source_url or ""}","{e.page_title or ""}","{e.company_name or ""}","{e.phone or ""}","{e.country or ""}","{e.city or ""}","{e.address or ""}","{e.category or ""}","{e.domain or ""}","{e.keywords or ""}","{e.validation_status or ""}"\n')
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ {output_csv}: {e}")

            # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ã—á–Ω—ã–π TXT —Ñ–∞–π–ª (—Ç–æ–ª—å–∫–æ email) –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            output_txt = self.output_dir / f"{filename_base}_{category}_{timestamp}.txt"
            try:
                with open(output_txt, 'w', encoding='utf-8') as f:
                    for enriched_email in sorted(enriched_emails, key=lambda x: x.email):
                        f.write(f"{enriched_email.email}\n")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ {output_txt}: {e}")

            print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(enriched_emails)} –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã—Ö email:")
            print(f"  üìÑ JSON: {output_json.name}")
            print(f"  üìä CSV: {output_csv.name}")
            print(f"  üìù TXT: {output_txt.name}")

    def clean_prefix_duplicates(self, emails: Set[str]) -> Tuple[Set[str], int]:
        """
        –û—á–∏—â–∞–µ—Ç email —Å –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–º–∏ –ø—Ä–µ—Ñ–∏–∫—Å–∞–º–∏:
        1. –ï—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤–µ—Ä—Å–∏—è –ë–ï–ó –ø—Ä–µ—Ñ–∏–∫—Å–∞ - —É–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç –° –ø—Ä–µ—Ñ–∏–∫—Å–æ–º
        2. –ï—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –¢–û–õ–¨–ö–û –≤–µ—Ä—Å–∏—è –° –ø—Ä–µ—Ñ–∏–∫—Å–æ–º - –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –µ—ë (—É–±–∏—Ä–∞–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å)
        """
        cleaned_emails = set(emails)
        removed_count = 0
        normalized_count = 0
        removal_reasons = defaultdict(int)
        normalization_reasons = defaultdict(int)

        # –ù–∞—Ö–æ–¥–∏–º email —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –ø—Ä–µ—Ñ–∏–∫—Å–∞–º–∏
        prefix_emails = {}  # email -> (clean_version, prefix_type)

        for email in emails:
            if '@' not in email:
                continue

            try:
                local_part, domain = email.split('@', 1)
            except ValueError:
                continue

            original_local = local_part
            clean_local = local_part
            prefix_type = None

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å '//'
            if local_part.startswith('//'):
                clean_local = local_part[2:]
                prefix_type = '//'
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å '20'
            elif local_part.startswith('20') and len(local_part) > 2:
                clean_local = local_part[2:]
                prefix_type = '20'
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã
            elif local_part[0] in ['-', '.', '+', '_']:
                # –£–¥–∞–ª—è–µ–º –≤—Å–µ –Ω–∞—á–∞–ª—å–Ω—ã–µ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã
                clean_local = local_part.lstrip('-.+_')
                if clean_local != original_local:
                    prefix_type = f'invalid_start({original_local[0]})'

            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –ø—Ä–µ—Ñ–∏–∫—Å
            if prefix_type and clean_local and len(clean_local) > 0:
                clean_version = f"{clean_local}@{domain}"
                prefix_emails[email] = (clean_version, prefix_type)

        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º email —Å –ø—Ä–µ—Ñ–∏–∫—Å–∞–º–∏
        for prefix_email, (clean_version, prefix_type) in prefix_emails.items():
            # –ï—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —á–∏—Å—Ç–∞—è –≤–µ—Ä—Å–∏—è - —É–¥–∞–ª—è–µ–º –≤–µ—Ä—Å–∏—é —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º (–¥—É–±–ª–∏–∫–∞—Ç)
            if clean_version in emails and clean_version != prefix_email:
                cleaned_emails.discard(prefix_email)
                removed_count += 1
                removal_reasons[prefix_type] += 1
                print(f"   üóëÔ∏è  –£–¥–∞–ª–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '{prefix_type}': {prefix_email} (–µ—Å—Ç—å {clean_version})")
            # –ï—Å–ª–∏ –ù–ï —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —á–∏—Å—Ç–∞—è –≤–µ—Ä—Å–∏—è - –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º (–∑–∞–º–µ–Ω—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å–Ω—É—é –Ω–∞ —á–∏—Å—Ç—É—é)
            elif clean_version not in emails and prefix_email in cleaned_emails:
                cleaned_emails.discard(prefix_email)
                cleaned_emails.add(clean_version)
                normalized_count += 1
                normalization_reasons[prefix_type] += 1
                print(f"   üîß –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω –æ–¥–∏–Ω–æ—á–Ω—ã–π email —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '{prefix_type}': {prefix_email} ‚Üí {clean_version}")

        return cleaned_emails, removed_count + normalized_count

    def print_statistics(self):
        """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ –∫–æ–Ω—Å–æ–ª—å —Å —Ü–≤–µ—Ç–∞–º–∏"""
        print("\n" + "="*60)
        print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–û–í–ï–†–ö–ò")
        print("="*60)

        total = self.stats['total_checked']
        if total == 0:
            print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è")
            return

        clean = self.stats['clean']
        blocked_email = self.stats['blocked_email']
        blocked_domain = self.stats['blocked_domain']
        invalid = self.stats['invalid']

        print(f"üìß –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ:      {total:,}")
        print(f"‚úÖ –ß–∏—Å—Ç—ã–µ email:        {clean:,} ({clean/total*100:.1f}%)")
        print(f"üö´ –ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã email:  {blocked_email:,} ({blocked_email/total*100:.1f}%)")
        print(f"üö´ –ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã –¥–æ–º–µ–Ω:  {blocked_domain:,} ({blocked_domain/total*100:.1f}%)")
        if invalid > 0:
            print(f"‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ:          {invalid:,} ({invalid/total*100:.1f}%)")

        print(f"\n‚ö° –í—Ä–µ–º—è –ø—Ä–æ–≤–µ—Ä–∫–∏:       {self.stats['check_time']:.2f} —Å–µ–∫")
        if self.stats['check_time'] > 0:
            print(f"üöÄ –°–∫–æ—Ä–æ—Å—Ç—å:            {total/self.stats['check_time']:,.0f} email/—Å–µ–∫")

    def print_enriched_statistics(self):
        """–í—ã–≤–æ–¥–∏—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–∫–ª—é—á–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±–æ–≥–∞—â–µ–Ω–∏–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏"""
        total = self.stats['total_checked']
        clean = self.stats['clean']
        blocked_email = self.stats['blocked_email']
        blocked_domain = self.stats['blocked_domain']
        invalid = self.stats['invalid']
        check_time = self.stats['check_time']
        emails_with_metadata = self.stats.get('emails_with_metadata', 0)
        enrichment_rate = self.stats.get('enrichment_rate', 0)

        print(f"\n{'='*80}")
        print(f"üìä –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –° –ú–ï–¢–ê–î–ê–ù–ù–´–ú–ò")
        print(f"{'='*80}")
        print(f"üìß –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ:      {total:,}")
        print(f"‚úÖ –ß–∏—Å—Ç—ã–µ email:        {clean:,} ({clean/total*100:.1f}%)")
        print(f"üö´ –ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã email:  {blocked_email:,} ({blocked_email/total*100:.1f}%)")
        print(f"üö´ –ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã –¥–æ–º–µ–Ω:  {blocked_domain:,} ({blocked_domain/total*100:.1f}%)")
        print(f"‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ:          {invalid:,} ({invalid/total*100:.1f}%)")
        print(f"")
        print(f"‚ú® –û–ë–û–ì–ê–©–ï–ù–ò–ï –ú–ï–¢–ê–î–ê–ù–ù–´–ú–ò:")
        print(f"üìö Email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏:  {emails_with_metadata:,} ({enrichment_rate:.1f}%)")
        print(f"üìä –ò—Å—Ç–æ—á–Ω–∏–∫ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö:  LVP —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏ output/")
        print(f"")
        print(f"‚ö° –í—Ä–µ–º—è –ø—Ä–æ–≤–µ—Ä–∫–∏:       {check_time:.2f} —Å–µ–∫")
        if check_time > 0:
            print(f"üöÄ –°–∫–æ—Ä–æ—Å—Ç—å:            {total/check_time:,.0f} email/—Å–µ–∫")

    def show_status(self, pattern: str = None, category: str = None, country: str = None):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –≤—Å–µ—Ö —Å–ø–∏—Å–∫–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π"""
        print("\n" + "="*80)
        print("üìä –°–¢–ê–¢–£–° EMAIL –°–ü–ò–°–ö–û–í")
        print("="*80)

        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –Ω–æ–≤—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏
        input_files = list(self.input_dir.glob("*.txt"))
        for file_path in input_files:
            filename = file_path.name
            self.config_manager.get_list_metadata(filename, self.output_dir)

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
        lists_to_show = []
        for list_info in self.config_manager.lists_config.get("lists", []):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
            if pattern and pattern.lower() not in list_info["filename"].lower():
                continue
            if category and category.lower() != list_info["category"].lower():
                continue
            if country and country.lower() != list_info["country"].lower():
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
            file_path = self.input_dir / list_info["filename"]
            if file_path.exists():
                file_size = file_path.stat().st_size
                list_info["file_size"] = file_size
                list_info["exists"] = True
            else:
                list_info["file_size"] = 0
                list_info["exists"] = False

            lists_to_show.append(list_info)

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        lists_to_show.sort(key=lambda x: x.get("priority", 999))

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        total_lists = len(lists_to_show)
        processed_lists = sum(1 for lst in lists_to_show if lst["processed"])
        pending_lists = total_lists - processed_lists

        print(f"üìã –í—Å–µ–≥–æ —Å–ø–∏—Å–∫–æ–≤: {total_lists}")
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_lists}")
        print(f"‚è≥ –û–∂–∏–¥–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏: {pending_lists}")
        print()

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª–∏
        print(f"{'‚Ññ':>3} {'–§–∞–π–ª':<20} {'–ù–∞–∑–≤–∞–Ω–∏–µ':<25} {'–°—Ç—Ä–∞–Ω–∞':<12} {'–ö–∞—Ç–µ–≥–æ—Ä–∏—è':<15} {'–†–∞–∑–º–µ—Ä':<10} {'–°—Ç–∞—Ç—É—Å':<12}")
        print("-" * 105)

        for i, list_info in enumerate(lists_to_show, 1):
            filename = list_info["filename"]
            display_name = list_info["display_name"][:24] + ("..." if len(list_info["display_name"]) > 24 else "")
            country = list_info["country"]
            category = list_info["category"]

            if list_info["exists"]:
                size_str = self._format_file_size(list_info["file_size"])
            else:
                size_str = "–ù–ï–¢ –§–ê–ô–õ–ê"

            status = "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω" if list_info["processed"] else "‚è≥ –û–∂–∏–¥–∞–µ—Ç"

            print(f"{i:>3} {filename:<20} {display_name:<25} {country:<12} {category:<15} {size_str:<10} {status}")

        print("\nüí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–∏–ª—å—Ç—Ä—ã: --pattern, --category, --country")
        print("üîÑ –î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤: python3 email_checker.py incremental --exclude-duplicates --generate-html")

    def _format_file_size(self, size_bytes: int) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–º –≤–∏–¥–µ"""
        if size_bytes < 1024:
            return f"{size_bytes}B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f}KB"
        else:
            return f"{size_bytes / (1024 * 1024):.1f}MB"

    def find_duplicates(self, lists: List[Set[str]]) -> Dict[str, Set[str]]:
        """–ù–∞—Ö–æ–¥–∏—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –º–µ–∂–¥—É –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Å–ø–∏—Å–∫–∞–º–∏"""
        if len(lists) < 2:
            return {}

        duplicates = {}
        for i, current_list in enumerate(lists[1:], 1):
            prev_emails = set()
            for j in range(i):
                prev_emails.update(lists[j])

            dupes = current_list.intersection(prev_emails)
            if dupes:
                duplicates[f'list_{i+1}_duplicates'] = dupes

        return duplicates

    def check_multiple_lists(self, input_files: List[str], exclude_duplicates: bool = False):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ø–∏—Å–∫–æ–≤, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –∏—Å–∫–ª—é—á–∞—è –¥—É–±–ª–∏–∫–∞—Ç—ã"""
        all_lists = []

        for input_file in input_files:
            if not Path(input_file).exists():
                print(f"‚ùå –§–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue

            emails = self.load_emails_from_file(input_file)
            all_lists.append(emails)

        if not all_lists:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return

        # –ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        if exclude_duplicates and len(all_lists) > 1:
            duplicates = self.find_duplicates(all_lists)
            print(f"\nüîç –ù–∞–π–¥–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –º–µ–∂–¥—É —Å–ø–∏—Å–∫–∞–º–∏:")
            for list_name, dupes in duplicates.items():
                print(f"   {list_name}: {len(dupes)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —Å–ø–∏—Å–∫–∞
        for i, (input_file, emails) in enumerate(zip(input_files, all_lists)):
            print(f"\nüìã –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–∏—Å–∫–∞ {i+1}: {input_file}")

            # –ò—Å–∫–ª—é—á–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–ø–∏—Å–∫–∞–º–∏ –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
            removed_dupes = 0  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—á–µ—Ç—á–∏–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –º–µ–∂–¥—É —Å–ø–∏—Å–∫–∞–º–∏
            if exclude_duplicates and i > 0:
                prev_emails = set()
                for j in range(i):
                    prev_emails.update(all_lists[j])

                original_count = len(emails)
                emails = emails - prev_emails
                removed_dupes = original_count - len(emails)

                if removed_dupes > 0:
                    print(f"   üóëÔ∏è  –ò—Å–∫–ª—é—á–µ–Ω–æ {removed_dupes} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–ø–∏—Å–∫–∞–º–∏")

            if not emails:
                print("   ‚ö†Ô∏è  –ü–æ—Å–ª–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç")
                continue

            # –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20' –≤–Ω—É—Ç—Ä–∏ —Å–ø–∏—Å–∫–∞
            original_count = len(emails)
            emails, removed_count = self.clean_prefix_duplicates(emails)
            if removed_count > 0:
                print(f"   üßπ –û—á–∏—â–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20' (–±—ã–ª–æ {original_count}, —Å—Ç–∞–ª–æ {len(emails)})")

            results = self.check_email_against_blocklists(emails)
            filename_base = f"{Path(input_file).stem}_seq{i+1}"
            self.report_generator.save_results(filename_base, results)
            
            result_data = {
                'filename': filename_base,
                'stats': dict(self.stats),
                'results': results,
                'duplicates_removed': removed_dupes,
                'prefix_duplicates_removed': removed_count,
                'timestamp': datetime.now().isoformat()
            }
            self.report_generator.add_result(result_data)
            
            self.print_statistics()

    def check_lvp_file(self, input_file: str):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç LVP —Ñ–∞–π–ª –Ω–∞–ø—Ä—è–º—É—é —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        if not Path(input_file).exists():
            print(f"‚ùå –§–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return

        filename_base = Path(input_file).stem
        print(f"\nüìß –ü–†–û–í–ï–†–ö–ê LVP –§–ê–ô–õ–ê: {filename_base}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–∑ LVP —Ñ–∞–π–ª–∞
        emails_with_metadata = self.load_emails_with_metadata(input_file)

        if not emails_with_metadata:
            print(f"‚ùå –§–∞–π–ª {input_file} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö email")
            return

        print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(emails_with_metadata)} email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–∑ LVP —Ñ–∞–π–ª–∞")

        # –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20'
        # –°–æ–∑–¥–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–æ email –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        email_set = set(obj.email for obj in emails_with_metadata)
        original_count = len(email_set)
        cleaned_emails, removed_count = self.clean_prefix_duplicates(email_set)

        if removed_count > 0:
            print(f"üßπ –û—á–∏—â–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20' (–±—ã–ª–æ {original_count}, —Å—Ç–∞–ª–æ {len(cleaned_emails)})")
            # –§–∏–ª—å—Ç—Ä—É–µ–º –æ–±—ä–µ–∫—Ç—ã, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ –≤ cleaned_emails
            emails_with_metadata = [obj for obj in emails_with_metadata if obj.email in cleaned_emails]

        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤
        results = self.check_emails_with_metadata(emails_with_metadata)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        self.save_results_with_metadata(filename_base, results)

        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.print_statistics()

        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å—Ç–∞—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        old_format_results = {
            'clean': [obj.email for obj in results['clean']],
            'blocked_email': [obj.email for obj in results['blocked_email']],
            'blocked_domain': [obj.email for obj in results['blocked_domain']],
            'invalid': [obj.email for obj in results['invalid']]
        }
        
        result_data = {
            'filename': filename_base,
            'stats': dict(self.stats),
            'results': old_format_results,
            'duplicates_removed': 0,
            'prefix_duplicates_removed': removed_count,
            'timestamp': datetime.now().isoformat()
        }
        self.report_generator.add_result(result_data)

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        filename = Path(input_file).name
        self.config_manager.update_list_processed_status(filename, processed=True)

    def check_multiple_lvp_files(self, input_files: List[str], exclude_duplicates: bool = False):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ LVP —Ñ–∞–π–ª–æ–≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –∏—Å–∫–ª—é—á–∞—è –¥—É–±–ª–∏–∫–∞—Ç—ã
        """
        all_lists = []

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
        for input_file in input_files:
            if not Path(input_file).exists():
                print(f"‚ùå –§–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue

            emails_with_metadata = self.load_emails_with_metadata(input_file)
            all_lists.append(emails_with_metadata)

        if not all_lists:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —Å–ø–∏—Å–∫–∞
        processed_emails = set()  # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö email

        for i, (input_file, emails_with_metadata) in enumerate(zip(input_files, all_lists)):
            print(f"\nüìã –û–±—Ä–∞–±–æ—Ç–∫–∞ LVP —Ñ–∞–π–ª–∞ {i+1}/{len(input_files)}: {Path(input_file).name}")

            # –ò—Å–∫–ª—é—á–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–ø–∏—Å–∫–∞–º–∏ –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
            removed_dupes = 0
            if exclude_duplicates and i > 0:
                original_count = len(emails_with_metadata)
                emails_with_metadata = [obj for obj in emails_with_metadata if obj.email.lower() not in processed_emails]
                removed_dupes = original_count - len(emails_with_metadata)

                if removed_dupes > 0:
                    print(f"   üóëÔ∏è  –ò—Å–∫–ª—é—á–µ–Ω–æ {removed_dupes} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–ø–∏—Å–∫–∞–º–∏")

            if not emails_with_metadata:
                print("   ‚ö†Ô∏è  –ü–æ—Å–ª–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç")
                continue

            # –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20' –≤–Ω—É—Ç—Ä–∏ —Å–ø–∏—Å–∫–∞
            email_set = set(obj.email for obj in emails_with_metadata)
            original_count = len(email_set)
            cleaned_emails, removed_count = self.clean_prefix_duplicates(email_set)

            if removed_count > 0:
                print(f"   üßπ –û—á–∏—â–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20' (–±—ã–ª–æ {original_count}, —Å—Ç–∞–ª–æ {len(cleaned_emails)})")
                emails_with_metadata = [obj for obj in emails_with_metadata if obj.email in cleaned_emails]

            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ email –≤ –Ω–∞–±–æ—Ä
            for obj in emails_with_metadata:
                processed_emails.add(obj.email.lower())

            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤
            results = self.check_emails_with_metadata(emails_with_metadata)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            filename_base = f"{Path(input_file).stem}_seq{i+1}"
            self.save_results_with_metadata(filename_base, results)

            # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å—Ç–∞—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            old_format_results = {
                'clean': [obj.email for obj in results['clean']],
                'blocked_email': [obj.email for obj in results['blocked_email']],
                'blocked_domain': [obj.email for obj in results['blocked_domain']],
                'invalid': [obj.email for obj in results['invalid']]
            }
            
            result_data = {
                'filename': filename_base,
                'stats': dict(self.stats),
                'results': old_format_results,
                'duplicates_removed': removed_dupes,
                'prefix_duplicates_removed': removed_count,
                'timestamp': datetime.now().isoformat()
            }
            self.report_generator.add_result(result_data)

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            filename = Path(input_file).name
            self.config_manager.update_list_processed_status(filename, processed=True)

            self.print_statistics()

    def check_lvp_batch(self, exclude_duplicates: bool = False, generate_html: bool = False):
        """
        Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö LVP —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ input/
        """
        # –ò—â–µ–º –≤—Å–µ LVP —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ input
        input_files = list(self.input_dir.glob("*.lvp"))
        if not input_files:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ LVP —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ input/")
            return

        print(f"\nüìã –ù–∞–π–¥–µ–Ω–æ {len(input_files)} LVP —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        unprocessed_files = []
        for input_file in input_files:
            filename = input_file.name
            list_metadata = self.config_manager.get_list_metadata(filename, self.output_dir)
            if not list_metadata.get("processed", False):
                unprocessed_files.append(str(input_file))

        if not unprocessed_files:
            print("üéâ –í—Å–µ LVP —Ñ–∞–π–ª—ã —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
            if generate_html:
                self.report_generator.generate_html_report("lvp_batch_report")
            return

        print(f"üìã –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(unprocessed_files)} –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö LVP —Ñ–∞–π–ª–æ–≤ –∏–∑ {len(input_files)}")

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã
        self.check_multiple_lvp_files(unprocessed_files, exclude_duplicates=exclude_duplicates)

        if generate_html:
            self.report_generator.generate_html_report("lvp_batch_report")

        print(f"\nüéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

    def check_all_incremental(self, exclude_duplicates: bool = False, generate_html: bool = False):
        """
        Unified incremental –æ–±—Ä–∞–±–æ—Ç–∫–∞ –í–°–ï–• —Ñ–∞–π–ª–æ–≤ (TXT + LVP) –≤ –ø–∞–ø–∫–µ input/ —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        """
        # –ò—â–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã (TXT –∏ LVP)
        txt_files = list(self.input_dir.glob("*.txt"))
        lvp_files = list(self.input_dir.glob("*.lvp"))
        all_input_files = txt_files + lvp_files

        if not all_input_files:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –ø–∞–ø–∫–µ input/")
            return

        print(f"\nüìã –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(txt_files)} TXT + {len(lvp_files)} LVP = {len(all_input_files)} –≤—Å–µ–≥–æ")

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        unprocessed_txt = []
        unprocessed_lvp = []

        for input_file in all_input_files:
            filename = input_file.name
            list_metadata = self.config_manager.get_list_metadata(filename, self.output_dir)
            if not list_metadata.get("processed", False):
                if filename.endswith('.lvp'):
                    unprocessed_lvp.append(str(input_file))
                else:
                    unprocessed_txt.append(str(input_file))

        total_unprocessed = len(unprocessed_txt) + len(unprocessed_lvp)

        if total_unprocessed == 0:
            print("üéâ –í—Å–µ —Ñ–∞–π–ª—ã —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã —Å–æ–≥–ª–∞—Å–Ω–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏!")
            if generate_html:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –∫–µ—à–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞
                cache_data = self.cache_manager.load_processed_files_cache()
                for filename, cached_result in cache_data.items():
                    if 'result_data' in cached_result:
                        self.report_generator.add_result(cached_result['result_data'])
                self.report_generator.generate_html_report("all_incremental_report")
            return

        print(f"üìã –ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö: {len(unprocessed_txt)} TXT + {len(unprocessed_lvp)} LVP = {total_unprocessed} —Ñ–∞–π–ª–æ–≤")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ email –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è)
        already_processed_emails = set()
        if exclude_duplicates:
            already_processed_emails = self.cache_manager.load_already_processed_emails()

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º TXT —Ñ–∞–π–ª—ã
        processed_emails_from_txt = set()
        if unprocessed_txt:
            print(f"\n{'='*60}")
            print(f"üìù –û–ë–†–ê–ë–û–¢–ö–ê TXT –§–ê–ô–õ–û–í ({len(unprocessed_txt)})")
            print(f"{'='*60}")

            for i, txt_file in enumerate(unprocessed_txt, 1):
                print(f"\n[{i}/{len(unprocessed_txt)}] –û–±—Ä–∞–±–æ—Ç–∫–∞ TXT: {Path(txt_file).name}")

                emails = self.load_emails_from_file(txt_file)
                original_count = len(emails)

                # –ò—Å–∫–ª—é—á–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Å —Ä–∞–Ω–µ–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏
                if exclude_duplicates:
                    emails_before_dedup = len(emails)
                    emails = emails - already_processed_emails - processed_emails_from_txt
                    removed = emails_before_dedup - len(emails)
                    if removed > 0:
                        print(f"   üóëÔ∏è  –ò—Å–∫–ª—é—á–µ–Ω–æ {removed} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å —Ä–∞–Ω–µ–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ —Å–ø–∏—Å–∫–∞–º–∏")

                if not emails:
                    print("   ‚ö†Ô∏è  –ü–æ—Å–ª–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç")
                    self.config_manager.update_list_processed_status(Path(txt_file).name, processed=True)
                    continue

                # –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20'
                emails, removed_count = self.clean_prefix_duplicates(emails)
                if removed_count > 0:
                    print(f"   üßπ –û—á–∏—â–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20'")

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
                results = self.check_email_against_blocklists(emails)
                filename_base = f"{Path(txt_file).stem}_incremental"
                self.report_generator.save_results(filename_base, results)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ—Ç—á–µ—Ç–∞
                result_data = {
                    'filename': filename_base,
                    'stats': dict(self.stats),
                    'results': results,
                    'duplicates_removed': original_count - len(emails),
                    'prefix_duplicates_removed': removed_count,
                    'timestamp': datetime.now().isoformat()
                }
                self.report_generator.add_result(result_data)
                
                # Update cache
                cache_data = self.cache_manager.load_processed_files_cache()
                filename_key = Path(txt_file).name
                cache_data[filename_key] = {
                    'hash': self.cache_manager.get_file_hash(txt_file),
                    'result_data': result_data,
                    'processed_at': datetime.now().isoformat()
                }
                self.cache_manager.save_processed_files_cache(cache_data)

                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –Ω–∞–±–æ—Ä –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö
                processed_emails_from_txt.update(emails)

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
                self.config_manager.update_list_processed_status(Path(txt_file).name, processed=True)
                self.print_statistics()

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º LVP —Ñ–∞–π–ª—ã
        if unprocessed_lvp:
            print(f"\n{'='*60}")
            print(f"üìÑ –û–ë–†–ê–ë–û–¢–ö–ê LVP –§–ê–ô–õ–û–í ({len(unprocessed_lvp)})")
            print(f"{'='*60}")

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ä–∞–Ω–µ–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ email (–∏–∑ –∫–µ—à–∞ + –∏–∑ —Ç–æ–ª—å–∫–æ —á—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö TXT)
            all_processed_emails = already_processed_emails | processed_emails_from_txt

            for i, lvp_file in enumerate(unprocessed_lvp, 1):
                print(f"\n[{i}/{len(unprocessed_lvp)}] –û–±—Ä–∞–±–æ—Ç–∫–∞ LVP: {Path(lvp_file).name}")

                emails_with_metadata = self.load_emails_with_metadata(lvp_file)
                if not emails_with_metadata:
                    print(f"   ‚ö†Ô∏è  –§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö email")
                    continue

                original_count = len(emails_with_metadata)

                # –ò—Å–∫–ª—é—á–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Å —Ä–∞–Ω–µ–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏
                if exclude_duplicates and all_processed_emails:
                    emails_before_dedup = len(emails_with_metadata)
                    emails_with_metadata = [obj for obj in emails_with_metadata
                                          if obj.email.lower() not in all_processed_emails]
                    removed = emails_before_dedup - len(emails_with_metadata)
                    if removed > 0:
                        print(f"   üóëÔ∏è  –ò—Å–∫–ª—é—á–µ–Ω–æ {removed} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å —Ä–∞–Ω–µ–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ —Å–ø–∏—Å–∫–∞–º–∏")

                if not emails_with_metadata:
                    print("   ‚ö†Ô∏è  –ü–æ—Å–ª–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç")
                    self.config_manager.update_list_processed_status(Path(lvp_file).name, processed=True)
                    continue

                # –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20'
                email_set = set(obj.email for obj in emails_with_metadata)
                cleaned_emails, removed_count = self.clean_prefix_duplicates(email_set)
                if removed_count > 0:
                    print(f"   üßπ –û—á–∏—â–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20'")
                    emails_with_metadata = [obj for obj in emails_with_metadata if obj.email in cleaned_emails]

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
                results = self.check_emails_with_metadata(emails_with_metadata)
                filename_base = f"{Path(lvp_file).stem}_incremental"
                self.save_results_with_metadata(filename_base, results)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ—Ç—á–µ—Ç–∞ (–≤ —Å—Ç–∞—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
                old_format_results = {
                    'clean': [obj.email for obj in results['clean']],
                    'blocked_email': [obj.email for obj in results['blocked_email']],
                    'blocked_domain': [obj.email for obj in results['blocked_domain']],
                    'invalid': [obj.email for obj in results['invalid']]
                }
                
                result_data = {
                    'filename': filename_base,
                    'stats': dict(self.stats),
                    'results': old_format_results,
                    'duplicates_removed': original_count - len(emails_with_metadata),
                    'prefix_duplicates_removed': removed_count,
                    'timestamp': datetime.now().isoformat()
                }
                self.report_generator.add_result(result_data)
                
                # Update cache
                cache_data = self.cache_manager.load_processed_files_cache()
                filename_key = Path(lvp_file).name
                cache_data[filename_key] = {
                    'hash': self.cache_manager.get_file_hash(lvp_file),
                    'result_data': result_data,
                    'processed_at': datetime.now().isoformat()
                }
                self.cache_manager.save_processed_files_cache(cache_data)

                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –Ω–∞–±–æ—Ä –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö
                for obj in emails_with_metadata:
                    all_processed_emails.add(obj.email.lower())

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
                self.config_manager.update_list_processed_status(Path(lvp_file).name, processed=True)
                self.print_statistics()

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –µ–¥–∏–Ω—ã–π –æ—Ç—á–µ—Ç
        if generate_html:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –í–°–ï —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –∫–µ—à–∞ (–≤–∫–ª—é—á–∞—è —Ä–∞–Ω–µ–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã)
            cache_data = self.cache_manager.load_processed_files_cache()
            # –û—á–∏—â–∞–µ–º all_results –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –∫–µ—à–∞ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
            self.report_generator.all_results.clear()
            for filename, cached_result in cache_data.items():
                if 'result_data' in cached_result:
                    self.report_generator.add_result(cached_result['result_data'])
            self.report_generator.generate_html_report("all_incremental_report")

        print(f"\n{'='*60}")
        print(f"üéâ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
        print(f"{'='*60}")
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ TXT: {len(unprocessed_txt)}")
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ LVP: {len(unprocessed_lvp)}")
        print(f"üìä –í—Å–µ–≥–æ: {total_unprocessed} —Ñ–∞–π–ª–æ–≤")

    def check_incremental_batch(self, exclude_duplicates: bool = False, generate_html: bool = False):
        """
        –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ input/ —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        """
        input_files = list(self.input_dir.glob("*.txt"))
        if not input_files:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ txt —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ input/")
            return

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        unprocessed_files = []
        for input_file in input_files:
            filename = input_file.name
            list_metadata = self.config_manager.get_list_metadata(filename, self.output_dir)
            if not list_metadata.get("processed", False):
                unprocessed_files.append(str(input_file))

        if not unprocessed_files:
            print("üéâ –í—Å–µ —Ñ–∞–π–ª—ã —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã —Å–æ–≥–ª–∞—Å–Ω–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏!")
            if generate_html:
                self.report_generator.generate_html_report("incremental_report")
            return

        print(f"\nüìã –ù–∞–π–¥–µ–Ω–æ {len(unprocessed_files)} –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ {len(input_files)}")

        file_paths = unprocessed_files
        
        # Check what needs processing
        cache_data = self.cache_manager.load_processed_files_cache()
        files_to_process = []
        
        print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è...")

        for file_path in file_paths:
            file_path = str(file_path)
            current_hash = self.cache_manager.get_file_hash(file_path)
            filename = Path(file_path).name

            if filename not in cache_data:
                # –ù–æ–≤—ã–π —Ñ–∞–π–ª
                files_to_process.append(file_path)
                print(f"   üìÑ –ù–æ–≤—ã–π —Ñ–∞–π–ª: {filename}")
            elif cache_data[filename].get('hash') != current_hash:
                # –§–∞–π–ª –∏–∑–º–µ–Ω–∏–ª—Å—è
                files_to_process.append(file_path)
                print(f"   üìù –ò–∑–º–µ–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {filename}")
            else:
                # –§–∞–π–ª –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è, –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –∫–µ—à–∞
                print(f"   ‚úÖ –ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {filename} (–∏–∑ –∫–µ—à–∞)")
                if 'result_data' in cache_data[filename]:
                    self.report_generator.add_result(cache_data[filename]['result_data'])

        if not files_to_process:
            print("üéâ –í—Å–µ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –∫–µ—à–µ –∏ –Ω–µ –∏–∑–º–µ–Ω—è–ª–∏—Å—å!")
            # –û—Ç–º–µ—á–∞–µ–º —Ñ–∞–π–ª—ã –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            for file_path in file_paths:
                filename = Path(file_path).name
                self.config_manager.update_list_processed_status(filename, processed=True)
            if generate_html:
                self.report_generator.generate_html_report("incremental_report")
            return

        print(f"\nüìã –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(files_to_process)} —Ñ–∞–π–ª–æ–≤ –∏–∑ {len(file_paths)}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —Å–ø–∏—Å–∫–∏ (–Ω—É–∂–Ω–æ –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –º–µ–∂–¥—É —Å–ø–∏—Å–∫–∞–º–∏)
        all_lists = []
        all_file_paths = []

        for input_file in file_paths:
            emails = self.load_emails_from_file(input_file)
            all_lists.append(emails)
            all_file_paths.append(input_file)

        # –ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –º–µ–∂–¥—É –≤—Å–µ–º–∏ —Å–ø–∏—Å–∫–∞–º–∏ –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        if exclude_duplicates and len(all_lists) > 1:
            duplicates = self.find_duplicates(all_lists)
            if duplicates:
                print(f"\nüîç –ù–∞–π–¥–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –º–µ–∂–¥—É —Å–ø–∏—Å–∫–∞–º–∏:")
                for list_name, dupes in duplicates.items():
                    print(f"   {list_name}: {len(dupes)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –í–°–ï —Ñ–∞–π–ª—ã –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
        processed_lists = []  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤

        for i, input_file in enumerate(all_file_paths):
            filename = Path(input_file).name
            emails = all_lists[i]

            print(f"\nüìã –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {filename}")

            # –ò—Å–∫–ª—é—á–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–ø–∏—Å–∫–∞–º–∏ –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
            original_count = len(emails)
            removed_dupes = 0  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—á–µ—Ç—á–∏–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –º–µ–∂–¥—É —Å–ø–∏—Å–∫–∞–º–∏
            if exclude_duplicates and i > 0:
                prev_emails = set()
                for processed_list in processed_lists:
                    prev_emails.update(processed_list)

                emails = emails - prev_emails
                removed_dupes = original_count - len(emails)

                if removed_dupes > 0:
                    print(f"   üóëÔ∏è  –ò—Å–∫–ª—é—á–µ–Ω–æ {removed_dupes} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–ø–∏—Å–∫–∞–º–∏")

            if not emails:
                print("   ‚ö†Ô∏è  –ü–æ—Å–ª–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç")
                processed_lists.append(set())  # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç–æ–π –Ω–∞–±–æ—Ä
                continue

            # –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20' –≤–Ω—É—Ç—Ä–∏ —Å–ø–∏—Å–∫–∞
            emails, removed_count = self.clean_prefix_duplicates(emails)
            if removed_count > 0:
                print(f"   üßπ –û—á–∏—â–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20' (–±—ã–ª–æ {original_count}, —Å—Ç–∞–ª–æ {len(emails)})")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ —Å–ª–µ–¥—É—é—â–∏—Ö
            processed_lists.append(emails.copy())

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–æ–≤—ã—Ö/–∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            if input_file in files_to_process:
                print(f"   üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –Ω–æ–≤–æ–≥–æ/–∏–∑–º–µ–Ω–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞")
                results = self.check_email_against_blocklists(emails)
                filename_base = f"{Path(input_file).stem}_incremental"
                self.report_generator.save_results(filename_base, results)
                
                result_data = {
                    'filename': filename_base,
                    'stats': dict(self.stats),
                    'results': results,
                    'duplicates_removed': removed_dupes,
                    'prefix_duplicates_removed': removed_count,
                    'timestamp': datetime.now().isoformat()
                }
                self.report_generator.add_result(result_data)
                
                # Update cache
                filename_key = Path(input_file).name
                cache_data[filename_key] = {
                    'hash': self.cache_manager.get_file_hash(input_file),
                    'result_data': result_data,
                    'processed_at': datetime.now().isoformat()
                }

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                self.config_manager.update_list_processed_status(filename, processed=True)

                self.print_statistics()
            else:
                print(f"   ‚úÖ –§–∞–π–ª –∏–∑ –∫–µ—à–∞, —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ä–∞–Ω–µ–µ")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∫–µ—à
        self.cache_manager.save_processed_files_cache(cache_data)
        print(f"\nüíæ –ö–µ—à –æ–±–Ω–æ–≤–ª–µ–Ω: {len(cache_data)} —Ñ–∞–π–ª–æ–≤")

        if generate_html:
            self.report_generator.generate_html_report("incremental_batch_report")
