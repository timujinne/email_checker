#!/usr/bin/env python3
"""
Smart Filter Processor - –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä —É–º–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ clean-–ª–∏—Å—Ç–æ–≤

–ü—Ä–∏–º–µ–Ω—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –∫ —É–∂–µ –æ—á–∏—â–µ–Ω–Ω—ã–º email-–ª–∏—Å—Ç–∞–º —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, italy_hydraulics_filter)
"""

import json
import csv
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Set, Optional, Tuple
from collections import defaultdict

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º Italy Hydraulics Filter
from smart_filters.italy_hydraulics_filter import (
    ItalyHydraulicsHardExclusionFilter,
    ItalyHydraulicsDetector,
    ItalyHydraulicsClassifier,
    ItalyHydraulicsLeadScorer,
    load_config
)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
from email_metadata import EmailWithMetadata


class FilterResult:
    """
    –†–µ–∑—É–ª—å—Ç–∞—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    """
    def __init__(self, source_file: Path):
        self.source_file = source_file
        self.timestamp = datetime.now()

        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º
        self.high_priority: List[Dict] = []
        self.medium_priority: List[Dict] = []
        self.low_priority: List[Dict] = []
        self.excluded: List[Dict] = []

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'total_input': 0,
            'hard_excluded': 0,
            'high_priority': 0,
            'medium_priority': 0,
            'low_priority': 0,
            'excluded': 0,
            'processing_time': 0.0
        }

        # –ü—Ä–∏—á–∏–Ω—ã –∏—Å–∫–ª—é—á–µ–Ω–∏–π
        self.exclusion_reasons: List[Dict] = []

    def get_statistics(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        return {
            'source_file': self.source_file.name,
            **self.stats,
            'success_rate': round((self.stats['high_priority'] + self.stats['medium_priority']) /
                                 max(1, self.stats['total_input']) * 100, 2)
        }


class SmartFilterProcessor:
    """
    –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä —É–º–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    """

    def __init__(self, filter_name: str = 'italy_hydraulics', base_dir: str = '.'):
        """
        Args:
            filter_name: –ò–º—è —Ñ–∏–ª—å—Ç—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'italy_hydraulics')
            base_dir: –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞
        """
        self.filter_name = filter_name
        self.base_dir = Path(base_dir)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥ —Ñ–∏–ª—å—Ç—Ä–∞
        config_path = self.base_dir / 'smart_filters' / 'configs' / f'{filter_name}_config.json'
        if not config_path.exists():
            raise FileNotFoundError(f"–ö–æ–Ω—Ñ–∏–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω: {config_path}")

        self.config = load_config(str(config_path))
        print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω –∫–æ–Ω—Ñ–∏–≥: {self.config['filter_name']} v{self.config['version']}")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Ñ–∏–ª—å—Ç—Ä–∞
        self._init_filter_components()

        # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.output_dir = self.base_dir / 'output'
        self.output_dir.mkdir(exist_ok=True)

    def _init_filter_components(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Ñ–∏–ª—å—Ç—Ä–∞"""
        if self.filter_name == 'italy_hydraulics':
            self.hard_exclusion_filter = ItalyHydraulicsHardExclusionFilter(self.config)
            self.detector = ItalyHydraulicsDetector(self.config)
            self.classifier = ItalyHydraulicsClassifier(self.config)
            self.lead_scorer = ItalyHydraulicsLeadScorer(self.config)
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä: {self.filter_name}")

        print(f"‚úì –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Ñ–∏–ª—å—Ç—Ä–∞: {self.filter_name}")

    def process_clean_file(self, clean_file_path: Path,
                          include_metadata: bool = True) -> FilterResult:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω clean-—Ñ–∞–π–ª

        Args:
            clean_file_path: –ü—É—Ç—å –∫ clean-—Ñ–∞–π–ª—É (TXT, CSV, JSON)
            include_metadata: –í–∫–ª—é—á–∞—Ç—å –ª–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ –≤—ã—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã

        Returns:
            FilterResult —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        print(f"\n{'='*70}")
        print(f"üîç SMART FILTER: {clean_file_path.name}")
        print(f"   –§–∏–ª—å—Ç—Ä: {self.config['filter_name']}")
        print(f"{'='*70}\n")

        result = FilterResult(clean_file_path)
        start_time = datetime.now()

        try:
            # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º email –∏–∑ clean-—Ñ–∞–π–ª–∞
            emails_data = self._load_clean_file(clean_file_path)
            result.stats['total_input'] = len(emails_data)
            print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(emails_data)} email")

            # 2. –ü—Ä–∏–º–µ–Ω—è–µ–º –∂–µ—Å—Ç–∫–∏–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
            after_hard_exclusions = self._apply_hard_exclusions(emails_data, result)
            print(f"‚úì –ü–æ—Å–ª–µ –∂–µ—Å—Ç–∫–∏—Ö –∏—Å–∫–ª—é—á–µ–Ω–∏–π: {len(after_hard_exclusions)} email "
                  f"({result.stats['hard_excluded']} –∏—Å–∫–ª—é—á–µ–Ω–æ)")

            # 3. –°–∫–æ—Ä–∏–Ω–≥ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤
            self._score_contacts(after_hard_exclusions, result)
            print(f"‚úì –°–∫–æ—Ä–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω:")
            print(f"   üî• High priority:   {result.stats['high_priority']}")
            print(f"   ‚≠ê Medium priority: {result.stats['medium_priority']}")
            print(f"   üí° Low priority:    {result.stats['low_priority']}")
            print(f"   ‚ùå Excluded:        {result.stats['excluded']}")

            # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            self._save_results(result, include_metadata)

            # 5. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç—ã
            if self.config['output_settings'].get('generate_html_report', True):
                self._generate_html_report(result)

            if self.config['output_settings'].get('generate_exclusion_report', True):
                self._save_exclusion_report(result)

        except Exception as error:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {clean_file_path.name}: {error}")
            raise

        finally:
            result.stats['processing_time'] = (datetime.now() - start_time).total_seconds()
            print(f"\n‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result.stats['processing_time']:.2f} —Å–µ–∫")
            print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞\n")

        return result

    def process_clean_batch(self, pattern: str = "output/*_clean_*.txt") -> List[FilterResult]:
        """
        Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö clean-—Ñ–∞–π–ª–æ–≤

        Args:
            pattern: Glob –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ clean-—Ñ–∞–π–ª–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ FilterResult –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
        """
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ clean-—Ñ–∞–π–ª—ã
        clean_files = list(Path('.').glob(pattern))

        if not clean_files:
            print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É: {pattern}")
            return []

        print(f"\n{'='*70}")
        print(f"üì¶ BATCH SMART FILTER")
        print(f"   –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(clean_files)}")
        print(f"   –§–∏–ª—å—Ç—Ä: {self.config['filter_name']}")
        print(f"{'='*70}\n")

        results = []
        for i, clean_file in enumerate(clean_files, 1):
            print(f"\n[{i}/{len(clean_files)}] –û–±—Ä–∞–±–æ—Ç–∫–∞: {clean_file.name}")
            try:
                result = self.process_clean_file(clean_file)
                results.append(result)
            except Exception as error:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ —Ñ–∞–π–ª–µ {clean_file.name}: {error}")
                continue

        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self._print_batch_summary(results)

        return results

    def _load_clean_file(self, file_path: Path) -> List[Dict]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç email –∏–∑ clean-—Ñ–∞–π–ª–∞

        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:
        - TXT: –æ–¥–∏–Ω email –Ω–∞ —Å—Ç—Ä–æ–∫—É
        - CSV: —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ email, company, description, keywords, source, domain
        - JSON: –º–∞—Å—Å–∏–≤ –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–ª—è–º–∏
        """
        emails_data = []

        try:
            if file_path.suffix.lower() == '.txt':
                # TXT: —Ç–æ–ª—å–∫–æ email
                with open(file_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        email = line.strip()
                        if email and '@' in email:
                            emails_data.append({
                                'email': email,
                                'company': '',
                                'description': '',
                                'keywords': '',
                                'source': '',
                                'domain': ''
                            })

            elif file_path.suffix.lower() == '.csv':
                # CSV: —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
                with open(file_path, 'r', encoding='utf-8', newline='') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        if row.get('email'):
                            emails_data.append({
                                'email': row.get('email', ''),
                                'company': row.get('company_name', row.get('company', '')),
                                'description': row.get('description', row.get('meta_description', '')),
                                'keywords': row.get('keywords', ''),
                                'source': row.get('source', ''),
                                'domain': row.get('domain', row.get('web_domain', ''))
                            })

            elif file_path.suffix.lower() == '.json':
                # JSON: —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    if isinstance(data, list):
                        for item in data:
                            if item.get('email'):
                                emails_data.append({
                                    'email': item.get('email', ''),
                                    'company': item.get('company_name', item.get('company', '')),
                                    'description': item.get('description', ''),
                                    'keywords': item.get('keywords', ''),
                                    'source': item.get('source', ''),
                                    'domain': item.get('domain', '')
                                })

            else:
                raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {file_path.suffix}")

        except Exception as error:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {file_path.name}: {error}")
            raise

        return emails_data

    def _apply_hard_exclusions(self, emails_data: List[Dict], result: FilterResult) -> List[Dict]:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –∂–µ—Å—Ç–∫–∏–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è"""
        after_exclusions = []

        for email_data in emails_data:
            email = email_data['email']
            company = email_data.get('company', '')
            description = email_data.get('description', '')
            domain = email_data.get('domain', '')

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∂–µ—Å—Ç–∫–∏–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
            exclusion_result = self.hard_exclusion_filter.should_exclude(
                email, company, description, domain
            )

            if exclusion_result['should_exclude']:
                result.stats['hard_excluded'] += 1
                result.exclusion_reasons.append({
                    'email': email,
                    'company': company,
                    'reasons': exclusion_result['reasons'],
                    'severity': exclusion_result['severity']
                })
            else:
                after_exclusions.append(email_data)

        return after_exclusions

    def _score_contacts(self, emails_data: List[Dict], result: FilterResult):
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Å–∫–æ—Ä–∏–Ω–≥ –∫ –∫–æ–Ω—Ç–∞–∫—Ç–∞–º"""
        for email_data in emails_data:
            email = email_data['email']
            company = email_data.get('company', '')
            description = email_data.get('description', '')
            keywords = email_data.get('keywords', '')
            source = email_data.get('source', '')
            domain = email_data.get('domain', '')

            # –°–∫–æ—Ä–∏–Ω–≥
            score_result = self.lead_scorer.score_contact(
                email, company, description, keywords, source, domain
            )

            # –î–æ–±–∞–≤–ª—è–µ–º score –∫ –¥–∞–Ω–Ω—ã–º
            email_data_with_score = {
                **email_data,
                'overall_score': score_result['overall'],
                'email_score': score_result['breakdown']['email'],
                'relevance_score': score_result['breakdown']['relevance'],
                'geographic_score': score_result['breakdown']['geographic'],
                'engagement_score': score_result['breakdown']['engagement'],
                'priority': score_result['priority'],
                'target_category': score_result['target_category']
            }

            # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            if score_result['priority'] == 'high':
                result.high_priority.append(email_data_with_score)
                result.stats['high_priority'] += 1
            elif score_result['priority'] == 'medium':
                result.medium_priority.append(email_data_with_score)
                result.stats['medium_priority'] += 1
            elif score_result['priority'] == 'low':
                result.low_priority.append(email_data_with_score)
                result.stats['low_priority'] += 1
            else:
                result.excluded.append(email_data_with_score)
                result.stats['excluded'] += 1

    def _save_results(self, result: FilterResult, include_metadata: bool = True):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª—ã"""
        timestamp = result.timestamp.strftime("%Y%m%d_%H%M%S")
        filename_prefix = self.config['output_settings'].get('filename_prefix', 'Smart_Filter')
        source_name = result.source_file.stem

        categories = {
            'HIGH': result.high_priority,
            'MEDIUM': result.medium_priority,
            'LOW': result.low_priority,
            'EXCLUDED': result.excluded
        }

        for category_name, emails in categories.items():
            if not emails:
                continue

            # TXT: —Ç–æ–ª—å–∫–æ email
            txt_file = self.output_dir / f"{filename_prefix}_{source_name}_{category_name}_{timestamp}.txt"
            with open(txt_file, 'w', encoding='utf-8') as f:
                for email_data in emails:
                    f.write(f"{email_data['email']}\n")
            print(f"   ‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ TXT: {txt_file.name} ({len(emails)} email)")

            # CSV: —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
            if include_metadata:
                csv_file = self.output_dir / f"{filename_prefix}_{source_name}_{category_name}_metadata_{timestamp}.csv"
                with open(csv_file, 'w', encoding='utf-8', newline='') as f:
                    if emails:
                        fieldnames = emails[0].keys()
                        writer = csv.DictWriter(f, fieldnames=fieldnames)
                        writer.writeheader()
                        writer.writerows(emails)
                print(f"   ‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ CSV: {csv_file.name}")

                # JSON: —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
                json_file = self.output_dir / f"{filename_prefix}_{source_name}_{category_name}_metadata_{timestamp}.json"
                with open(json_file, 'w', encoding='utf-8') as f:
                    json.dump(emails, f, ensure_ascii=False, indent=2)
                print(f"   ‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ JSON: {json_file.name}")

    def _save_exclusion_report(self, result: FilterResult):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç—á–µ—Ç –æ–± –∏—Å–∫–ª—é—á–µ–Ω–∏—è—Ö"""
        if not result.exclusion_reasons:
            return

        timestamp = result.timestamp.strftime("%Y%m%d_%H%M%S")
        filename_prefix = self.config['output_settings'].get('filename_prefix', 'Smart_Filter')
        source_name = result.source_file.stem

        report_file = self.output_dir / f"{filename_prefix}_{source_name}_EXCLUSION_REPORT_{timestamp}.csv"

        with open(report_file, 'w', encoding='utf-8', newline='') as f:
            fieldnames = ['email', 'company', 'reasons', 'severity']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()

            for exclusion in result.exclusion_reasons:
                writer.writerow({
                    'email': exclusion['email'],
                    'company': exclusion['company'],
                    'reasons': ', '.join(exclusion['reasons']),
                    'severity': exclusion['severity']
                })

        print(f"   ‚úì –û—Ç—á–µ—Ç –æ–± –∏—Å–∫–ª—é—á–µ–Ω–∏—è—Ö: {report_file.name} ({len(result.exclusion_reasons)} –∑–∞–ø–∏—Å–µ–π)")

    def _generate_html_report(self, result: FilterResult):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç HTML –æ—Ç—á–µ—Ç"""
        # TODO: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å HTML –æ—Ç—á–µ—Ç —Å Google Charts
        # –ü–æ–∫–∞ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –¥–ª—è MVP
        pass

    def _print_batch_summary(self, results: List[FilterResult]):
        """–í—ã–≤–æ–¥–∏—Ç –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É batch –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        print(f"\n{'='*70}")
        print("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê BATCH –û–ë–†–ê–ë–û–¢–ö–ò")
        print(f"{'='*70}\n")

        total_stats = defaultdict(int)
        for result in results:
            for key, value in result.stats.items():
                total_stats[key] += value

        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(results)}")
        print(f"üìß –í—Å–µ–≥–æ email –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_stats['total_input']}")
        print(f"\nüéØ –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        print(f"   üî• High priority:   {total_stats['high_priority']}")
        print(f"   ‚≠ê Medium priority: {total_stats['medium_priority']}")
        print(f"   üí° Low priority:    {total_stats['low_priority']}")
        print(f"   ‚ùå Excluded:        {total_stats['hard_excluded'] + total_stats['excluded']}")
        print(f"\n‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_stats['processing_time']:.2f} —Å–µ–∫")
        print(f"‚úÖ Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞\n")


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("Usage: python3 smart_filter_processor.py <clean_file_path> [filter_name]")
        print("\nExample:")
        print("  python3 smart_filter_processor.py output/list_clean_20251010.txt italy_hydraulics")
        sys.exit(1)

    clean_file = Path(sys.argv[1])
    filter_name = sys.argv[2] if len(sys.argv) > 2 else 'italy_hydraulics'

    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    processor = SmartFilterProcessor(filter_name=filter_name)

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª
    result = processor.process_clean_file(clean_file)

    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print("\n" + "="*70)
    print("üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print("="*70)
    for key, value in result.get_statistics().items():
        print(f"   {key}: {value}")
