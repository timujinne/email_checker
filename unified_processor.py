#!/usr/bin/env python3
"""
Unified Processor - –Ω–æ–≤–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è check_all_incremental —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è –∑–∞–º–µ–Ω—ã
–¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–¥–∞ –≤ email_checker.py
"""

from pathlib import Path
from typing import List, Optional
from email_processor import EmailProcessor, BatchResult
from metadata_store import MetadataStore
from cache_manager import CacheManager
from progress_tracker import ProgressTracker, ConsoleProgressDisplay


class UnifiedEmailProcessor:
    """
    –í—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ email —Å–ø–∏—Å–∫–æ–≤

    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –Ω–æ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≤ –µ–¥–∏–Ω—ã–π workflow
    """

    def __init__(self, base_dir: str = "."):
        """
        Args:
            base_dir: –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞
        """
        self.base_dir = Path(base_dir)
        self.input_dir = self.base_dir / "input"
        self.output_dir = self.base_dir / "output"

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.cache_manager = CacheManager(str(self.base_dir / ".cache"))
        self.metadata_store = MetadataStore(str(self.base_dir / ".cache" / "metadata_store.db"))

        # EmailChecker –¥–ª—è –±–∞–∑–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∑–¥–µ—Å—å —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        from email_checker import EmailChecker
        self.checker = EmailChecker(str(self.base_dir))

        # –ü—Ä–æ—Ü–µ—Å—Å–æ—Ä
        self.processor = EmailProcessor(self.checker, self.metadata_store)

        # Progress tracking
        self.progress_tracker: Optional[ProgressTracker] = None

    def process_all_incremental(self,
                               exclude_duplicates: bool = False,
                               generate_html: bool = False,
                               show_progress: bool = True) -> BatchResult:
        """
        Unified incremental –æ–±—Ä–∞–±–æ—Ç–∫–∞ –í–°–ï–• —Ñ–∞–π–ª–æ–≤ (TXT + LVP)

        –≠—Ç–æ –Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è check_all_incremental() —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏:
        - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
        - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —Ñ–æ—Ä–º–∞—Ç–∞–º–∏
        - Progress tracking
        - –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ

        Args:
            exclude_duplicates: –ò—Å–∫–ª—é—á–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏
            generate_html: –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å HTML –æ—Ç—á–µ—Ç
            show_progress: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ –∫–æ–Ω—Å–æ–ª–∏

        Returns:
            BatchResult —Å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        """
        print(f"\n{'='*60}")
        print("üì¶ UNIFIED INCREMENTAL PROCESSING")
        print(f"{'='*60}\n")

        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ñ–∞–π–ª—ã
        txt_files = list(self.input_dir.glob("*.txt"))
        lvp_files = list(self.input_dir.glob("*.lvp"))
        all_files = txt_files + lvp_files

        if not all_files:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –ø–∞–ø–∫–µ input/")
            return BatchResult()

        print(f"üìã –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(txt_files)} TXT + {len(lvp_files)} LVP = {len(all_files)} –≤—Å–µ–≥–æ")

        # –§–∏–ª—å—Ç—Ä—É–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (–ø–æ MD5 —Ö–µ—à—É)
        files_to_process = []
        files_from_cache = []

        for file_path in all_files:
            if self.cache_manager.is_file_processed(file_path):
                files_from_cache.append(file_path)
            else:
                files_to_process.append(file_path)

        if files_from_cache:
            print(f"‚úì –ù–∞–π–¥–µ–Ω–æ –≤ –∫–µ—à–µ: {len(files_from_cache)} —Ñ–∞–π–ª–æ–≤ (–ø—Ä–æ–ø—É—Å–∫–∞–µ–º)")

        if not files_to_process:
            print("\nüéâ –í—Å–µ —Ñ–∞–π–ª—ã —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã! –ò–∑–º–µ–Ω–µ–Ω–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.")

            if generate_html:
                self._generate_html_report_from_cache()

            return BatchResult()

        print(f"üîÑ –ö –æ–±—Ä–∞–±–æ—Ç–∫–µ: {len(files_to_process)} —Ñ–∞–π–ª–æ–≤")

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º: —Å–Ω–∞—á–∞–ª–∞ LVP (—á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ), –ø–æ—Ç–æ–º TXT
        lvp_to_process = [f for f in files_to_process if f.suffix.lower() == '.lvp']
        txt_to_process = [f for f in files_to_process if f.suffix.lower() == '.txt']
        files_to_process = lvp_to_process + txt_to_process

        print(f"   üìÑ LVP: {len(lvp_to_process)} (–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –ø–µ—Ä–≤—ã–º–∏)")
        print(f"   üìù TXT: {len(txt_to_process)} (–±—É–¥—É—Ç –æ–±–æ–≥–∞—â–µ–Ω—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–∑ LVP)")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è progress tracker
        if show_progress:
            self.progress_tracker = ProgressTracker(total_files=len(files_to_process))
            display = ConsoleProgressDisplay(self.progress_tracker)
            display.start()
            self.progress_tracker.start()

            # –ü–æ–¥–∫–ª—é—á–∞–µ–º callbacks
            self.processor.set_progress_callback(self._on_file_progress)

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã
        batch_result = self.processor.process_batch(
            files=files_to_process,
            exclude_duplicates=exclude_duplicates,
            enrich_from_store=True  # –í–ê–ñ–ù–û: –æ–±–æ–≥–∞—â–∞–µ–º TXT –∏–∑ MetadataStore
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –∫–µ—à
        for result in batch_result.results:
            if result.success:
                self.cache_manager.save_processing_result(result)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—ã—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã
                self._save_output_files(result)

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                self._update_list_config(result.file_path.name, processed=True)

        if self.progress_tracker:
            self.progress_tracker.finish()
            print(self.progress_tracker.get_summary())

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML –æ—Ç—á–µ—Ç–∞
        if generate_html:
            self._generate_html_report(batch_result)

        # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self._print_summary(batch_result)

        return batch_result

    def _on_file_progress(self, filename: str, progress: float):
        """Callback –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞"""
        if self.progress_tracker:
            if progress == 0.0:
                # –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞
                self.progress_tracker.start_file(filename)
            elif progress == 1.0:
                # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞
                self.progress_tracker.complete_file(success=True)

    def _save_output_files(self, result):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—ã—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã –Ω–∞ –¥–∏—Å–∫"""
        from datetime import datetime

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename_base = f"{result.file_path.stem}_{timestamp}"

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        categories = {
            'clean': result.clean_emails,
            'blocked_email': result.blocked_email,
            'blocked_domain': result.blocked_domain,
            'invalid': result.invalid_emails
        }

        for category, emails in categories.items():
            if emails:
                output_file = self.output_dir / f"{filename_base}_{category}.txt"
                with open(output_file, 'w', encoding='utf-8') as f:
                    for email in emails:
                        f.write(f"{email}\n")

        # –ï—Å–ª–∏ –µ—Å—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON/CSV
        if result.has_metadata and result.emails_with_metadata:
            self._save_metadata_files(filename_base, result.emails_with_metadata)

    def _save_metadata_files(self, filename_base: str, emails_with_metadata: List):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ JSON –∏ CSV —Ñ–æ—Ä–º–∞—Ç–∞—Ö"""
        import json
        import csv

        # JSON
        json_file = self.output_dir / f"{filename_base}_metadata.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            data = [obj.to_dict() for obj in emails_with_metadata]
            json.dump(data, f, ensure_ascii=False, indent=2)

        # CSV
        csv_file = self.output_dir / f"{filename_base}_metadata.csv"
        with open(csv_file, 'w', encoding='utf-8', newline='') as f:
            if emails_with_metadata:
                writer = csv.DictWriter(f, fieldnames=emails_with_metadata[0].to_dict().keys())
                writer.writeheader()
                for obj in emails_with_metadata:
                    writer.writerow(obj.to_dict())

    def _update_list_config(self, filename: str, processed: bool):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ lists_config.json"""
        import json

        config_file = self.base_dir / "lists_config.json"

        if not config_file.exists():
            return

        with open(config_file, 'r', encoding='utf-8') as f:
            config = json.load(f)

        # –ù–∞—Ö–æ–¥–∏–º –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å
        for item in config.get('lists', []):
            if item['filename'] == filename:
                item['processed'] = processed
                break

        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)

    def _generate_html_report(self, batch_result: BatchResult):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç HTML –æ—Ç—á–µ—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å EmailChecker
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ checker.all_results
        for result in batch_result.results:
            if result.success:
                result_data = {
                    'filename': result.file_path.stem,
                    'stats': result.get_statistics(),
                    'results': {
                        'clean': result.clean_emails,
                        'blocked_email': result.blocked_email,
                        'blocked_domain': result.blocked_domain,
                        'invalid': result.invalid_emails
                    },
                    'duplicates_removed': result.duplicates_removed,
                    'prefix_duplicates_removed': result.prefix_duplicates_removed,
                    'timestamp': result.timestamp
                }
                self.checker.all_results.append(result_data)

        self.checker.generate_html_report("unified_report")

    def _generate_html_report_from_cache(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç HTML –æ—Ç—á–µ—Ç –∏–∑ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–µ—à –≤ legacy —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        legacy_cache_file = self.base_dir / ".cache" / "legacy_export.json"
        self.cache_manager.export_legacy_format(legacy_cache_file)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ checker
        import json
        with open(legacy_cache_file, 'r', encoding='utf-8') as f:
            cache_data = json.load(f)

        for filename, file_data in cache_data.items():
            self.checker.all_results.append(file_data['result_data'])

        self.checker.generate_html_report("unified_report")

    def _print_summary(self, batch_result: BatchResult):
        """–í—ã–≤–æ–¥–∏—Ç –∏—Ç–æ–≥–æ–≤—É—é —Å–≤–æ–¥–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        stats = batch_result.get_aggregated_stats()

        print(f"\n{'='*60}")
        print("üéâ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
        print(f"{'='*60}")
        print(f"üìÅ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {stats['successful_files']}/{stats['total_files']}")

        if stats['failed_files'] > 0:
            print(f"‚ùå –û—à–∏–±–æ–∫: {stats['failed_files']}")

        print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê EMAIL:")
        print(f"   –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ: {stats.get('total_checked', 0):,}")
        print(f"   ‚úÖ –ß–∏—Å—Ç—ã–µ: {stats.get('clean', 0):,}")
        print(f"   üö´ –ë–ª–æ–∫ email: {stats.get('blocked_email', 0):,}")
        print(f"   üö´ –ë–ª–æ–∫ –¥–æ–º–µ–Ω: {stats.get('blocked_domain', 0):,}")
        print(f"   ‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ: {stats.get('invalid', 0):,}")

        if stats.get('duplicates_removed', 0) > 0:
            print(f"\nüóëÔ∏è  –î—É–±–ª–∏–∫–∞—Ç—ã –∏—Å–∫–ª—é—á–µ–Ω—ã: {stats['duplicates_removed']:,}")

        if stats.get('prefix_duplicates_removed', 0) > 0:
            print(f"üßπ –ü—Ä–µ—Ñ–∏–∫—Å–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã: {stats['prefix_duplicates_removed']:,}")

        if stats.get('has_metadata', 0) > 0:
            print(f"\nüíé –§–∞–π–ª–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏: {stats['has_metadata']}")

        print(f"\n‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {stats['total_processing_time']:.2f} —Å–µ–∫")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ MetadataStore
        metadata_stats = self.metadata_store.get_statistics()
        if metadata_stats['total_emails'] > 0:
            print(f"\nüíæ –•–†–ê–ù–ò–õ–ò–©–ï –ú–ï–¢–ê–î–ê–ù–ù–´–•:")
            print(f"   –í—Å–µ–≥–æ email: {metadata_stats['total_emails']:,}")
            print(f"   –° –∫–æ–º–ø–∞–Ω–∏–µ–π: {metadata_stats['with_company_name']:,}")
            print(f"   –° —Ç–µ–ª–µ—Ñ–æ–Ω–æ–º: {metadata_stats['with_phone']:,}")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–µ—à–∞
        cache_stats = self.cache_manager.get_all_statistics()
        print(f"\nüíø –ö–ï–®–ò–†–û–í–ê–ù–ò–ï:")
        print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {cache_stats['total_files']}")
        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö email: {cache_stats['total_unique_emails']:,}")
        print(f"   –†–∞–∑–º–µ—Ä –ë–î: {cache_stats['database_size_mb']:.2f} MB")


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    import sys

    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    processor = UnifiedEmailProcessor()

    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
    result = processor.process_all_incremental(
        exclude_duplicates=True,
        generate_html=True,
        show_progress=True
    )

    # –ö–æ–¥ –≤–æ–∑–≤—Ä–∞—Ç–∞ –¥–ª—è CI/CD
    sys.exit(0 if result.failed_files == 0 else 1)
