#!/usr/bin/env python3
"""
–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–æ–º–µ–Ω–æ–≤ –∏–∑ –î–í–£–• –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤:
1. processing_cache_final.db (491K email) - –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–º–µ–Ω—ã –∏–∑ email –∞–¥—Ä–µ—Å–æ–≤
2. metadata.db (–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ) - –±–µ—Ä—ë–º –¥–æ–º–µ–Ω—ã –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ domain

–û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è
"""

import sqlite3
from pathlib import Path
from typing import Set, Dict

# –°–ø–∏—Å–æ–∫ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö email-–ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
COMMON_EMAIL_PROVIDERS = {
    # –ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ
    'gmail.com', 'googlemail.com', 'outlook.com', 'hotmail.com', 'live.com',
    'yahoo.com', 'yahoo.de', 'yahoo.fr', 'yahoo.co.uk', 'yahoo.it',
    'aol.com', 'icloud.com', 'protonmail.com', 'zoho.com',
    'gmx.com', 'gmx.net', 'gmx.de', 'web.de', 'fastmail.com', 'tutanota.com',
    'me.com', 'mac.com', 'msn.com', 't-online.de', 'freenet.de',
    'orange.fr', 'free.fr', 'laposte.net', 'wanadoo.fr', 'sfr.fr',
    'libero.it', 'virgilio.it', 'alice.it', 'tim.it', 'tiscali.it',
    'interia.pl', 'o2.pl', 'wp.pl', 'onet.pl', 'gazeta.pl',
    'seznam.cz', 'centrum.cz', 'email.cz', 'post.cz',
    'bluewin.ch', 'sunrise.ch', 'hispeed.ch',
    'qq.com', '163.com', '126.com', 'sina.com',

    # –†–æ—Å—Å–∏–π—Å–∫–∏–µ –∏ –°–ù–ì
    'mail.ru', 'yandex.ru', 'ya.ru', 'yandex.com', 'yandex.kz', 'yandex.by',
    'bk.ru', 'inbox.ru', 'list.ru', 'internet.ru', 'rambler.ru',
    'yandex.ua',

    # –ë–µ–ª–∞—Ä—É—Å—å
    'tut.by', 'mail.by',

    # –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω
    'mail.kz', 'inbox.kz',

    # –£–∫—Ä–∞–∏–Ω–∞
    'ukr.net', 'i.ua', 'meta.ua', 'bigmir.net', 'email.ua'
}

# –†—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–µ –¥–æ–º–µ–Ω–Ω—ã–µ –∑–æ–Ω—ã
RUSSIAN_SPEAKING_ZONES = {
    '.ru', '.—Ä—Ñ', '.su',
    '.by', '.–±–µ–ª',
    '.kz', '.“õ–∞–∑',
    '.kg'
}

# –£–∫—Ä–∞–∏–Ω—Å–∫–∏–µ –¥–æ–º–µ–Ω–Ω—ã–µ –∑–æ–Ω—ã (–∏—Å–∫–ª—é—á–∞—Ç—å)
UKRAINIAN_ZONES = {
    '.ua', '.—É–∫—Ä'
}


def extract_domain_from_email(email: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–æ–º–µ–Ω –∏–∑ email –∞–¥—Ä–µ—Å–∞"""
    try:
        parts = email.lower().strip().split('@')
        if len(parts) == 2:
            return parts[1]
    except:
        pass
    return ""


def extract_domains_from_cache(db_path: str = ".cache/processing_cache_final.db") -> Set[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–æ–º–µ–Ω—ã –∏–∑ email –∞–¥—Ä–µ—Å–æ–≤ –≤ –∫–µ—à–µ"""
    db_file = Path(db_path)
    if not db_file.exists():
        print(f"‚ö†Ô∏è  –ë–∞–∑–∞ –∫–µ—à–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {db_path}")
        return set()

    print(f"\nüìÇ –ò–°–¢–û–ß–ù–ò–ö 1: –ë–∞–∑–∞ –∫–µ—à–∞ ({db_path})")
    print(f"   –†–∞–∑–º–µ—Ä: {db_file.stat().st_size / (1024*1024):.2f} MB")

    conn = sqlite3.connect(str(db_file))
    cursor = conn.cursor()

    cursor.execute("SELECT COUNT(*) FROM processed_emails")
    total_emails = cursor.fetchone()[0]
    print(f"   Email –∞–¥—Ä–µ—Å–æ–≤: {total_emails:,}")

    print(f"   –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–º–µ–Ω—ã –∏–∑ email...")
    cursor.execute("SELECT DISTINCT email FROM processed_emails")

    domains = set()
    for row in cursor.fetchall():
        domain = extract_domain_from_email(row[0])
        if domain:
            domains.add(domain)

    conn.close()
    print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(domains):,} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤")
    return domains


def extract_domains_from_metadata(db_path: str = "metadata.db") -> Set[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–æ–º–µ–Ω—ã –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ domain –≤ metadata.db"""
    db_file = Path(db_path)
    if not db_file.exists():
        print(f"‚ö†Ô∏è  –ë–∞–∑–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {db_path}")
        return set()

    print(f"\nüìÇ –ò–°–¢–û–ß–ù–ò–ö 2: –ë–∞–∑–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö ({db_path})")
    print(f"   –†–∞–∑–º–µ—Ä: {db_file.stat().st_size / (1024*1024):.2f} MB")

    conn = sqlite3.connect(str(db_file))
    cursor = conn.cursor()

    cursor.execute("SELECT COUNT(*) FROM email_metadata")
    total_rows = cursor.fetchone()[0]
    print(f"   –ó–∞–ø–∏—Å–µ–π —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏: {total_rows:,}")

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–º–µ–Ω—ã –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ domain
    print(f"   –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ 'domain'...")
    cursor.execute("""
        SELECT DISTINCT domain
        FROM email_metadata
        WHERE domain IS NOT NULL AND domain != ''
    """)

    domains_from_column = set()
    for row in cursor.fetchall():
        domain = row[0].lower().strip()
        if domain:
            domains_from_column.add(domain)

    print(f"   ‚úÖ –ò–∑ –∫–æ–ª–æ–Ω–∫–∏ 'domain': {len(domains_from_column):,} –¥–æ–º–µ–Ω–æ–≤")

    # –¢–∞–∫–∂–µ –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–º–µ–Ω—ã –∏–∑ email –∞–¥—Ä–µ—Å–æ–≤ (–Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ domain –ø—É—Å—Ç–æ–π)
    print(f"   –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ 'email'...")
    cursor.execute("""
        SELECT DISTINCT email
        FROM email_metadata
        WHERE email IS NOT NULL AND email != ''
    """)

    domains_from_email = set()
    for row in cursor.fetchall():
        domain = extract_domain_from_email(row[0])
        if domain:
            domains_from_email.add(domain)

    print(f"   ‚úÖ –ò–∑ –∫–æ–ª–æ–Ω–∫–∏ 'email': {len(domains_from_email):,} –¥–æ–º–µ–Ω–æ–≤")

    conn.close()

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–æ–º–µ–Ω—ã –∏–∑ –æ–±–µ–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
    all_domains = domains_from_column | domains_from_email
    print(f"   üìä –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {len(all_domains):,} –¥–æ–º–µ–Ω–æ–≤")

    return all_domains


def filter_russian_speaking_domains(domains: Set[str]) -> Set[str]:
    """–§–∏–ª—å—Ç—Ä—É–µ—Ç –¥–æ–º–µ–Ω—ã, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –∏–∑ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö —Å—Ç—Ä–∞–Ω"""
    filtered = set()

    for domain in domains:
        domain_lower = domain.lower()

        # –ò—Å–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
        if domain_lower in COMMON_EMAIL_PROVIDERS:
            continue

        # –ò—Å–∫–ª—é—á–∞–µ–º —É–∫—Ä–∞–∏–Ω—Å–∫–∏–µ
        if any(domain_lower.endswith(zone) for zone in UKRAINIAN_ZONES):
            continue

        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–µ
        if any(domain_lower.endswith(zone) for zone in RUSSIAN_SPEAKING_ZONES):
            filtered.add(domain)

    return filtered


def get_domain_statistics(domains: Set[str]) -> Dict[str, int]:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–æ–º–µ–Ω–Ω—ã–º –∑–æ–Ω–∞–º"""
    stats = {}
    for domain in domains:
        domain_lower = domain.lower()
        for zone in RUSSIAN_SPEAKING_ZONES:
            if domain_lower.endswith(zone):
                stats[zone] = stats.get(zone, 0) + 1
                break
    return stats


def save_domains(domains: Set[str], base_filename: str):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–æ–º–µ–Ω—ã –≤ —Ñ–∞–π–ª—ã"""
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)

    # –û–±—â–∏–π —Ñ–∞–π–ª
    output_file = output_dir / f"{base_filename}.txt"
    sorted_domains = sorted(domains)

    with open(output_file, 'w', encoding='utf-8') as f:
        for domain in sorted_domains:
            f.write(f"{domain}\n")

    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {output_file}")
    print(f"   –í—Å–µ–≥–æ –¥–æ–º–µ–Ω–æ–≤: {len(domains):,}")

    # –ü–æ –∑–æ–Ω–∞–º
    zones_dir = output_dir / f"{base_filename}_by_zone"
    zones_dir.mkdir(exist_ok=True)

    zones = {}
    for domain in domains:
        for zone in RUSSIAN_SPEAKING_ZONES:
            if domain.lower().endswith(zone):
                zone_name = zone.lstrip('.')
                if zone_name not in zones:
                    zones[zone_name] = []
                zones[zone_name].append(domain)
                break

    print(f"\nüìÅ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –ø–æ –∑–æ–Ω–∞–º –≤: {zones_dir}/")
    for zone, zone_domains in sorted(zones.items(), key=lambda x: len(x[1]), reverse=True):
        zone_file = zones_dir / f"domains_{zone}.txt"
        with open(zone_file, 'w', encoding='utf-8') as f:
            for domain in sorted(zone_domains):
                f.write(f"{domain}\n")
        print(f"   ‚Ä¢ {zone_file.name}: {len(zone_domains):,} –¥–æ–º–µ–Ω–æ–≤")


def main():
    print("=" * 80)
    print("üåç –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –î–û–ú–ï–ù–û–í –ò–ó –í–°–ï–• –ò–°–¢–û–ß–ù–ò–ö–û–í")
    print("=" * 80)

    # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ –∫–µ—à–∞ (email –∞–¥—Ä–µ—Å–∞)
    cache_domains = extract_domains_from_cache()

    # 2. –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ metadata (–∫–æ–ª–æ–Ω–∫–∞ domain + email)
    metadata_domains = extract_domains_from_metadata()

    # 3. –û–±—ä–µ–¥–∏–Ω—è–µ–º
    print(f"\nüîó –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í:")
    all_domains = cache_domains | metadata_domains
    print(f"   ‚Ä¢ –ò–∑ –∫–µ—à–∞: {len(cache_domains):,} –¥–æ–º–µ–Ω–æ–≤")
    print(f"   ‚Ä¢ –ò–∑ metadata: {len(metadata_domains):,} –¥–æ–º–µ–Ω–æ–≤")
    print(f"   ‚Ä¢ –û–±—â–∏—Ö: {len(cache_domains & metadata_domains):,} –¥–æ–º–µ–Ω–æ–≤")
    print(f"   ‚Ä¢ –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {len(all_domains):,} –¥–æ–º–µ–Ω–æ–≤")

    # 4. –§–∏–ª—å—Ç—Ä—É–µ–º
    print(f"\nüîß –ü–†–ò–ú–ï–ù–ï–ù–ò–ï –§–ò–õ–¨–¢–†–û–í:")
    print(f"   ‚Ä¢ –ò—Å–∫–ª—é—á–∞–µ–º {len(COMMON_EMAIL_PROVIDERS)} –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤")
    print(f"   ‚Ä¢ –ó–æ–Ω—ã: {', '.join(sorted(RUSSIAN_SPEAKING_ZONES))}")
    print(f"   ‚Ä¢ –ò—Å–∫–ª—é—á–∞–µ–º: {', '.join(sorted(UKRAINIAN_ZONES))}")

    filtered_domains = filter_russian_speaking_domains(all_domains)

    # 5. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    print(f"   ‚Ä¢ –í—Å–µ–≥–æ –¥–æ–º–µ–Ω–æ–≤: {len(all_domains):,}")
    print(f"   ‚Ä¢ –ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(filtered_domains):,}")
    print(f"   ‚Ä¢ –ò—Å–∫–ª—é—á–µ–Ω–æ: {len(all_domains) - len(filtered_domains):,}")

    zone_stats = get_domain_statistics(filtered_domains)
    print(f"\nüìà –ü–æ –¥–æ–º–µ–Ω–Ω—ã–º –∑–æ–Ω–∞–º:")
    for zone, count in sorted(zone_stats.items(), key=lambda x: x[1], reverse=True):
        pct = (count / len(filtered_domains) * 100) if filtered_domains else 0
        print(f"   ‚Ä¢ {zone:8s}: {count:8,d} –¥–æ–º–µ–Ω–æ–≤ ({pct:5.1f}%)")

    # 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º
    save_domains(filtered_domains, "russian_domains_combined")

    print("\n" + "=" * 80)
    print("‚úÖ –ì–û–¢–û–í–û!")
    print("=" * 80)


if __name__ == "__main__":
    main()
