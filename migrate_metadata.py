#!/usr/bin/env python3
"""
–ú–∏–≥—Ä–∞—Ü–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö JSON –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
"""

import json
import os
from pathlib import Path
from datetime import datetime
from metadata_database import MetadataDatabase, EmailMetadata, LVPSource
import hashlib


class MetadataMigrator:
    """–ö–ª–∞—Å—Å –¥–ª—è –º–∏–≥—Ä–∞—Ü–∏–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON —Ñ–∞–π–ª–æ–≤ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""

    def __init__(self, base_dir: str = "."):
        self.base_dir = Path(base_dir)
        self.output_dir = self.base_dir / "output"
        self.db = MetadataDatabase()

    def migrate_all_json_files(self):
        """–ú–∏–≥—Ä–∏—Ä—É–µ—Ç –≤—Å–µ JSON —Ñ–∞–π–ª—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        print("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –º–∏–≥—Ä–∞—Ü–∏—é –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö...")

        if not self.output_dir.exists():
            print("‚ùå –ü–∞–ø–∫–∞ output –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return

        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ JSON —Ñ–∞–π–ª—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        metadata_files = list(self.output_dir.glob("*metadata*.json"))

        if not metadata_files:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ JSON —Ñ–∞–π–ª–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏")
            return

        total_emails = 0
        processed_files = 0
        skipped_emails = 0

        for json_file in metadata_files:
            try:
                print(f"\nüìÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {json_file.name}...")

                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                emails = data.get("emails", [])
                file_emails = 0
                file_skipped = 0

                for email_data in emails:
                    email_address = email_data.get("email", "").strip().lower()

                    if not email_address:
                        file_skipped += 1
                        continue

                    # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç EmailMetadata
                    metadata = EmailMetadata(
                        email=email_address,
                        domain=email_data.get("domain"),
                        source_url=email_data.get("source_url"),
                        page_title=email_data.get("page_title"),
                        company_name=email_data.get("company_name"),
                        phone=email_data.get("phone"),
                        country=email_data.get("country"),
                        city=email_data.get("city"),
                        address=email_data.get("address"),
                        category=email_data.get("category"),
                        keywords=email_data.get("keywords"),
                        meta_description=email_data.get("meta_description"),
                        meta_keywords=email_data.get("meta_keywords"),
                        validation_status=email_data.get("validation_status"),
                        validation_date=email_data.get("validation_date"),
                        validation_log=email_data.get("validation_log"),
                        source_file=json_file.name
                    )

                    # –í—Å—Ç–∞–≤–ª—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
                    if self.db.insert_email_metadata(metadata):
                        file_emails += 1
                    else:
                        file_skipped += 1

                total_emails += file_emails
                skipped_emails += file_skipped
                processed_files += 1

                print(f"‚úÖ –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {file_emails} email –∏–∑ {json_file.name}")
                if file_skipped > 0:
                    print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ {file_skipped} –∑–∞–ø–∏—Å–µ–π")

            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {json_file.name}: {e}")

        print(f"\n{'='*60}")
        print(f"üìä –ò–¢–û–ì–ò –ú–ò–ì–†–ê–¶–ò–ò:")
        print(f"üìÅ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {processed_files}")
        print(f"üìß –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ email: {total_emails:,}")
        print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—â–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {skipped_emails:,}")
        print(f"{'='*60}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        self._show_database_statistics()

    def _show_database_statistics(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –º–∏–≥—Ä–∞—Ü–∏–∏"""
        print("\nüìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ë–ê–ó–´ –î–ê–ù–ù–´–•:")

        stats = self.db.get_statistics()

        print(f"üìß –í—Å–µ–≥–æ email: {stats['total_emails']:,}")
        print(f"üìû –° —Ç–µ–ª–µ—Ñ–æ–Ω–∞–º–∏: {stats['with_phone']:,}")
        print(f"üö´ –ë–µ–∑ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤: {stats['without_phone']:,}")

        print(f"\nüåç –¢–æ–ø —Å—Ç—Ä–∞–Ω—ã:")
        for country, count in list(stats['countries'].items())[:10]:
            print(f"  {country}: {count:,}")

        print(f"\nüè¢ –¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:")
        for category, count in list(stats['categories'].items())[:10]:
            print(f"  {category}: {count:,}")

        print(f"\n‚úÖ –°—Ç–∞—Ç—É—Å—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
        for status, count in stats['validation_statuses'].items():
            status_name = status or "Unknown"
            print(f"  {status_name}: {count:,}")

    def deduplicate_database(self):
        """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö, –æ—Å—Ç–∞–≤–ª—è—è —Å–∞–º—ã–µ –ø–æ–ª–Ω—ã–µ –∑–∞–ø–∏—Å–∏"""
        print("\nüßπ –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤...")

        # SQL –∑–∞–ø—Ä–æ—Å –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤, –æ—Å—Ç–∞–≤–ª—è—è –∑–∞–ø–∏—Å—å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –ø–æ–ª–µ–π
        cursor = self.db.conn.cursor()

        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É —Å –ø–æ–¥—Å—á–µ—Ç–æ–º –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –ø–æ–ª–µ–π
        cursor.execute('''
            CREATE TEMPORARY TABLE temp_email_scores AS
            SELECT
                id,
                email,
                (CASE WHEN domain IS NOT NULL AND domain != '' THEN 1 ELSE 0 END +
                 CASE WHEN source_url IS NOT NULL AND source_url != '' THEN 1 ELSE 0 END +
                 CASE WHEN page_title IS NOT NULL AND page_title != '' THEN 1 ELSE 0 END +
                 CASE WHEN company_name IS NOT NULL AND company_name != '' THEN 1 ELSE 0 END +
                 CASE WHEN phone IS NOT NULL AND phone != '' THEN 1 ELSE 0 END +
                 CASE WHEN country IS NOT NULL AND country != '' THEN 1 ELSE 0 END +
                 CASE WHEN city IS NOT NULL AND city != '' THEN 1 ELSE 0 END +
                 CASE WHEN address IS NOT NULL AND address != '' THEN 1 ELSE 0 END +
                 CASE WHEN category IS NOT NULL AND category != '' THEN 1 ELSE 0 END +
                 CASE WHEN keywords IS NOT NULL AND keywords != '' THEN 1 ELSE 0 END +
                 CASE WHEN meta_description IS NOT NULL AND meta_description != '' THEN 1 ELSE 0 END +
                 CASE WHEN meta_keywords IS NOT NULL AND meta_keywords != '' THEN 1 ELSE 0 END +
                 CASE WHEN validation_status IS NOT NULL AND validation_status != '' THEN 1 ELSE 0 END +
                 CASE WHEN validation_date IS NOT NULL AND validation_date != '' THEN 1 ELSE 0 END
                ) as completeness_score,
                ROW_NUMBER() OVER (PARTITION BY email ORDER BY
                    (CASE WHEN domain IS NOT NULL AND domain != '' THEN 1 ELSE 0 END +
                     CASE WHEN source_url IS NOT NULL AND source_url != '' THEN 1 ELSE 0 END +
                     CASE WHEN page_title IS NOT NULL AND page_title != '' THEN 1 ELSE 0 END +
                     CASE WHEN company_name IS NOT NULL AND company_name != '' THEN 1 ELSE 0 END +
                     CASE WHEN phone IS NOT NULL AND phone != '' THEN 1 ELSE 0 END +
                     CASE WHEN country IS NOT NULL AND country != '' THEN 1 ELSE 0 END +
                     CASE WHEN city IS NOT NULL AND city != '' THEN 1 ELSE 0 END +
                     CASE WHEN address IS NOT NULL AND address != '' THEN 1 ELSE 0 END +
                     CASE WHEN category IS NOT NULL AND category != '' THEN 1 ELSE 0 END +
                     CASE WHEN keywords IS NOT NULL AND keywords != '' THEN 1 ELSE 0 END +
                     CASE WHEN meta_description IS NOT NULL AND meta_description != '' THEN 1 ELSE 0 END +
                     CASE WHEN meta_keywords IS NOT NULL AND meta_keywords != '' THEN 1 ELSE 0 END +
                     CASE WHEN validation_status IS NOT NULL AND validation_status != '' THEN 1 ELSE 0 END +
                     CASE WHEN validation_date IS NOT NULL AND validation_date != '' THEN 1 ELSE 0 END
                    ) DESC, updated_at DESC
                ) as row_num
            FROM email_metadata
        ''')

        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        cursor.execute('''
            SELECT COUNT(*) FROM temp_email_scores WHERE row_num > 1
        ''')
        duplicates_count = cursor.fetchone()[0]

        if duplicates_count > 0:
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã (–æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–∏ —Å row_num = 1)
            cursor.execute('''
                DELETE FROM email_metadata
                WHERE id IN (
                    SELECT id FROM temp_email_scores WHERE row_num > 1
                )
            ''')

            self.db.conn.commit()
            print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω–æ {duplicates_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
        else:
            print("‚úÖ –î—É–±–ª–∏–∫–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
        cursor.execute('DROP TABLE temp_email_scores')

    def optimize_database(self):
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
        print("\n‚ö° –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")

        cursor = self.db.conn.cursor()

        # –ü–µ—Ä–µ—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
        cursor.execute('REINDEX')

        # –°–∂–∏–º–∞–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        cursor.execute('VACUUM')

        self.db.conn.commit()
        print("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")

    def close(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""
        self.db.close()


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –º–∏–≥—Ä–∞—Ü–∏–∏"""
    print("üöÄ –ú–ò–ì–†–ê–¶–ò–Ø –ú–ï–¢–ê–î–ê–ù–ù–´–• –í –ë–ê–ó–£ –î–ê–ù–ù–´–•")
    print("="*50)

    migrator = MetadataMigrator()

    try:
        # –í—ã–ø–æ–ª–Ω—è–µ–º –º–∏–≥—Ä–∞—Ü–∏—é
        migrator.migrate_all_json_files()

        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        migrator.deduplicate_database()

        # –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        migrator.optimize_database()

        print("\nüéâ –ú–∏–≥—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")

    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –º–∏–≥—Ä–∞—Ü–∏–∏: {e}")

    finally:
        migrator.close()


if __name__ == "__main__":
    main()