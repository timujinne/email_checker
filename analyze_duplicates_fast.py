#!/usr/bin/env python3
"""–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""

import sqlite3
import xml.etree.ElementTree as ET
import re
import os
from datetime import datetime

def sanitize_xml(content):
    """–£–¥–∞–ª—è–µ—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ XML-—Å–∏–º–≤–æ–ª—ã"""
    return re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F]', '', content)

def normalize_email(email):
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç email-–∞–¥—Ä–µ—Å"""
    email = email.lower().strip()
    if email.startswith('//'):
        email = email[2:]
    if email.startswith('20'):
        email = email[2:]
    return email

def parse_lvp_file(filepath):
    """–ü–∞—Ä—Å–∏—Ç LVP —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ email-–∞–¥—Ä–µ—Å–æ–≤"""
    emails = []

    try:
        print(f"üìÑ –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª: {filepath}")
        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()

        print("üßπ –°–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏—è XML...")
        content = sanitize_xml(content)

        print("üîç –ü–∞—Ä—Å–∏–Ω–≥ XML...")
        root = ET.fromstring(content)

        # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å email
        namespaces = {
            '': 'http://schemas.datacontract.org/2004/07/Verifier',
            'i': 'http://www.w3.org/2001/XMLSchema-instance'
        }

        email_paths = [
            './/Email',
            './/{http://schemas.datacontract.org/2004/07/Verifier}Email',
            './/ValidatorDataClass.ValidatorDataClassItem/Email'
        ]

        for path in email_paths:
            email_elements = root.findall(path, namespaces)
            if email_elements:
                for elem in email_elements:
                    if elem.text:
                        email = normalize_email(elem.text)
                        if email and '@' in email:
                            emails.append(email)
                break

        print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(emails):,} email-–∞–¥—Ä–µ—Å–æ–≤")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")

    return emails

def load_db_emails(db_path='metadata.db'):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ email –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –≤ set –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞"""

    if not os.path.exists(db_path):
        print(f"‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö {db_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return set()

    print(f"\nüìä –ó–∞–≥—Ä—É–∑–∫–∞ email –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    cursor.execute('SELECT LOWER(email) FROM email_metadata')
    db_emails = set(row[0].lower() for row in cursor.fetchall())

    conn.close()

    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(db_emails):,} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö email –∏–∑ –ë–î")
    return db_emails

def analyze_duplicates(file_emails, db_emails):
    """–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ set intersection"""

    # –£–±–∏—Ä–∞–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–∑ —Ñ–∞–π–ª–∞
    unique_file_emails = set(email.lower() for email in file_emails)
    internal_dups = len(file_emails) - len(unique_file_emails)

    # –ù–∞—Ö–æ–¥–∏–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è —Å –ë–î
    duplicates = unique_file_emails & db_emails
    new_emails = unique_file_emails - db_emails

    return {
        'total': len(file_emails),
        'unique': len(unique_file_emails),
        'internal_duplicates': internal_dups,
        'db_duplicates': len(duplicates),
        'new_emails': len(new_emails),
        'duplicates_list': sorted(duplicates),
        'new_emails_list': sorted(new_emails)
    }

def main():
    lvp_file = 'input/Germany HC 10.11.2025.lvp'

    print("="*70)
    print("üìã –ë–´–°–¢–†–´–ô –ê–ù–ê–õ–ò–ó –î–£–ë–õ–ò–ö–ê–¢–û–í –í LVP –§–ê–ô–õ–ï")
    print("="*70)
    print(f"\n–§–∞–π–ª: {lvp_file}\n")

    # –®–∞–≥ 1: –ü–∞—Ä—Å–∏–º LVP —Ñ–∞–π–ª
    print("1Ô∏è‚É£ –ü–∞—Ä—Å–∏–Ω–≥ LVP —Ñ–∞–π–ª–∞...")
    emails = parse_lvp_file(lvp_file)

    if not emails:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å email –∏–∑ —Ñ–∞–π–ª–∞")
        return

    # –®–∞–≥ 2: –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ email –∏–∑ –ë–î –≤ –ø–∞–º—è—Ç—å (–±—ã—Å—Ç—Ä–æ!)
    print("\n2Ô∏è‚É£ –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
    db_emails = load_db_emails()

    if not db_emails:
        print("‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return

    # –®–∞–≥ 3: –ë—ã—Å—Ç—Ä–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ set operations
    print("\n3Ô∏è‚É£ –ê–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (–±—ã—Å—Ç—Ä–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ)...")
    results = analyze_duplicates(emails, db_emails)

    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "="*70)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê")
    print("="*70)

    print(f"\nüì¶ –§–∞–π–ª Germany HC 10.11.2025.lvp:")
    print(f"  ‚Ä¢ –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {results['total']:,}")
    print(f"  ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö email: {results['unique']:,}")
    print(f"  ‚Ä¢ –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {results['internal_duplicates']:,}")

    print(f"\nüîç –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö ({len(db_emails):,} email):")
    print(f"  ‚Ä¢ ‚úÖ –ù–æ–≤—ã—Ö email (–ù–ï –≤ –ë–î): {results['new_emails']:,} ({results['new_emails']/results['unique']*100:.1f}%)")
    print(f"  ‚Ä¢ üîÑ –î—É–±–ª–∏–∫–∞—Ç–æ–≤ (–£–ñ–ï –≤ –ë–î): {results['db_duplicates']:,} ({results['db_duplicates']/results['unique']*100:.1f}%)")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

    if results['duplicates_list']:
        dup_file = f'output/Germany_HC_duplicates_{timestamp}.txt'
        with open(dup_file, 'w', encoding='utf-8') as f:
            f.write(f"–î—É–±–ª–∏–∫–∞—Ç—ã –∏–∑ —Ñ–∞–π–ª–∞ Germany HC 10.11.2025.lvp\n")
            f.write(f"–í—Å–µ–≥–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(results['duplicates_list']):,}\n")
            f.write(f"–î–∞—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("="*70 + "\n\n")
            for email in results['duplicates_list']:
                f.write(f"{email}\n")

        print(f"\nüíæ –°–ø–∏—Å–æ–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {dup_file}")

    if results['new_emails_list']:
        new_file = f'output/Germany_HC_new_emails_{timestamp}.txt'
        with open(new_file, 'w', encoding='utf-8') as f:
            f.write(f"–ù–æ–≤—ã–µ email –∏–∑ —Ñ–∞–π–ª–∞ Germany HC 10.11.2025.lvp\n")
            f.write(f"–í—Å–µ–≥–æ –Ω–æ–≤—ã—Ö: {len(results['new_emails_list']):,}\n")
            f.write(f"–î–∞—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("="*70 + "\n\n")
            for email in results['new_emails_list']:
                f.write(f"{email}\n")

        print(f"üíæ –°–ø–∏—Å–æ–∫ –Ω–æ–≤—ã—Ö email —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {new_file}")

    print("\n" + "="*70)
    print("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print("="*70)

if __name__ == '__main__':
    main()
