#!/usr/bin/env python3
"""
Email Metadata Classes - —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± email
"""

import json
import xml.etree.ElementTree as ET
from dataclasses import dataclass, asdict
from typing import Dict, List, Optional, Any
from datetime import datetime
from pathlib import Path


@dataclass
class EmailWithMetadata:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è email —Å –ø–æ–ª–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏"""

    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è
    email: str

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–µ
    source_url: Optional[str] = None
    domain: Optional[str] = None
    page_title: Optional[str] = None
    meta_description: Optional[str] = None
    meta_keywords: Optional[str] = None

    # –ö–æ–Ω—Ç–∞–∫—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    company_name: Optional[str] = None
    phone: Optional[str] = None
    country: Optional[str] = None
    city: Optional[str] = None
    address: Optional[str] = None

    # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è
    category: Optional[str] = None
    keywords: Optional[str] = None

    # –í–∞–ª–∏–¥–∞—Ü–∏—è (–∏–∑ LVP)
    validation_status: Optional[str] = None
    validation_log: Optional[str] = None
    validation_date: Optional[str] = None

    # –°–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è
    found_date: Optional[str] = None
    id: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å"""
        return asdict(self)

    def to_json(self) -> str:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ JSON"""
        return json.dumps(self.to_dict(), ensure_ascii=False, indent=2)

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'EmailWithMetadata':
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–∑ —Å–ª–æ–≤–∞—Ä—è"""
        return cls(**data)

    @classmethod
    def from_simple_email(cls, email: str) -> 'EmailWithMetadata':
        """–°–æ–∑–¥–∞–Ω–∏–µ –∏–∑ –ø—Ä–æ—Å—Ç–æ–≥–æ email —Å—Ç—Ä–æ–∫–∏ (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
        return cls(email=email)


class LVPParser:
    """–ü–∞—Ä—Å–µ—Ä –¥–ª—è LVP (XML) —Ñ–∞–π–ª–æ–≤ –æ—Ç —Å–∏—Å—Ç–µ–º—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ email"""

    def __init__(self):
        self.namespace = {
            '': 'http://schemas.datacontract.org/2004/07/Verifier',
            'i': 'http://www.w3.org/2001/XMLSchema-instance',
            'a': 'http://schemas.microsoft.com/2003/10/Serialization/Arrays'
        }

    def parse_file(self, filepath: str) -> List[EmailWithMetadata]:
        """–ü–∞—Ä—Å–∏—Ç LVP —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ EmailWithMetadata"""
        emails = []

        try:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –æ–±—ã—á–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
            try:
                tree = ET.parse(filepath)
                root = tree.getroot()
            except ET.ParseError as e:
                if "reference to invalid character number" in str(e):
                    print(f"‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ XML, –≤—ã–ø–æ–ª–Ω—è–µ–º –æ—á–∏—Å—Ç–∫—É...")
                    # –ü—Ä–æ–±—É–µ–º –æ—á–∏—Å—Ç–∏—Ç—å —Ñ–∞–π–ª –∏ –ø–∞—Ä—Å–∏—Ç—å –∑–∞–Ω–æ–≤–æ
                    cleaned_content = self._sanitize_xml_file(filepath)
                    root = ET.fromstring(cleaned_content)
                else:
                    raise  # –ï—Å–ª–∏ —ç—Ç–æ –¥—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞, –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –¥–∞–ª—å—à–µ

            print(f"üîç Root tag: {root.tag}")
            print(f"üîç Root namespace: {root.attrib}")

            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ–∏—Å–∫–∞ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            items_variants = [
                root.findall('.//ValidatorDataClass.ValidatorDataClassItem'),
                root.findall('.//{http://schemas.datacontract.org/2004/07/Verifier}ValidatorDataClass.ValidatorDataClassItem'),
                root.findall('.//Items/ValidatorDataClass.ValidatorDataClassItem'),
                root.findall('.//{http://schemas.datacontract.org/2004/07/Verifier}Items/{http://schemas.datacontract.org/2004/07/Verifier}ValidatorDataClass.ValidatorDataClassItem')
            ]

            items = []
            for variant in items_variants:
                if variant:
                    items = variant
                    print(f"‚úì –ù–∞–π–¥–µ–Ω–æ {len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
                    break

            if not items:
                print("‚ö†Ô∏è  –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –≤—Å–µ –¥–æ—á–µ—Ä–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã...")
                all_children = list(root.iter())
                print(f"üîç –í—Å–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ XML: {len(all_children)}")
                for i, child in enumerate(all_children[:10]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                    print(f"  {i}: {child.tag}")

            for item in items:
                email_data = self._parse_item(item)
                if email_data:
                    emails.append(email_data)

            print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(emails)} email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–∑ {filepath}")

        except ET.ParseError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ XML —Ñ–∞–π–ª–∞ {filepath}: {e}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {filepath}: {e}")

        return emails

    def _sanitize_xml_file(self, filepath: str) -> str:
        """–û—á–∏—â–∞–µ—Ç XML —Ñ–∞–π–ª –æ—Ç –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        print(f"üßπ –û—á–∏—Å—Ç–∫–∞ XML —Ñ–∞–π–ª–∞ –æ—Ç –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤...")

        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª –∫–∞–∫ —Ç–µ–∫—Å—Ç
        with open(filepath, 'r', encoding='utf-8', errors='replace') as f:
            content = f.read()

        # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        invalid_chars = [
            '&#xFFFF;', '&#xFFFE;',  # –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
            '&#x0;', '&#x1;', '&#x2;', '&#x3;', '&#x4;', '&#x5;', '&#x6;', '&#x7;', '&#x8;',
            '&#xB;', '&#xC;', '&#xE;', '&#xF;', '&#x10;', '&#x11;', '&#x12;', '&#x13;',
            '&#x14;', '&#x15;', '&#x16;', '&#x17;', '&#x18;', '&#x19;', '&#x1A;', '&#x1B;',
            '&#x1C;', '&#x1D;', '&#x1E;', '&#x1F;'  # –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        ]

        removed_count = 0
        for invalid_char in invalid_chars:
            if invalid_char in content:
                removed_count += content.count(invalid_char)
                content = content.replace(invalid_char, '')  # –£–¥–∞–ª—è–µ–º –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã

        if removed_count > 0:
            print(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {removed_count} –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ XML")

        return content

    def _parse_item(self, item: ET.Element) -> Optional[EmailWithMetadata]:
        """–ü–∞—Ä—Å–∏—Ç –æ–¥–∏–Ω —ç–ª–µ–º–µ–Ω—Ç ValidatorDataClassItem"""
        try:
            ns = '{http://schemas.datacontract.org/2004/07/Verifier}'

            # –û—Å–Ω–æ–≤–Ω–æ–π email
            email_elem = item.find(f'{ns}Email')
            if email_elem is None or not email_elem.text:
                print(f"‚ö†Ô∏è  Email –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —ç–ª–µ–º–µ–Ω—Ç–µ: {item.tag}")
                return None

            email = email_elem.text.strip().lower()

            # ID
            id_elem = item.find(f'{ns}ID')
            item_id = id_elem.text if id_elem is not None else None

            # –°—Ç–∞—Ç—É—Å –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            status_elem = item.find(f'{ns}Status')
            validation_status = status_elem.text if status_elem is not None else None

            # –ú–∞–ø–ø–∏–Ω–≥ —Ü–∏—Ñ—Ä–æ–≤—ã—Ö —Å—Ç–∞—Ç—É—Å–æ–≤ –≤ —Å—Ç—Ä–æ–∫–æ–≤—ã–µ
            if validation_status and validation_status.isdigit():
                status_map = {
                    '0': 'Valid',
                    '1': 'NotSure',
                    '2': 'Invalid',
                    '3': 'NotChecked',
                    '4': 'Temp'
                }
                validation_status = status_map.get(validation_status, validation_status)

            # –õ–æ–≥ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            log_elem = item.find(f'{ns}Log')
            validation_log = log_elem.text if log_elem is not None else None

            # –ü–∞—Ä—Å–∏–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ _Data —Å–µ–∫—Ü–∏–∏
            data_dict = self._parse_data_section(item)

            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç EmailWithMetadata
            email_obj = EmailWithMetadata(
                email=email,
                id=item_id,
                validation_status=validation_status,
                validation_log=validation_log,
                validation_date=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),

                # –î–∞–Ω–Ω—ã–µ –∏–∑ _Data —Å–µ–∫—Ü–∏–∏
                phone=data_dict.get('Column_Phone2'),
                company_name=data_dict.get('Column_Name'),
                source_url=data_dict.get('Column_Source'),
                keywords=data_dict.get('Column_Keywords'),
                page_title=data_dict.get('Column_Title'),
                meta_description=data_dict.get('Column_METADescription'),
                meta_keywords=data_dict.get('Column_METAKeywords'),
                domain=data_dict.get('Column_Domain'),
                country=data_dict.get('Column_Country'),
                city=data_dict.get('Column_City'),
                address=data_dict.get('Column_Address'),
                category=data_dict.get('Column_Category')
            )

            return email_obj

        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —ç–ª–µ–º–µ–Ω—Ç–∞: {e}")
            return None

    def _parse_data_section(self, item: ET.Element) -> Dict[str, str]:
        """–ü–∞—Ä—Å–∏—Ç —Å–µ–∫—Ü–∏—é _Data —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø–æ–ª—è–º–∏"""
        data_dict = {}

        ns = '{http://schemas.datacontract.org/2004/07/Verifier}'
        a_ns = '{http://schemas.microsoft.com/2003/10/Serialization/Arrays}'

        # –ù–∞—Ö–æ–¥–∏–º —Å–µ–∫—Ü–∏—é _Data
        data_section = item.find(f'{ns}_Data')
        if data_section is None:
            return data_dict

        # –ü–∞—Ä—Å–∏–º –≤—Å–µ KeyValueOfstringstring —ç–ª–µ–º–µ–Ω—Ç—ã
        for kv_pair in data_section.findall(f'.//{a_ns}KeyValueOfstringstring'):
            key_elem = kv_pair.find(f'{a_ns}Key')
            value_elem = kv_pair.find(f'{a_ns}Value')

            if key_elem is not None and value_elem is not None:
                key = key_elem.text
                value = value_elem.text if value_elem.text else ""

                if key and value.strip():
                    data_dict[key] = value.strip()

        return data_dict


class EmailMetadataManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ñ–æ—Ä–º–∞—Ç–∞–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö email"""

    def __init__(self, base_dir: str = "."):
        self.base_dir = Path(base_dir)
        self.lvp_parser = LVPParser()

    def load_emails_from_file(self, filepath: str) -> List[EmailWithMetadata]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç email –∏–∑ —Ñ–∞–π–ª–∞, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è—è —Ñ–æ—Ä–º–∞—Ç"""
        filepath = Path(filepath)

        if not filepath.exists():
            print(f"‚ùå –§–∞–π–ª {filepath} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return []

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é
        if filepath.suffix.lower() == '.lvp':
            return self._load_from_lvp(str(filepath))
        elif filepath.suffix.lower() == '.json':
            return self._load_from_json(str(filepath))
        elif filepath.suffix.lower() == '.csv':
            return self._load_from_csv(str(filepath))
        elif filepath.suffix.lower() == '.txt':
            return self._load_from_txt(str(filepath))
        else:
            print(f"‚ö†Ô∏è  –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {filepath}")
            return []

    def _load_from_lvp(self, filepath: str) -> List[EmailWithMetadata]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ LVP —Ñ–∞–π–ª–∞"""
        return self.lvp_parser.parse_file(filepath)

    def _load_from_json(self, filepath: str) -> List[EmailWithMetadata]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ JSON —Ñ–∞–π–ª–∞"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)

            emails = []
            if isinstance(data, list):
                # –ú–∞—Å—Å–∏–≤ email –æ–±—ä–µ–∫—Ç–æ–≤
                for item in data:
                    if isinstance(item, dict):
                        emails.append(EmailWithMetadata.from_dict(item))
            elif isinstance(data, dict) and 'emails' in data:
                # –û–±—ä–µ–∫—Ç —Å –º–∞—Å—Å–∏–≤–æ–º emails
                for item in data['emails']:
                    emails.append(EmailWithMetadata.from_dict(item))

            print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(emails)} email –∏–∑ JSON {filepath}")
            return emails

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ JSON —Ñ–∞–π–ª–∞ {filepath}: {e}")
            return []

    def _load_from_csv(self, filepath: str) -> List[EmailWithMetadata]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ CSV —Ñ–∞–π–ª–∞"""
        import csv

        try:
            emails = []
            with open(filepath, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    if 'email' in row and row['email']:
                        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç EmailWithMetadata –∏–∑ CSV —Å—Ç—Ä–æ–∫–∏
                        email_obj = EmailWithMetadata(
                            email=row['email'].strip().lower(),
                            source_url=row.get('source_url'),
                            page_title=row.get('page_title'),
                            company_name=row.get('company_name'),
                            category=row.get('category'),
                            country=row.get('country'),
                            city=row.get('city'),
                            address=row.get('address'),
                            phone=row.get('phone'),
                            domain=row.get('domain'),
                            keywords=row.get('keywords'),
                            meta_description=row.get('meta_description'),
                            meta_keywords=row.get('meta_keywords')
                        )
                        emails.append(email_obj)

            print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(emails)} email –∏–∑ CSV {filepath}")
            return emails

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ CSV —Ñ–∞–π–ª–∞ {filepath}: {e}")
            return []

    def _load_from_txt(self, filepath: str) -> List[EmailWithMetadata]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ –æ–±—ã—á–Ω–æ–≥–æ TXT —Ñ–∞–π–ª–∞ (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)"""
        import re

        emails = []
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                for line in f:
                    email = line.strip().lower()
                    if email and self._is_valid_email(email):
                        emails.append(EmailWithMetadata.from_simple_email(email))

            print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(emails)} email –∏–∑ TXT {filepath}")
            return emails

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ TXT —Ñ–∞–π–ª–∞ {filepath}: {e}")
            return []

    def _is_valid_email(self, email: str) -> bool:
        """–ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è email"""
        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        return bool(re.match(pattern, email))

    def save_emails_to_json(self, emails: List[EmailWithMetadata], filepath: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –≤ JSON"""
        try:
            data = {
                "metadata": {
                    "generated_date": datetime.now().isoformat(),
                    "total_count": len(emails),
                    "format_version": "1.0"
                },
                "emails": [email.to_dict() for email in emails]
            }

            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)

            print(f"‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(emails)} email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –≤ {filepath}")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ JSON {filepath}: {e}")

    def save_emails_to_csv(self, emails: List[EmailWithMetadata], filepath: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –≤ CSV"""
        import csv

        try:
            fieldnames = [
                'email', 'source_url', 'page_title', 'company_name', 'phone',
                'country', 'city', 'address', 'category', 'domain', 'keywords',
                'meta_description', 'meta_keywords', 'validation_status', 'found_date'
            ]

            with open(filepath, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()

                for email in emails:
                    row = {}
                    for field in fieldnames:
                        row[field] = getattr(email, field, '')
                    writer.writerow(row)

            print(f"‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(emails)} email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –≤ CSV {filepath}")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ CSV {filepath}: {e}")