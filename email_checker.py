#!/usr/bin/env python3
"""
Email Checker - –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ email —Å–ø–∏—Å–∫–æ–≤ –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤
"""

import os
import re
import argparse
import json
import hashlib
from pathlib import Path
from datetime import datetime
from typing import Set, List, Tuple, Dict, Union
from collections import defaultdict
import time

# –ò–º–ø–æ—Ä—Ç –Ω–∞—à–µ–≥–æ –º–æ–¥—É–ª—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
from email_metadata import EmailMetadataManager, EmailWithMetadata
from metadata_integration import MetadataIntegrator, EnrichedEmailResult

class EmailChecker:
    def __init__(self, base_dir: str = "."):
        self.base_dir = Path(base_dir)
        self.input_dir = self.base_dir / "input"
        self.blocklists_dir = self.base_dir / "blocklists"
        self.output_dir = self.base_dir / "output"

        # –ö–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –±–ª–æ–∫-–ª–∏—Å—Ç—ã
        self.blocked_emails: Set[str] = set()
        self.blocked_domains: Set[str] = set()
        self.cache_loaded = False

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = defaultdict(int)
        self.all_results = []  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤—Å–µ—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫

        # –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π
        self.cache_dir = self.base_dir / ".cache"
        self.cache_dir.mkdir(exist_ok=True)
        self.processed_files_cache = self.cache_dir / "processed_files.json"

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–ø–∏—Å–∫–æ–≤
        self.lists_config_file = self.base_dir / "lists_config.json"
        self.lists_config = self._load_lists_config()

        # –ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ email
        self.metadata_manager = EmailMetadataManager(str(self.base_dir))

        # –ò–Ω—Ç–µ–≥—Ä–∞—Ç–æ—Ä –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ LVP —Ñ–∞–π–ª–æ–≤
        self.metadata_integrator = MetadataIntegrator(str(self.base_dir))

    def load_emails_from_file(self, filepath: str) -> Set[str]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç email –∞–¥—Ä–µ—Å–∞ –∏–∑ txt —Ñ–∞–π–ª–∞ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π"""
        emails = set()
        invalid_count = 0
        normalized_count = 0

        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                for line in f:
                    email = line.strip().lower()
                    if not email:
                        continue

                    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –°–Ω–∞—á–∞–ª–∞ –≤—Å–µ–≥–¥–∞ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º, –ø–æ—Ç–æ–º –ø—Ä–æ–≤–µ—Ä—è–µ–º
                    # –≠—Ç–æ –ø–æ–∑–≤–æ–ª–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å email —Å –ø—Ä–µ—Ñ–∏–∫—Å–∞–º–∏ //, 20, –∏ —Ç.–¥.
                    normalized = self.normalize_email(email)

                    if normalized:
                        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞ - –¥–æ–±–∞–≤–ª—è–µ–º
                        emails.add(normalized)
                        if normalized != email:
                            normalized_count += 1
                    else:
                        # –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å - –æ—Ç–∫–ª–æ–Ω—è–µ–º
                        invalid_count += 1

            print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(emails)} –≤–∞–ª–∏–¥–Ω—ã—Ö email –∏–∑ {filepath}")
            if normalized_count > 0:
                print(f"  üîß –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ: {normalized_count} email")
            if invalid_count > 0:
                print(f"  ‚ö†Ô∏è  –û—Ç–∫–ª–æ–Ω–µ–Ω–æ –Ω–µ–≤–∞–ª–∏–¥–Ω—ã—Ö: {invalid_count} email")
        except FileNotFoundError:
            print(f"‚ùå –§–∞–π–ª {filepath} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {filepath}: {e}")

        return emails

    def load_emails_with_metadata(self, filepath: str) -> List[EmailWithMetadata]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ (LVP, JSON, CSV, TXT)"""
        return self.metadata_manager.load_emails_from_file(filepath)

    def load_blocklists(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–ª–æ–∫-–ª–∏—Å—Ç—ã –≤ –ø–∞–º—è—Ç—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
        if self.cache_loaded:
            return

        print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤...")
        start_time = time.time()

        # –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö email
        email_blocklist = self.blocklists_dir / "blocked_emails.txt"
        if email_blocklist.exists():
            self.blocked_emails = self.load_emails_from_file(str(email_blocklist))

        # –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤
        domain_blocklist = self.blocklists_dir / "blocked_domains.txt"
        if domain_blocklist.exists():
            with open(domain_blocklist, 'r', encoding='utf-8') as f:
                for line in f:
                    domain = line.strip().lower()
                    if domain:
                        self.blocked_domains.add(domain)

        self.cache_loaded = True
        load_time = time.time() - start_time

        print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.blocked_emails)} –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö email")
        print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.blocked_domains)} –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤")
        print(f"‚úì –í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏: {load_time:.2f} —Å–µ–∫\n")

    def save_blocked_emails_to_file(self, new_blocked_emails: Set[str], reason: str = "validation_status"):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –Ω–æ–≤—ã–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ email –≤ blocklist —Ñ–∞–π–ª

        Args:
            new_blocked_emails: –ú–Ω–æ–∂–µ—Å—Ç–≤–æ email –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –±–ª–æ–∫-–ª–∏—Å—Ç
            reason: –ü—Ä–∏—á–∏–Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        if not new_blocked_emails:
            return

        email_blocklist = self.blocklists_dir / "blocked_emails.txt"

        # –ß–∏—Ç–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ blocked emails –∏–∑ —Ñ–∞–π–ª–∞
        existing_in_file = set()
        if email_blocklist.exists():
            with open(email_blocklist, 'r', encoding='utf-8') as f:
                for line in f:
                    email = line.strip().lower()
                    if email:
                        existing_in_file.add(email)

        # –ù–∞—Ö–æ–¥–∏–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ email (–∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Ñ–∞–π–ª–µ)
        truly_new = new_blocked_emails - existing_in_file

        if not truly_new:
            return

        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ email –≤ —Ñ–∞–π–ª
        try:
            with open(email_blocklist, 'a', encoding='utf-8') as f:
                for email in sorted(truly_new):
                    f.write(f"{email}\n")

            # –û–±–Ω–æ–≤–ª—è–µ–º in-memory –∫–µ—à
            self.blocked_emails.update(truly_new)

            print(f"üìù –î–æ–±–∞–≤–ª–µ–Ω–æ {len(truly_new)} email –≤ –±–ª–æ–∫-–ª–∏—Å—Ç ({reason})")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –±–ª–æ–∫-–ª–∏—Å—Ç: {e}")

    def _is_valid_email(self, email: str) -> bool:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ email —Ñ–æ—Ä–º–∞—Ç–∞ (–ü–û–°–õ–ï –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏)
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ RFC —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–æ–∫–µ–Ω—ã
        –ù–ï –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å—ã - –æ–Ω–∏ —É–¥–∞–ª—è—é—Ç—Å—è –≤ normalize_email()
        """
        # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞
        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        if not re.match(pattern, email):
            return False

        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—É—é —á–∞—Å—Ç—å –∏ –¥–æ–º–µ–Ω
        try:
            local_part, domain = email.split('@', 1)
        except ValueError:
            return False

        # RFC —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —á–∞—Å—Ç–∏
        # Email –Ω–µ –º–æ–∂–µ—Ç –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å: . - + _
        if local_part[0] in ['.', '-', '+', '_']:
            return False

        # Email –Ω–µ –º–æ–∂–µ—Ç –∑–∞–∫–∞–Ω—á–∏–≤–∞—Ç—å—Å—è —Ç–æ—á–∫–æ–π –ø–µ—Ä–µ–¥ @
        if local_part[-1] == '.':
            return False

        # –î–≤–µ —Ç–æ—á–∫–∏ –ø–æ–¥—Ä—è–¥ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã
        if '..' in local_part:
            return False

        # –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏ (–±–æ–ª–µ–µ 64 —Å–∏–º–≤–æ–ª–æ–≤ –ø–æ RFC)
        if len(local_part) > 64:
            return False

        # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏ (–º–µ–Ω–µ–µ 1 —Å–∏–º–≤–æ–ª–∞)
        if len(local_part) < 1:
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã (—Ç–µ, —á—Ç–æ –Ω–µ —É–¥–∞–ª—è—é—Ç—Å—è –≤ normalize)
        invalid_chars = ['<', '>', '(', ')', '[', ']', ',', ';', ':', '\\', '"', ' ', '/', '\t', '\n']
        if any(char in local_part for char in invalid_chars):
            return False

        # RFC —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –¥–ª—è –¥–æ–º–µ–Ω–∞
        # –î–æ–º–µ–Ω –Ω–µ –º–æ–∂–µ—Ç –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è –∏–ª–∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞—Ç—å—Å—è —Ç–æ—á–∫–æ–π –∏–ª–∏ –¥–µ—Ñ–∏—Å–æ–º
        if domain[0] in ['.', '-'] or domain[-1] in ['.', '-']:
            return False

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤ –∏ —Ö–µ—à–µ–π
        # 1. MD5 —Ö–µ—à–∏ (32 —Å–∏–º–≤–æ–ª–∞ hex)
        if re.match(r'^[a-f0-9]{32}$', local_part.lower()):
            return False

        # 2. SHA1 —Ö–µ—à–∏ (40 —Å–∏–º–≤–æ–ª–æ–≤ hex)
        if re.match(r'^[a-f0-9]{40}$', local_part.lower()):
            return False

        # 3. UUID —Ñ–æ—Ä–º–∞—Ç (8-4-4-4-12 —Å–∏–º–≤–æ–ª–æ–≤)
        if re.match(r'^[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}$', local_part.lower()):
            return False

        # 4. –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–æ–º–µ–Ω—ã —Å–µ—Ä–≤–∏—Å–æ–≤ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        tech_domains = ['sentry.', 'getsentry.', 'bugsnag.', 'rollbar.', 'airbrake.']
        if any(tech_domain in domain.lower() for tech_domain in tech_domains):
            return False

        # 5. –ò—Å–∫–ª—é—á–∞–µ–º –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–µ hex —Å—Ç—Ä–æ–∫–∏ (–≤–µ—Ä–æ—è—Ç–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã)
        if len(local_part) > 20 and re.match(r'^[a-f0-9]+$', local_part.lower()):
            return False

        return True

    def normalize_email(self, email: str) -> Union[str, None]:
        """
        –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç email: —É–¥–∞–ª—è–µ—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã –∏ —Å–∏–º–≤–æ–ª—ã
        –í—Å–µ–≥–¥–∞ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫–æ –≤—Å–µ–º email, –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω–∏ –≤—ã–≥–ª—è–¥—è—Ç –≤–∞–ª–∏–¥–Ω—ã–º–∏
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π email –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å
        """
        if not email or '@' not in email:
            return None

        try:
            local_part, domain = email.split('@', 1)
        except ValueError:
            return None

        original_email = email
        original_local = local_part
        normalized = False

        # –£–¥–∞–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å "//" –µ—Å–ª–∏ –µ—Å—Ç—å (–ü–†–ò–û–†–ò–¢–ï–¢ 1 - —Å–∞–º—ã–π —á–∞—Å—Ç—ã–π)
        if local_part.startswith('//'):
            local_part = local_part[2:]
            normalized = True
            self.stats['normalized_slash_prefix'] += 1

        # –£–¥–∞–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å "20" –µ—Å–ª–∏ –µ—Å—Ç—å –∏ –æ—Å—Ç–∞–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω–∞—è —á–∞—Å—Ç—å (–ü–†–ò–û–†–ò–¢–ï–¢ 2)
        if local_part.startswith('20') and len(local_part) > 2:
            local_part = local_part[2:]
            normalized = True
            self.stats['normalized_20_prefix'] += 1

        # –£–¥–∞–ª—è–µ–º –í–°–ï –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã –≤ –Ω–∞—á–∞–ª–µ: . - + _
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º while —á—Ç–æ–±—ã —É–¥–∞–ª–∏—Ç—å –≤—Å–µ –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏–µ
        while local_part and local_part[0] in ['.', '-', '+', '_']:
            local_part = local_part[1:]
            normalized = True
            self.stats['normalized_invalid_start'] += 1

        # –£–¥–∞–ª—è–µ–º —Ç–æ—á–∫–∏ –≤ –∫–æ–Ω—Ü–µ –ª–æ–∫–∞–ª—å–Ω–æ–π —á–∞—Å—Ç–∏
        while local_part and local_part[-1] == '.':
            local_part = local_part[:-1]
            normalized = True
            self.stats['normalized_trailing_dot'] += 1

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —á—Ç–æ-—Ç–æ –æ—Å—Ç–∞–ª–æ—Å—å
        if not local_part or len(local_part) < 1:
            self.stats['invalid_after_normalization'] += 1
            return None

        # –°–æ–±–∏—Ä–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π email
        normalized_email = f"{local_part}@{domain}"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –ü–û–°–õ–ï –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        if not self._is_valid_email(normalized_email):
            self.stats['invalid_after_normalization'] += 1
            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º—É –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            if normalized:
                print(f"   ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å: {original_email} ‚Üí {normalized_email} (–Ω–µ –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é)")
            return None

        # –õ–æ–≥–∏—Ä—É–µ–º –µ—Å–ª–∏ –±—ã–ª–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        if normalized and original_local != local_part:
            print(f"   üîß –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω: {original_email} ‚Üí {normalized_email}")

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π email (–¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ –±—ã–ª–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
        return normalized_email

    def _get_domain(self, email: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–æ–º–µ–Ω –∏–∑ email"""
        try:
            return email.split('@')[1].lower()
        except IndexError:
            return ""

    def check_email_against_blocklists(self, emails: Set[str]) -> Dict[str, List[str]]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç email –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏: clean, blocked_email, blocked_domain
        """
        self.load_blocklists()

        result = {
            'clean': [],
            'blocked_email': [],
            'blocked_domain': [],
            'invalid': []
        }

        print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ email –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤...")
        start_time = time.time()

        for email in emails:
            if not self._is_valid_email(email):
                result['invalid'].append(email)
                continue

            domain = self._get_domain(email)

            if email in self.blocked_emails:
                result['blocked_email'].append(email)
            elif domain in self.blocked_domains:
                result['blocked_domain'].append(email)
            else:
                result['clean'].append(email)

        check_time = time.time() - start_time

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.stats['total_checked'] = len(emails)
        self.stats['clean'] = len(result['clean'])
        self.stats['blocked_email'] = len(result['blocked_email'])
        self.stats['blocked_domain'] = len(result['blocked_domain'])
        self.stats['invalid'] = len(result['invalid'])
        self.stats['check_time'] = check_time

        return result

    def check_emails_with_enrichment(self, emails: List[str], list_name: str = "unknown") -> Dict[str, List[EnrichedEmailResult]]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç email –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–±–æ–≥–∞—â–µ–Ω–∏–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–∑ LVP —Ñ–∞–π–ª–æ–≤

        Args:
            emails: –°–ø–∏—Å–æ–∫ email –∞–¥—Ä–µ—Å–æ–≤
            list_name: –ù–∞–∑–≤–∞–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–ª—è –æ—Ç—á–µ—Ç–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏ –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: clean, blocked_email, blocked_domain, invalid
        """
        print(f"\nüöÄ –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –° –ò–ù–¢–ï–ì–†–ê–¶–ò–ï–ô –ú–ï–¢–ê–î–ê–ù–ù–´–•")
        print(f"üìß –°–ø–∏—Å–æ–∫: {list_name}")
        print(f"üìä Email –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏: {len(emails)}")

        # –®–∞–≥ 1: –û–±–æ–≥–∞—â–∞–µ–º email –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–∑ LVP —Ñ–∞–π–ª–æ–≤
        enriched_emails = self.metadata_integrator.enrich_email_list(emails, list_name)

        # –®–∞–≥ 2: –ó–∞–≥—Ä—É–∂–∞–µ–º –±–ª–æ–∫-–ª–∏—Å—Ç—ã
        self.load_blocklists()

        # –®–∞–≥ 3: –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤
        result = {
            'clean': [],
            'blocked_email': [],
            'blocked_domain': [],
            'invalid': []
        }

        print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã—Ö email –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤...")
        start_time = time.time()

        for enriched_email in enriched_emails:
            email = enriched_email.email

            if not self._is_valid_email(email):
                enriched_email.is_clean = False
                enriched_email.blocked_reason = "Invalid email format"
                result['invalid'].append(enriched_email)
                continue

            domain = self._get_domain(email)

            if email in self.blocked_emails:
                enriched_email.is_clean = False
                enriched_email.blocked_reason = "Email in blocklist"
                result['blocked_email'].append(enriched_email)
            elif domain in self.blocked_domains:
                enriched_email.is_clean = False
                enriched_email.blocked_reason = "Domain in blocklist"
                result['blocked_domain'].append(enriched_email)
            else:
                enriched_email.is_clean = True
                result['clean'].append(enriched_email)

        check_time = time.time() - start_time

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ–±–æ–≥–∞—â–µ–Ω–∏—é
        total_with_metadata = sum(1 for enriched in enriched_emails if enriched.has_metadata)
        enrichment_rate = (total_with_metadata / len(enriched_emails)) * 100 if enriched_emails else 0

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.stats['total_checked'] = len(emails)
        self.stats['clean'] = len(result['clean'])
        self.stats['blocked_email'] = len(result['blocked_email'])
        self.stats['blocked_domain'] = len(result['blocked_domain'])
        self.stats['invalid'] = len(result['invalid'])
        self.stats['check_time'] = check_time
        self.stats['emails_with_metadata'] = total_with_metadata
        self.stats['enrichment_rate'] = enrichment_rate

        print(f"‚ú® –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è {total_with_metadata} email ({enrichment_rate:.1f}%)")

        return result

    def check_emails_with_metadata(self, emails_with_metadata: List[EmailWithMetadata]) -> Dict[str, List[EmailWithMetadata]]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏: clean, blocked_email, blocked_domain
        """
        self.load_blocklists()

        result = {
            'clean': [],
            'blocked_email': [],
            'blocked_domain': [],
            'invalid': []
        }

        # –î–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –±–ª–æ–∫-–ª–∏—Å—Ç
        emails_to_block_from_status = set()

        print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤...")
        start_time = time.time()

        for email_obj in emails_with_metadata:
            email = email_obj.email

            if not self._is_valid_email(email):
                result['invalid'].append(email_obj)
                continue

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ validation_status –∏–∑ LVP —Ñ–∞–π–ª–∞
            if email_obj.validation_status:
                status = email_obj.validation_status.lower()
                if status == 'invalid':
                    result['invalid'].append(email_obj)
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
                    emails_to_block_from_status.add(email)
                    continue
                elif status in ['temp', 'notsure', 'notchecked']:
                    # –í—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ –Ω–µ–Ω–∞–¥—ë–∂–Ω—ã–µ email –±–ª–æ–∫–∏—Ä—É–µ–º
                    result['blocked_email'].append(email_obj)
                    continue

            domain = self._get_domain(email)

            if email in self.blocked_emails:
                result['blocked_email'].append(email_obj)
            elif domain in self.blocked_domains:
                result['blocked_domain'].append(email_obj)
            else:
                result['clean'].append(email_obj)

        check_time = time.time() - start_time

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º Invalid email –≤ –±–ª–æ–∫-–ª–∏—Å—Ç
        if emails_to_block_from_status:
            self.save_blocked_emails_to_file(emails_to_block_from_status, reason="LVP status=Invalid")

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        total_emails = len(emails_with_metadata)
        self.stats['total_checked'] = total_emails
        self.stats['clean'] = len(result['clean'])
        self.stats['blocked_email'] = len(result['blocked_email'])
        self.stats['blocked_domain'] = len(result['blocked_domain'])
        self.stats['invalid'] = len(result['invalid'])
        self.stats['check_time'] = check_time

        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(result['clean'])} —á–∏—Å—Ç—ã—Ö email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏")

        return result

    def _save_result_for_report(self, filename: str, results: Dict[str, List[str]], file_path: str = None, cache_data: Dict = None, duplicates_removed: int = 0, prefix_duplicates_removed: int = 0):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è HTML –æ—Ç—á–µ—Ç–∞ –∏ –≤ –∫–µ—à"""
        result_data = {
            'filename': filename,
            'stats': dict(self.stats),
            'results': results,
            'duplicates_removed': duplicates_removed,  # –î—É–±–ª–∏–∫–∞—Ç—ã —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–ø–∏—Å–∫–∞–º–∏
            'prefix_duplicates_removed': prefix_duplicates_removed,  # –î—É–±–ª–∏–∫–∞—Ç—ã —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20'
            'timestamp': datetime.now().isoformat()
        }

        self.all_results.append(result_data)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à –µ—Å–ª–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ
        if file_path and cache_data is not None:
            filename_key = Path(file_path).name
            cache_data[filename_key] = {
                'hash': self._get_file_hash(file_path),
                'result_data': result_data,
                'processed_at': datetime.now().isoformat()
            }

    def find_duplicates(self, lists: List[Set[str]]) -> Dict[str, Set[str]]:
        """–ù–∞—Ö–æ–¥–∏—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –º–µ–∂–¥—É –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Å–ø–∏—Å–∫–∞–º–∏"""
        if len(lists) < 2:
            return {}

        duplicates = {}
        for i, current_list in enumerate(lists[1:], 1):
            prev_emails = set()
            for j in range(i):
                prev_emails.update(lists[j])

            dupes = current_list.intersection(prev_emails)
            if dupes:
                duplicates[f'list_{i+1}_duplicates'] = dupes

        return duplicates

    def clean_prefix_duplicates(self, emails: Set[str]) -> Tuple[Set[str], int]:
        """
        –û—á–∏—â–∞–µ—Ç email —Å –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–º–∏ –ø—Ä–µ—Ñ–∏–∫—Å–∞–º–∏:
        1. –ï—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤–µ—Ä—Å–∏—è –ë–ï–ó –ø—Ä–µ—Ñ–∏–∫—Å–∞ - —É–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç –° –ø—Ä–µ—Ñ–∏–∫—Å–æ–º
        2. –ï—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –¢–û–õ–¨–ö–û –≤–µ—Ä—Å–∏—è –° –ø—Ä–µ—Ñ–∏–∫—Å–æ–º - –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –µ—ë (—É–±–∏—Ä–∞–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å)

        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å—ã: '20', '//', –Ω–∞—á–∞–ª—å–Ω—ã–µ '-', '.', '+', '_'
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—á–∏—â–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        """
        cleaned_emails = set(emails)
        removed_count = 0
        normalized_count = 0
        removal_reasons = defaultdict(int)
        normalization_reasons = defaultdict(int)

        # –ù–∞—Ö–æ–¥–∏–º email —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –ø—Ä–µ—Ñ–∏–∫—Å–∞–º–∏
        prefix_emails = {}  # email -> (clean_version, prefix_type)

        for email in emails:
            if '@' not in email:
                continue

            try:
                local_part, domain = email.split('@', 1)
            except ValueError:
                continue

            original_local = local_part
            clean_local = local_part
            prefix_type = None

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å '//'
            if local_part.startswith('//'):
                clean_local = local_part[2:]
                prefix_type = '//'
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å '20'
            elif local_part.startswith('20') and len(local_part) > 2:
                clean_local = local_part[2:]
                prefix_type = '20'
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã
            elif local_part[0] in ['-', '.', '+', '_']:
                # –£–¥–∞–ª—è–µ–º –≤—Å–µ –Ω–∞—á–∞–ª—å–Ω—ã–µ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã
                clean_local = local_part.lstrip('-.+_')
                if clean_local != original_local:
                    prefix_type = f'invalid_start({original_local[0]})'

            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –ø—Ä–µ—Ñ–∏–∫—Å
            if prefix_type and clean_local and len(clean_local) > 0:
                clean_version = f"{clean_local}@{domain}"
                prefix_emails[email] = (clean_version, prefix_type)

        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º email —Å –ø—Ä–µ—Ñ–∏–∫—Å–∞–º–∏
        for prefix_email, (clean_version, prefix_type) in prefix_emails.items():
            # –ï—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —á–∏—Å—Ç–∞—è –≤–µ—Ä—Å–∏—è - —É–¥–∞–ª—è–µ–º –≤–µ—Ä—Å–∏—é —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º (–¥—É–±–ª–∏–∫–∞—Ç)
            if clean_version in emails and clean_version != prefix_email:
                cleaned_emails.discard(prefix_email)
                removed_count += 1
                removal_reasons[prefix_type] += 1
                print(f"   üóëÔ∏è  –£–¥–∞–ª–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '{prefix_type}': {prefix_email} (–µ—Å—Ç—å {clean_version})")
            # –ï—Å–ª–∏ –ù–ï —Å—É—â–µ—Å—Ç–≤—É–µ—Ç —á–∏—Å—Ç–∞—è –≤–µ—Ä—Å–∏—è - –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º (–∑–∞–º–µ–Ω—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å–Ω—É—é –Ω–∞ —á–∏—Å—Ç—É—é)
            elif clean_version not in emails and prefix_email in cleaned_emails:
                cleaned_emails.discard(prefix_email)
                cleaned_emails.add(clean_version)
                normalized_count += 1
                normalization_reasons[prefix_type] += 1
                print(f"   üîß –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω –æ–¥–∏–Ω–æ—á–Ω—ã–π email —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '{prefix_type}': {prefix_email} ‚Üí {clean_version}")

        # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
        if removed_count > 0:
            print(f"\nüìä –°–≤–æ–¥–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ –ø—Ä–µ—Ñ–∏–∫—Å–∞–º:")
            for prefix_type, count in sorted(removal_reasons.items(), key=lambda x: x[1], reverse=True):
                print(f"   ‚Ä¢ –ü—Ä–µ—Ñ–∏–∫—Å '{prefix_type}': {count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
            print()

        if normalized_count > 0:
            print(f"\nüìä –°–≤–æ–¥–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö email —Å –ø—Ä–µ—Ñ–∏–∫—Å–∞–º–∏:")
            for prefix_type, count in sorted(normalization_reasons.items(), key=lambda x: x[1], reverse=True):
                print(f"   ‚Ä¢ –ü—Ä–µ—Ñ–∏–∫—Å '{prefix_type}': {count} –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ")
            print()

        return cleaned_emails, removed_count + normalized_count

    def _get_file_hash(self, filepath: str) -> str:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ö–µ—à —Ñ–∞–π–ª–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
        try:
            with open(filepath, 'rb') as f:
                content = f.read()
                return hashlib.md5(content).hexdigest()
        except Exception:
            return ""

    def _save_processed_files_cache(self, processed_files: Dict):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–µ—à –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        try:
            with open(self.processed_files_cache, 'w', encoding='utf-8') as f:
                json.dump(processed_files, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–µ—à–∞: {e}")

    def _load_processed_files_cache(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–µ—à –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
        try:
            if self.processed_files_cache.exists():
                with open(self.processed_files_cache, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–µ—à–∞: {e}")
        return {}

    def _load_cached_results(self, cache_data: Dict):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ self.all_results"""
        for file_info in cache_data.values():
            if 'result_data' in file_info:
                self.all_results.append(file_info['result_data'])

    def _load_lists_config(self) -> Dict:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ø–∏—Å–∫–æ–≤"""
        try:
            if self.lists_config_file.exists():
                with open(self.lists_config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        return {"lists": []}

    def _save_lists_config(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å–ø–∏—Å–∫–æ–≤"""
        try:
            with open(self.lists_config_file, 'w', encoding='utf-8') as f:
                json.dump(self.lists_config, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")

    def _get_list_metadata(self, filename: str) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–∞–π–ª–∞ —Å–ø–∏—Å–∫–∞"""
        for list_info in self.lists_config.get("lists", []):
            if list_info["filename"] == filename:
                return list_info

        # –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏, —Å–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é –∑–∞–ø–∏—Å—å
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –≤—ã—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã (–∑–Ω–∞—á–∏—Ç —Ñ–∞–π–ª –±—ã–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω)
        output_files = list(self.output_dir.glob(f"{Path(filename).stem}_*"))
        is_processed = len(output_files) > 0

        # –£–º–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω—ã –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
        filename_lower = filename.lower()
        detected_country = "Unknown"
        detected_category = "General"

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω—ã
        if any(marker in filename_lower for marker in ["ru_", "_ru", "russia", "russian"]):
            detected_country = "Russia"
        elif any(marker in filename_lower for marker in ["poland", "polland", "pol_", "_pl"]):
            detected_country = "Poland"
        elif any(marker in filename_lower for marker in ["belgium", "belg_", "_be"]):
            detected_country = "Belgium"
        elif any(marker in filename_lower for marker in ["germany", "german", "_de", "_ger"]):
            detected_country = "Germany"
        elif any(marker in filename_lower for marker in ["czech", "czeh", "_cz"]):
            detected_country = "Czech Republic"
        elif any(marker in filename_lower for marker in ["bulgaria", "bolgar", "_bg"]):
            detected_country = "Bulgaria"
        elif any(marker in filename_lower for marker in ["romania", "rumonia", "romonia", "_ro", "_rom"]):
            detected_country = "Romania"
        elif any(marker in filename_lower for marker in ["hungary", "hungar", "_hu", "_hun"]):
            detected_country = "Hungary"
        elif any(marker in filename_lower for marker in ["croatia", "croat", "_hr", "_cro"]):
            detected_country = "Croatia"
        elif any(marker in filename_lower for marker in ["montenegro", "monten", "_me", "_mne"]):
            detected_country = "Montenegro"
        elif any(marker in filename_lower for marker in ["macedonia", "macedon", "_mk", "_mac"]):
            detected_country = "North Macedonia"
        elif any(marker in filename_lower for marker in ["serbia", "serb", "_rs", "_srb"]):
            detected_country = "Serbia"
        elif any(marker in filename_lower for marker in ["slovenia", "sloven", "_si", "_slo"]):
            detected_country = "Slovenia"
        elif any(marker in filename_lower for marker in ["slovakia", "slovak", "_sk", "_svk"]):
            detected_country = "Slovakia"
        elif any(marker in filename_lower for marker in ["austria", "austri", "_at", "_aut"]):
            detected_country = "Austria"
        elif any(marker in filename_lower for marker in ["netherlands", "dutch", "_nl", "_ned"]):
            detected_country = "Netherlands"
        elif any(marker in filename_lower for marker in ["france", "french", "_fr", "_fra"]):
            detected_country = "France"
        elif any(marker in filename_lower for marker in ["italy", "italian", "_it", "_ita"]):
            detected_country = "Italy"
        elif any(marker in filename_lower for marker in ["spain", "spanish", "_es", "_esp"]):
            detected_country = "Spain"
        elif any(marker in filename_lower for marker in ["portugal", "portug", "_pt", "_por"]):
            detected_country = "Portugal"
        elif any(marker in filename_lower for marker in ["eu_", "europe"]):
            detected_country = "Europe"
        elif any(marker in filename_lower for marker in ["rf_", "_rf", "rb_"]):
            detected_country = "Mixed"

        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        if any(marker in filename_lower for marker in ["motor", "auto", "car"]):
            detected_category = "Automotive"
        elif any(marker in filename_lower for marker in ["agro", "agri", "farm"]):
            detected_category = "Agriculture"
        elif any(marker in filename_lower for marker in ["metal", "manufacture", "industry"]):
            detected_category = "Manufacturing"
        elif any(marker in filename_lower for marker in ["transport", "municip", "public"]):
            detected_category = "Transportation"
        elif any(marker in filename_lower for marker in ["hc_", "construct", "build", "buld"]):
            detected_category = "Manufacturing"  # Heavy Construction
        elif any(marker in filename_lower for marker in ["full", "complete", "database"]):
            detected_category = "Regional"

        new_list = {
            "filename": filename,
            "display_name": Path(filename).stem.replace("_", " ").title(),
            "country": detected_country,
            "category": detected_category,
            "priority": len(self.lists_config.get("lists", [])) + 1,
            "processed": is_processed,
            "date_added": datetime.now().strftime("%Y-%m-%d"),
            "description": f"Auto-detected list: {filename}"
        }

        self.lists_config.setdefault("lists", []).append(new_list)
        self._save_lists_config()
        return new_list

    def _update_list_processed_status(self, filename: str, processed: bool = True):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        for list_info in self.lists_config.get("lists", []):
            if list_info["filename"] == filename:
                list_info["processed"] = processed
                self._save_lists_config()
                break

    def show_status(self, pattern: str = None, category: str = None, country: str = None):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –≤—Å–µ—Ö —Å–ø–∏—Å–∫–æ–≤ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π"""
        print("\n" + "="*80)
        print("üìä –°–¢–ê–¢–£–° EMAIL –°–ü–ò–°–ö–û–í")
        print("="*80)

        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –Ω–æ–≤—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏
        input_files = list(self.input_dir.glob("*.txt"))
        for file_path in input_files:
            filename = file_path.name
            self._get_list_metadata(filename)

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
        lists_to_show = []
        for list_info in self.lists_config.get("lists", []):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
            if pattern and pattern.lower() not in list_info["filename"].lower():
                continue
            if category and category.lower() != list_info["category"].lower():
                continue
            if country and country.lower() != list_info["country"].lower():
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
            file_path = self.input_dir / list_info["filename"]
            if file_path.exists():
                file_size = file_path.stat().st_size
                list_info["file_size"] = file_size
                list_info["exists"] = True
            else:
                list_info["file_size"] = 0
                list_info["exists"] = False

            lists_to_show.append(list_info)

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        lists_to_show.sort(key=lambda x: x.get("priority", 999))

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        total_lists = len(lists_to_show)
        processed_lists = sum(1 for lst in lists_to_show if lst["processed"])
        pending_lists = total_lists - processed_lists

        print(f"üìã –í—Å–µ–≥–æ —Å–ø–∏—Å–∫–æ–≤: {total_lists}")
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_lists}")
        print(f"‚è≥ –û–∂–∏–¥–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏: {pending_lists}")
        print()

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª–∏
        print(f"{'‚Ññ':>3} {'–§–∞–π–ª':<20} {'–ù–∞–∑–≤–∞–Ω–∏–µ':<25} {'–°—Ç—Ä–∞–Ω–∞':<12} {'–ö–∞—Ç–µ–≥–æ—Ä–∏—è':<15} {'–†–∞–∑–º–µ—Ä':<10} {'–°—Ç–∞—Ç—É—Å':<12}")
        print("-" * 105)

        for i, list_info in enumerate(lists_to_show, 1):
            filename = list_info["filename"]
            display_name = list_info["display_name"][:24] + ("..." if len(list_info["display_name"]) > 24 else "")
            country = list_info["country"]
            category = list_info["category"]

            if list_info["exists"]:
                size_str = self._format_file_size(list_info["file_size"])
            else:
                size_str = "–ù–ï–¢ –§–ê–ô–õ–ê"

            status = "‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω" if list_info["processed"] else "‚è≥ –û–∂–∏–¥–∞–µ—Ç"

            print(f"{i:>3} {filename:<20} {display_name:<25} {country:<12} {category:<15} {size_str:<10} {status}")

        print("\nüí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–∏–ª—å—Ç—Ä—ã: --pattern, --category, --country")
        print("üîÑ –î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤: python3 email_checker.py incremental --exclude-duplicates --generate-html")

    def _format_file_size(self, size_bytes: int) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –≤ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º–æ–º –≤–∏–¥–µ"""
        if size_bytes < 1024:
            return f"{size_bytes}B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f}KB"
        else:
            return f"{size_bytes / (1024 * 1024):.1f}MB"

    def check_incremental_update(self, input_files: List[str]) -> Tuple[List[str], Dict]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞–∫–∏–µ —Ñ–∞–π–ª—ã –Ω—É–∂–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø—Ä–∏ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–æ–≤—ã—Ö/–∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏ –∫–µ—à
        """
        cache_data = self._load_processed_files_cache()
        files_to_process = []

        print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è...")

        for file_path in input_files:
            file_path = str(file_path)
            current_hash = self._get_file_hash(file_path)
            filename = Path(file_path).name

            if filename not in cache_data:
                # –ù–æ–≤—ã–π —Ñ–∞–π–ª
                files_to_process.append(file_path)
                print(f"   üìÑ –ù–æ–≤—ã–π —Ñ–∞–π–ª: {filename}")
            elif cache_data[filename].get('hash') != current_hash:
                # –§–∞–π–ª –∏–∑–º–µ–Ω–∏–ª—Å—è
                files_to_process.append(file_path)
                print(f"   üìù –ò–∑–º–µ–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {filename}")
            else:
                # –§–∞–π–ª –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è, –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –∫–µ—à–∞
                print(f"   ‚úÖ –ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {filename} (–∏–∑ –∫–µ—à–∞)")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –Ω–µ–∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        self._load_cached_results(cache_data)

        return files_to_process, cache_data

    def print_statistics(self):
        """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ –∫–æ–Ω—Å–æ–ª—å —Å —Ü–≤–µ—Ç–∞–º–∏"""
        print("\n" + "="*60)
        print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–†–û–í–ï–†–ö–ò")
        print("="*60)

        total = self.stats['total_checked']
        if total == 0:
            print("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è")
            return

        clean = self.stats['clean']
        blocked_email = self.stats['blocked_email']
        blocked_domain = self.stats['blocked_domain']
        invalid = self.stats['invalid']

        print(f"üìß –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ:      {total:,}")
        print(f"‚úÖ –ß–∏—Å—Ç—ã–µ email:        {clean:,} ({clean/total*100:.1f}%)")
        print(f"üö´ –ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã email:  {blocked_email:,} ({blocked_email/total*100:.1f}%)")
        print(f"üö´ –ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã –¥–æ–º–µ–Ω:  {blocked_domain:,} ({blocked_domain/total*100:.1f}%)")
        if invalid > 0:
            print(f"‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ:          {invalid:,} ({invalid/total*100:.1f}%)")

        print(f"\n‚ö° –í—Ä–µ–º—è –ø—Ä–æ–≤–µ—Ä–∫–∏:       {self.stats['check_time']:.2f} —Å–µ–∫")
        print(f"üöÄ –°–∫–æ—Ä–æ—Å—Ç—å:            {total/self.stats['check_time']:,.0f} email/—Å–µ–∫")

    def generate_html_report(self, filename_base: str = "report"):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç HTML –æ—Ç—á–µ—Ç —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π"""
        if not self.all_results:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞")
            return

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.output_dir / f"{filename_base}_{timestamp}.html"

        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        total_stats = defaultdict(int)
        list_details = []

        for result in self.all_results:
            for key, value in result['stats'].items():
                total_stats[key] += value
            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
            total_stats['duplicates_removed'] += result.get('duplicates_removed', 0)
            total_stats['prefix_duplicates_removed'] += result.get('prefix_duplicates_removed', 0)
            list_details.append(result)

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML
        html_content = self._create_html_template(total_stats, list_details)

        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(html_content)

        print(f"üìä HTML –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file.name}")

    def _create_html_template(self, total_stats: Dict, list_details: List) -> str:
        """–°–æ–∑–¥–∞–µ—Ç HTML —à–∞–±–ª–æ–Ω –æ—Ç—á–µ—Ç–∞"""
        total = total_stats['total_checked']
        clean = total_stats['clean']
        blocked_email = total_stats['blocked_email']
        blocked_domain = total_stats['blocked_domain']
        invalid = total_stats['invalid']
        duplicates_removed = total_stats['duplicates_removed']
        prefix_duplicates_removed = total_stats['prefix_duplicates_removed']

        # –î–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
        pie_data = [
            ['–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'],
            ['–ß–∏—Å—Ç—ã–µ', clean],
            ['–ë–ª–æ–∫ email', blocked_email],
            ['–ë–ª–æ–∫ –¥–æ–º–µ–Ω', blocked_domain]
        ]
        if invalid > 0:
            pie_data.append(['–ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ', invalid])

        # –î–µ—Ç–∞–ª–∏ –ø–æ —Å–ø–∏—Å–∫–∞–º
        lists_table = ""
        for i, detail in enumerate(list_details, 1):
            stats = detail['stats']
            duplicates_removed = detail.get('duplicates_removed', 0)
            prefix_duplicates_removed = detail.get('prefix_duplicates_removed', 0)
            lists_table += f"""
            <tr>
                <td>{detail['filename']}</td>
                <td>{stats['total_checked']:,}</td>
                <td class="text-success">{stats['clean']:,}</td>
                <td class="text-danger">{stats['blocked_email']:,}</td>
                <td class="text-warning">{stats['blocked_domain']:,}</td>
                <td class="text-muted">{stats['invalid']:,}</td>
                <td class="text-info">{duplicates_removed:,}</td>
                <td class="text-secondary">{prefix_duplicates_removed:,}</td>
                <td>{stats['check_time']:.2f}—Å</td>
            </tr>
            """

        html = f"""
<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Email Checker - –û—Ç—á–µ—Ç</title>
    <script src="https://www.gstatic.com/charts/loader.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <style>
        .metric-card {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 10px;
            padding: 20px;
            margin: 10px 0;
        }}
        .metric-value {{
            font-size: 2.5rem;
            font-weight: bold;
        }}
        .chart-container {{
            background: white;
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            margin: 20px 0;
        }}
        .table-container {{
            background: white;
            border-radius: 10px;
            padding: 20px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        body {{
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            min-height: 100vh;
        }}
        .header {{
            background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%);
            color: white;
            padding: 30px 0;
            margin-bottom: 30px;
        }}
    </style>
</head>
<body>
    <div class="header">
        <div class="container">
            <h1 class="text-center">üìß Email Checker - –û—Ç—á–µ—Ç</h1>
            <p class="text-center lead">–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {datetime.now().strftime("%d.%m.%Y %H:%M:%S")}</p>
        </div>
    </div>

    <div class="container">
        <!-- –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ -->
        <div class="row mb-4">
            <div class="col-md-3">
                <div class="metric-card text-center">
                    <div class="metric-value">{total:,}</div>
                    <div>–í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ</div>
                </div>
            </div>
            <div class="col-md-3">
                <div class="metric-card text-center" style="background: linear-gradient(135deg, #56ab2f 0%, #a8e6cf 100%);">
                    <div class="metric-value">{clean:,}</div>
                    <div>–ß–∏—Å—Ç—ã–µ ({clean/total*100 if total > 0 else 0:.1f}%)</div>
                </div>
            </div>
            <div class="col-md-3">
                <div class="metric-card text-center" style="background: linear-gradient(135deg, #ff6b6b 0%, #ffa8a8 100%);">
                    <div class="metric-value">{blocked_email + blocked_domain:,}</div>
                    <div>–ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–æ ({(blocked_email + blocked_domain)/total*100 if total > 0 else 0:.1f}%)</div>
                </div>
            </div>
            <div class="col-md-3">
                <div class="metric-card text-center" style="background: linear-gradient(135deg, #4ecdc4 0%, #44a08d 100%);">
                    <div class="metric-value">{total_stats['check_time']:.2f}—Å</div>
                    <div>–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏</div>
                </div>
            </div>
        </div>

        <!-- –ì—Ä–∞—Ñ–∏–∫–∏ -->
        <div class="row">
            <div class="col-md-6">
                <div class="chart-container">
                    <h3 class="text-center mb-3">üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤</h3>
                    <div id="pieChart" style="height: 400px;"></div>
                </div>
            </div>
            <div class="col-md-6">
                <div class="chart-container">
                    <h3 class="text-center mb-3">üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏</h3>
                    <div id="barChart" style="height: 400px;"></div>
                </div>
            </div>
        </div>

        <!-- –î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ -->
        <div class="table-container">
            <h3 class="mb-3">üìã –î–µ—Ç–∞–ª–∏ –ø–æ —Å–ø–∏—Å–∫–∞–º</h3>
            <div class="table-responsive">
                <table class="table table-striped table-hover">
                    <thead class="table-dark">
                        <tr>
                            <th>–§–∞–π–ª</th>
                            <th>–í—Å–µ–≥–æ</th>
                            <th class="text-success">–ß–∏—Å—Ç—ã–µ</th>
                            <th class="text-danger">–ë–ª–æ–∫ Email</th>
                            <th class="text-warning">–ë–ª–æ–∫ –î–æ–º–µ–Ω</th>
                            <th class="text-muted">–ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ</th>
                            <th class="text-info">–î—É–±–ª–∏ –º–µ–∂–¥—É —Å–ø–∏—Å–∫–∞–º–∏</th>
                            <th class="text-secondary">–î—É–±–ª–∏ —Å '20'</th>
                            <th>–í—Ä–µ–º—è</th>
                        </tr>
                    </thead>
                    <tbody>
                        {lists_table}
                    </tbody>
                </table>
            </div>
        </div>

        <!-- –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å -->
        <div class="chart-container mt-4">
            <h3 class="text-center mb-3">‚ö° –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å</h3>
            <div class="row text-center">
                <div class="col-md-4">
                    <h4 class="text-primary">{total/total_stats['check_time']:,.0f}</h4>
                    <p>email/—Å–µ–∫</p>
                </div>
                <div class="col-md-4">
                    <h4 class="text-info">{len(list_details)}</h4>
                    <p>–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–ø–∏—Å–∫–æ–≤</p>
                </div>
                <div class="col-md-4">
                    <h4 class="text-success">{(clean/total*100) if total > 0 else 0:.1f}%</h4>
                    <p>—É—Å–ø–µ—à–Ω–æ—Å—Ç—å –æ—á–∏—Å—Ç–∫–∏</p>
                </div>
            </div>
        </div>
    </div>

    <script>
        google.charts.load('current', {{'packages':['corechart']}});
        google.charts.setOnLoadCallback(drawCharts);

        function drawCharts() {{
            // –ö—Ä—É–≥–æ–≤–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞
            var pieData = google.visualization.arrayToDataTable({pie_data});
            var pieOptions = {{
                title: '–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ email –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º',
                pieHole: 0.4,
                colors: ['#28a745', '#dc3545', '#ffc107', '#6c757d'],
                backgroundColor: 'transparent'
            }};
            var pieChart = new google.visualization.PieChart(document.getElementById('pieChart'));
            pieChart.draw(pieData, pieOptions);

            // –°—Ç–æ–ª–±—á–∞—Ç–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞
            var barData = google.visualization.arrayToDataTable([
                ['–¢–∏–ø', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'],
                ['–ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã –ø–æ email', {blocked_email}],
                ['–ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã –ø–æ –¥–æ–º–µ–Ω—É', {blocked_domain}]
            ]);
            var barOptions = {{
                title: '–¢–∏–ø—ã –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏',
                colors: ['#dc3545', '#ffc107'],
                backgroundColor: 'transparent',
                hAxis: {{title: '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ'}},
                vAxis: {{title: '–¢–∏–ø –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏'}}
            }};
            var barChart = new google.visualization.ColumnChart(document.getElementById('barChart'));
            barChart.draw(barData, barOptions);
        }}
    </script>
</body>
</html>
        """
        return html

    def save_results(self, filename_base: str, results: Dict[str, List[str]]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        for category, emails in results.items():
            if not emails:
                continue

            output_file = self.output_dir / f"{filename_base}_{category}_{timestamp}.txt"
            with open(output_file, 'w', encoding='utf-8') as f:
                for email in sorted(emails):
                    f.write(f"{email}\n")

            print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(emails)} email –≤ {output_file.name}")

    def save_results_with_metadata(self, filename_base: str, results: Dict[str, List[EmailWithMetadata]]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –≤ JSON –∏ CSV —Ñ–æ—Ä–º–∞—Ç–∞—Ö"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        for category, emails_objs in results.items():
            if not emails_objs:
                continue

            # SAFETY NET: –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –≤–Ω—É—Ç—Ä–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ email –∞–¥—Ä–µ—Å—É
            # (–Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ –≤ LVP —Ñ–∞–π–ª–µ –µ—Å—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã)
            seen_emails = {}
            unique_emails_objs = []
            duplicates_found = 0

            for email_obj in emails_objs:
                email_key = email_obj.email.lower()
                if email_key not in seen_emails:
                    seen_emails[email_key] = True
                    unique_emails_objs.append(email_obj)
                else:
                    duplicates_found += 1

            if duplicates_found > 0:
                print(f"   üßπ –£–¥–∞–ª–µ–Ω–æ {duplicates_found} –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}'")

            emails_objs = unique_emails_objs

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON —Å –ø–æ–ª–Ω—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
            output_json = self.output_dir / f"{filename_base}_{category}_metadata_{timestamp}.json"
            self.metadata_manager.save_emails_to_json(emails_objs, str(output_json))

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ CSV –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
            output_csv = self.output_dir / f"{filename_base}_{category}_metadata_{timestamp}.csv"
            self.metadata_manager.save_emails_to_csv(emails_objs, str(output_csv))

            # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ã—á–Ω—ã–π TXT —Ñ–∞–π–ª (—Ç–æ–ª—å–∫–æ email) –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            output_txt = self.output_dir / f"{filename_base}_{category}_{timestamp}.txt"
            with open(output_txt, 'w', encoding='utf-8') as f:
                for email_obj in sorted(emails_objs, key=lambda x: x.email):
                    f.write(f"{email_obj.email}\n")

            print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(emails_objs)} email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏:")
            print(f"  üìÑ JSON: {output_json.name}")
            print(f"  üìä CSV: {output_csv.name}")
            print(f"  üìù TXT: {output_txt.name}")

    def save_enriched_results(self, filename_base: str, results: Dict[str, List[EnrichedEmailResult]]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON –∏ CSV —Ñ–æ—Ä–º–∞—Ç–∞—Ö"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        for category, enriched_emails in results.items():
            if not enriched_emails:
                continue

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON
            output_json = self.output_dir / f"{filename_base}_{category}_enriched_{timestamp}.json"
            enriched_data = {
                "metadata": {
                    "generated_date": datetime.now().isoformat(),
                    "total_emails": len(enriched_emails),
                    "emails_with_metadata": sum(1 for e in enriched_emails if e.has_metadata),
                    "enrichment_rate": f"{sum(1 for e in enriched_emails if e.has_metadata)/len(enriched_emails)*100:.1f}%" if enriched_emails else "0%",
                    "category": category,
                    "source_file": filename_base
                },
                "emails": [
                    {
                        "email": e.email,
                        "is_clean": e.is_clean,
                        "blocked_reason": e.blocked_reason,
                        "has_metadata": e.has_metadata,
                        "metadata_source": e.metadata_source,
                        "source_url": e.source_url,
                        "page_title": e.page_title,
                        "company_name": e.company_name,
                        "phone": e.phone,
                        "country": e.country,
                        "city": e.city,
                        "address": e.address,
                        "category": e.category,
                        "domain": e.domain,
                        "keywords": e.keywords,
                        "meta_description": e.meta_description,
                        "meta_keywords": e.meta_keywords,
                        "validation_status": e.validation_status,
                        "validation_date": e.validation_date
                    } for e in enriched_emails
                ]
            }

            with open(output_json, 'w', encoding='utf-8') as f:
                json.dump(enriched_data, f, ensure_ascii=False, indent=2)

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ CSV –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞
            output_csv = self.output_dir / f"{filename_base}_{category}_enriched_{timestamp}.csv"
            with open(output_csv, 'w', encoding='utf-8') as f:
                f.write("email,is_clean,blocked_reason,has_metadata,metadata_source,source_url,page_title,company_name,phone,country,city,address,category,domain,keywords,validation_status\n")
                for e in enriched_emails:
                    f.write(f'"{e.email}",{e.is_clean},"{e.blocked_reason or ""}",{e.has_metadata},"{e.metadata_source or ""}","{e.source_url or ""}","{e.page_title or ""}","{e.company_name or ""}","{e.phone or ""}","{e.country or ""}","{e.city or ""}","{e.address or ""}","{e.category or ""}","{e.domain or ""}","{e.keywords or ""}","{e.validation_status or ""}"\n')

            # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ã—á–Ω—ã–π TXT —Ñ–∞–π–ª (—Ç–æ–ª—å–∫–æ email) –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            output_txt = self.output_dir / f"{filename_base}_{category}_{timestamp}.txt"
            with open(output_txt, 'w', encoding='utf-8') as f:
                for enriched_email in sorted(enriched_emails, key=lambda x: x.email):
                    f.write(f"{enriched_email.email}\n")

            print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(enriched_emails)} –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã—Ö email:")
            print(f"  üìÑ JSON: {output_json.name}")
            print(f"  üìä CSV: {output_csv.name}")
            print(f"  üìù TXT: {output_txt.name}")

    def print_enriched_statistics(self):
        """–í—ã–≤–æ–¥–∏—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤–∫–ª—é—á–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±–æ–≥–∞—â–µ–Ω–∏–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏"""
        total = self.stats['total_checked']
        clean = self.stats['clean']
        blocked_email = self.stats['blocked_email']
        blocked_domain = self.stats['blocked_domain']
        invalid = self.stats['invalid']
        check_time = self.stats['check_time']
        emails_with_metadata = self.stats.get('emails_with_metadata', 0)
        enrichment_rate = self.stats.get('enrichment_rate', 0)

        print(f"\n{'='*80}")
        print(f"üìä –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –° –ú–ï–¢–ê–î–ê–ù–ù–´–ú–ò")
        print(f"{'='*80}")
        print(f"üìß –í—Å–µ–≥–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ:      {total:,}")
        print(f"‚úÖ –ß–∏—Å—Ç—ã–µ email:        {clean:,} ({clean/total*100:.1f}%)")
        print(f"üö´ –ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã email:  {blocked_email:,} ({blocked_email/total*100:.1f}%)")
        print(f"üö´ –ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã –¥–æ–º–µ–Ω:  {blocked_domain:,} ({blocked_domain/total*100:.1f}%)")
        print(f"‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–µ:          {invalid:,} ({invalid/total*100:.1f}%)")
        print(f"")
        print(f"‚ú® –û–ë–û–ì–ê–©–ï–ù–ò–ï –ú–ï–¢–ê–î–ê–ù–ù–´–ú–ò:")
        print(f"üìö Email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏:  {emails_with_metadata:,} ({enrichment_rate:.1f}%)")
        print(f"üìä –ò—Å—Ç–æ—á–Ω–∏–∫ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö:  LVP —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏ output/")
        print(f"")
        print(f"‚ö° –í—Ä–µ–º—è –ø—Ä–æ–≤–µ—Ä–∫–∏:       {check_time:.2f} —Å–µ–∫")
        if check_time > 0:
            print(f"üöÄ –°–∫–æ—Ä–æ—Å—Ç—å:            {total/check_time:,.0f} email/—Å–µ–∫")

    def check_single_list(self, input_file: str):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫ email"""
        if not os.path.exists(input_file):
            print(f"‚ùå –§–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return

        emails = self.load_emails_from_file(input_file)
        if not emails:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö email –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
            return

        # –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20'
        original_count = len(emails)
        emails, removed_count = self.clean_prefix_duplicates(emails)
        if removed_count > 0:
            print(f"üßπ –û—á–∏—â–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20' (–±—ã–ª–æ {original_count}, —Å—Ç–∞–ª–æ {len(emails)})")

        results = self.check_email_against_blocklists(emails)

        filename_base = Path(input_file).stem
        self.save_results(filename_base, results)
        self._save_result_for_report(filename_base, results, duplicates_removed=0, prefix_duplicates_removed=removed_count)

    def check_single_list_with_metadata(self, input_file: str):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ (LVP, JSON, CSV, TXT)"""
        if not os.path.exists(input_file):
            print(f"‚ùå –§–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return

        filename_base = Path(input_file).stem
        print(f"\nüìß –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏: {filename_base}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        emails_with_metadata = self.load_emails_with_metadata(input_file)

        if not emails_with_metadata:
            print(f"‚ùå –§–∞–π–ª {input_file} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö email")
            return

        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤
        results = self.check_emails_with_metadata(emails_with_metadata)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        self.save_results_with_metadata(filename_base, results)

        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.print_statistics()

        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å—Ç–∞—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        old_format_results = {
            'clean': [obj.email for obj in results['clean']],
            'blocked_email': [obj.email for obj in results['blocked_email']],
            'blocked_domain': [obj.email for obj in results['blocked_domain']],
            'invalid': [obj.email for obj in results['invalid']]
        }
        self._save_result_for_report(filename_base, old_format_results, duplicates_removed=0, prefix_duplicates_removed=0)

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        filename = Path(input_file).name
        self._update_list_processed_status(filename, processed=True)

        self.print_statistics()

    def check_single_list_enriched(self, input_file: str):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫ email —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–±–æ–≥–∞—â–µ–Ω–∏–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–∑ LVP —Ñ–∞–π–ª–æ–≤"""
        if not os.path.exists(input_file):
            print(f"‚ùå –§–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return

        filename_base = Path(input_file).stem
        print(f"\nüìß –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –°–ü–ò–°–ö–ê: {filename_base}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º email –∏–∑ —Ñ–∞–π–ª–∞
        emails = self.load_emails_from_file(input_file)
        if not emails:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö email –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
            return

        # –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20'
        original_count = len(emails)
        emails, removed_count = self.clean_prefix_duplicates(emails)
        if removed_count > 0:
            print(f"üßπ –û—á–∏—â–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20' (–±—ã–ª–æ {original_count}, —Å—Ç–∞–ª–æ {len(emails)})")

        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —Å –æ–±–æ–≥–∞—â–µ–Ω–∏–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        enriched_results = self.check_emails_with_enrichment(list(emails), filename_base)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.save_enriched_results(filename_base, enriched_results)

        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.print_enriched_statistics()

        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å—Ç–∞—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        old_format_results = {
            'clean': [obj.email for obj in enriched_results['clean']],
            'blocked_email': [obj.email for obj in enriched_results['blocked_email']],
            'blocked_domain': [obj.email for obj in enriched_results['blocked_domain']],
            'invalid': [obj.email for obj in enriched_results['invalid']]
        }
        self._save_result_for_report(filename_base, old_format_results,
                                   duplicates_removed=0, prefix_duplicates_removed=removed_count)

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        filename = Path(input_file).name
        self._update_list_processed_status(filename, processed=True)

    def check_lvp_file(self, input_file: str):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç LVP —Ñ–∞–π–ª –Ω–∞–ø—Ä—è–º—É—é —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏

        Args:
            input_file: –ü—É—Ç—å –∫ LVP —Ñ–∞–π–ª—É
        """
        if not os.path.exists(input_file):
            print(f"‚ùå –§–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return

        filename_base = Path(input_file).stem
        print(f"\nüìß –ü–†–û–í–ï–†–ö–ê LVP –§–ê–ô–õ–ê: {filename_base}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–∑ LVP —Ñ–∞–π–ª–∞
        emails_with_metadata = self.load_emails_with_metadata(input_file)

        if not emails_with_metadata:
            print(f"‚ùå –§–∞–π–ª {input_file} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö email")
            return

        print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(emails_with_metadata)} email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–∑ LVP —Ñ–∞–π–ª–∞")

        # –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20'
        # –°–æ–∑–¥–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–æ email –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        email_set = set(obj.email for obj in emails_with_metadata)
        original_count = len(email_set)
        cleaned_emails, removed_count = self.clean_prefix_duplicates(email_set)

        if removed_count > 0:
            print(f"üßπ –û—á–∏—â–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20' (–±—ã–ª–æ {original_count}, —Å—Ç–∞–ª–æ {len(cleaned_emails)})")
            # –§–∏–ª—å—Ç—Ä—É–µ–º –æ–±—ä–µ–∫—Ç—ã, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ –≤ cleaned_emails
            emails_with_metadata = [obj for obj in emails_with_metadata if obj.email in cleaned_emails]

        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤
        results = self.check_emails_with_metadata(emails_with_metadata)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        self.save_results_with_metadata(filename_base, results)

        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.print_statistics()

        # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å—Ç–∞—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        old_format_results = {
            'clean': [obj.email for obj in results['clean']],
            'blocked_email': [obj.email for obj in results['blocked_email']],
            'blocked_domain': [obj.email for obj in results['blocked_domain']],
            'invalid': [obj.email for obj in results['invalid']]
        }
        self._save_result_for_report(filename_base, old_format_results,
                                   duplicates_removed=0, prefix_duplicates_removed=removed_count)

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        filename = Path(input_file).name
        self._update_list_processed_status(filename, processed=True)

    def check_multiple_lvp_files(self, input_files: List[str], exclude_duplicates: bool = False):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ LVP —Ñ–∞–π–ª–æ–≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –∏—Å–∫–ª—é—á–∞—è –¥—É–±–ª–∏–∫–∞—Ç—ã

        Args:
            input_files: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ LVP —Ñ–∞–π–ª–∞–º
            exclude_duplicates: –ò—Å–∫–ª—é—á–∞—Ç—å –ª–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏
        """
        all_lists = []

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
        for input_file in input_files:
            if not os.path.exists(input_file):
                print(f"‚ùå –§–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue

            emails_with_metadata = self.load_emails_with_metadata(input_file)
            all_lists.append(emails_with_metadata)

        if not all_lists:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —Å–ø–∏—Å–∫–∞
        processed_emails = set()  # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö email

        for i, (input_file, emails_with_metadata) in enumerate(zip(input_files, all_lists)):
            print(f"\nüìã –û–±—Ä–∞–±–æ—Ç–∫–∞ LVP —Ñ–∞–π–ª–∞ {i+1}/{len(input_files)}: {Path(input_file).name}")

            # –ò—Å–∫–ª—é—á–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–ø–∏—Å–∫–∞–º–∏ –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
            removed_dupes = 0
            if exclude_duplicates and i > 0:
                original_count = len(emails_with_metadata)
                emails_with_metadata = [obj for obj in emails_with_metadata if obj.email.lower() not in processed_emails]
                removed_dupes = original_count - len(emails_with_metadata)

                if removed_dupes > 0:
                    print(f"   üóëÔ∏è  –ò—Å–∫–ª—é—á–µ–Ω–æ {removed_dupes} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–ø–∏—Å–∫–∞–º–∏")

            if not emails_with_metadata:
                print("   ‚ö†Ô∏è  –ü–æ—Å–ª–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç")
                continue

            # –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20' –≤–Ω—É—Ç—Ä–∏ —Å–ø–∏—Å–∫–∞
            email_set = set(obj.email for obj in emails_with_metadata)
            original_count = len(email_set)
            cleaned_emails, removed_count = self.clean_prefix_duplicates(email_set)

            if removed_count > 0:
                print(f"   üßπ –û—á–∏—â–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20' (–±—ã–ª–æ {original_count}, —Å—Ç–∞–ª–æ {len(cleaned_emails)})")
                emails_with_metadata = [obj for obj in emails_with_metadata if obj.email in cleaned_emails]

            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ email –≤ –Ω–∞–±–æ—Ä
            for obj in emails_with_metadata:
                processed_emails.add(obj.email.lower())

            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤
            results = self.check_emails_with_metadata(emails_with_metadata)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            filename_base = f"{Path(input_file).stem}_seq{i+1}"
            self.save_results_with_metadata(filename_base, results)

            # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å—Ç–∞—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            old_format_results = {
                'clean': [obj.email for obj in results['clean']],
                'blocked_email': [obj.email for obj in results['blocked_email']],
                'blocked_domain': [obj.email for obj in results['blocked_domain']],
                'invalid': [obj.email for obj in results['invalid']]
            }
            self._save_result_for_report(filename_base, old_format_results,
                                       duplicates_removed=removed_dupes, prefix_duplicates_removed=removed_count)

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            filename = Path(input_file).name
            self._update_list_processed_status(filename, processed=True)

            self.print_statistics()

    def _load_already_processed_emails(self) -> Set[str]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ email –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏

        –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–ê–Ø –í–ï–†–°–ò–Ø: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ö–µ—à–∏ –≤–º–µ—Å—Ç–æ –ø–æ–ª–Ω—ã—Ö email
        –≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏: 95%, —Å–∫–æ—Ä–æ—Å—Ç—å: 10x

        Returns:
            –ú–Ω–æ–∂–µ—Å—Ç–≤–æ —Ö–µ—à–µ–π/email –∏–∑ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤
        """
        import sqlite3

        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1: –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–µ—à (—Ö–µ—à–∏) ‚≠ê –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø
        optimized_cache = self.cache_dir / "processing_cache_optimized.db"
        if optimized_cache.exists():
            try:
                conn = sqlite3.connect(optimized_cache)
                cursor = conn.cursor()

                # –ü–æ–ª—É—á–∞–µ–º —Ö–µ—à–∏ –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
                cursor.execute('SELECT hash FROM email_hashes')
                processed_hashes = {row[0].hex() for row in cursor.fetchall()}

                conn.close()

                print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(processed_hashes):,} —Ö–µ—à–µ–π –∏–∑ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–µ—à–∞")
                print(f"   üíæ –≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏: 95% | –ë–∞–∑–∞: {optimized_cache.name}")
                return processed_hashes

            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–µ—à–∞: {e}")

        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: SQLite –∫–µ—à —Å –ø–æ–ª–Ω—ã–º–∏ email
        sqlite_cache_paths = [
            self.cache_dir / "processing_cache_final.db",
            self.cache_dir / "processing_cache.db"
        ]

        for sqlite_cache_path in sqlite_cache_paths:
            if sqlite_cache_path.exists():
                try:
                    conn = sqlite3.connect(sqlite_cache_path)
                    cursor = conn.cursor()

                    cursor.execute('SELECT DISTINCT email_normalized FROM processed_emails')
                    processed_emails = {row[0] for row in cursor.fetchall()}

                    conn.close()

                    print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(processed_emails):,} email –∏–∑ SQLite –∫–µ—à–∞")
                    print(f"   –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {sqlite_cache_path.name}")
                    print(f"   üí° –°–æ–≤–µ—Ç: –ó–∞–ø—É—Å—Ç–∏—Ç–µ migrate_to_optimized_cache.py –¥–ª—è 95% —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏")
                    return processed_emails

                except Exception as e:
                    print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑ {sqlite_cache_path.name}: {e}")
                    continue

        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3: JSON –∫–µ—à (legacy)
        processed_emails = set()
        cache_data = self._load_processed_files_cache()

        for filename, file_info in cache_data.items():
            if 'result_data' in file_info:
                result_data = file_info['result_data']
                results = result_data.get('results', {})
                for category in ['clean', 'blocked_email', 'blocked_domain', 'invalid']:
                    if category in results:
                        processed_emails.update(results[category])

        print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(processed_emails):,} email –∏–∑ JSON –∫–µ—à–∞ (legacy)")
        print("   üí° –°–æ–≤–µ—Ç: –ó–∞–ø—É—Å—Ç–∏—Ç–µ migrate_to_optimized_cache.py –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è")
        return processed_emails

    def check_lvp_batch(self, exclude_duplicates: bool = False, generate_html: bool = False):
        """
        Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö LVP —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ input/

        Args:
            exclude_duplicates: –ò—Å–∫–ª—é—á–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏
            generate_html: –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å HTML –æ—Ç—á–µ—Ç
        """
        # –ò—â–µ–º –≤—Å–µ LVP —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ input
        input_files = list(self.input_dir.glob("*.lvp"))
        if not input_files:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ LVP —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ input/")
            return

        print(f"\nüìã –ù–∞–π–¥–µ–Ω–æ {len(input_files)} LVP —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        unprocessed_files = []
        for input_file in input_files:
            filename = input_file.name
            list_metadata = self._get_list_metadata(filename)
            if not list_metadata.get("processed", False):
                unprocessed_files.append(str(input_file))

        if not unprocessed_files:
            print("üéâ –í—Å–µ LVP —Ñ–∞–π–ª—ã —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
            if generate_html:
                self.generate_html_report("lvp_batch_report")
            return

        print(f"üìã –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(unprocessed_files)} –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö LVP —Ñ–∞–π–ª–æ–≤ –∏–∑ {len(input_files)}")

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª—ã
        self.check_multiple_lvp_files(unprocessed_files, exclude_duplicates=exclude_duplicates)

        if generate_html:
            self.generate_html_report("lvp_batch_report")

        print(f"\nüéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

    def check_multiple_lists(self, input_files: List[str], exclude_duplicates: bool = False):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ø–∏—Å–∫–æ–≤, –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –∏—Å–∫–ª—é—á–∞—è –¥—É–±–ª–∏–∫–∞—Ç—ã"""
        all_lists = []

        for input_file in input_files:
            if not os.path.exists(input_file):
                print(f"‚ùå –§–∞–π–ª {input_file} –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue

            emails = self.load_emails_from_file(input_file)
            all_lists.append(emails)

        if not all_lists:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return

        # –ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        if exclude_duplicates and len(all_lists) > 1:
            duplicates = self.find_duplicates(all_lists)
            print(f"\nüîç –ù–∞–π–¥–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –º–µ–∂–¥—É —Å–ø–∏—Å–∫–∞–º–∏:")
            for list_name, dupes in duplicates.items():
                print(f"   {list_name}: {len(dupes)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —Å–ø–∏—Å–∫–∞
        for i, (input_file, emails) in enumerate(zip(input_files, all_lists)):
            print(f"\nüìã –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–∏—Å–∫–∞ {i+1}: {input_file}")

            # –ò—Å–∫–ª—é—á–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–ø–∏—Å–∫–∞–º–∏ –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
            removed_dupes = 0  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—á–µ—Ç—á–∏–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –º–µ–∂–¥—É —Å–ø–∏—Å–∫–∞–º–∏
            if exclude_duplicates and i > 0:
                prev_emails = set()
                for j in range(i):
                    prev_emails.update(all_lists[j])

                original_count = len(emails)
                emails = emails - prev_emails
                removed_dupes = original_count - len(emails)

                if removed_dupes > 0:
                    print(f"   üóëÔ∏è  –ò—Å–∫–ª—é—á–µ–Ω–æ {removed_dupes} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–ø–∏—Å–∫–∞–º–∏")

            if not emails:
                print("   ‚ö†Ô∏è  –ü–æ—Å–ª–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç")
                continue

            # –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20' –≤–Ω—É—Ç—Ä–∏ —Å–ø–∏—Å–∫–∞
            original_count = len(emails)
            emails, removed_count = self.clean_prefix_duplicates(emails)
            if removed_count > 0:
                print(f"   üßπ –û—á–∏—â–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20' (–±—ã–ª–æ {original_count}, —Å—Ç–∞–ª–æ {len(emails)})")

            results = self.check_email_against_blocklists(emails)
            filename_base = f"{Path(input_file).stem}_seq{i+1}"
            self.save_results(filename_base, results)
            self._save_result_for_report(filename_base, results, duplicates_removed=removed_dupes, prefix_duplicates_removed=removed_count)
            self.print_statistics()

    def check_all_incremental(self, exclude_duplicates: bool = False, generate_html: bool = False):
        """
        Unified incremental –æ–±—Ä–∞–±–æ—Ç–∫–∞ –í–°–ï–• —Ñ–∞–π–ª–æ–≤ (TXT + LVP) –≤ –ø–∞–ø–∫–µ input/ —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º

        Args:
            exclude_duplicates: –ò—Å–∫–ª—é—á–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –º–µ–∂–¥—É —Å–ø–∏—Å–∫–∞–º–∏
            generate_html: –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å HTML –æ—Ç—á–µ—Ç
        """
        # –ò—â–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã (TXT –∏ LVP)
        txt_files = list(self.input_dir.glob("*.txt"))
        lvp_files = list(self.input_dir.glob("*.lvp"))
        all_input_files = txt_files + lvp_files

        if not all_input_files:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –ø–∞–ø–∫–µ input/")
            return

        print(f"\nüìã –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(txt_files)} TXT + {len(lvp_files)} LVP = {len(all_input_files)} –≤—Å–µ–≥–æ")

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        unprocessed_txt = []
        unprocessed_lvp = []

        for input_file in all_input_files:
            filename = input_file.name
            list_metadata = self._get_list_metadata(filename)
            if not list_metadata.get("processed", False):
                if filename.endswith('.lvp'):
                    unprocessed_lvp.append(str(input_file))
                else:
                    unprocessed_txt.append(str(input_file))

        total_unprocessed = len(unprocessed_txt) + len(unprocessed_lvp)

        if total_unprocessed == 0:
            print("üéâ –í—Å–µ —Ñ–∞–π–ª—ã —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã —Å–æ–≥–ª–∞—Å–Ω–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏!")
            if generate_html:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –∫–µ—à–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞
                cache_data = self._load_processed_files_cache()
                for filename, cached_result in cache_data.items():
                    if 'result_data' in cached_result:
                        self.all_results.append(cached_result['result_data'])
                self.generate_html_report("all_incremental_report")
            return

        print(f"üìã –ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö: {len(unprocessed_txt)} TXT + {len(unprocessed_lvp)} LVP = {total_unprocessed} —Ñ–∞–π–ª–æ–≤")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ email –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è)
        already_processed_emails = set()
        if exclude_duplicates:
            already_processed_emails = self._load_already_processed_emails()

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º TXT —Ñ–∞–π–ª—ã
        processed_emails_from_txt = set()
        if unprocessed_txt:
            print(f"\n{'='*60}")
            print(f"üìù –û–ë–†–ê–ë–û–¢–ö–ê TXT –§–ê–ô–õ–û–í ({len(unprocessed_txt)})")
            print(f"{'='*60}")

            for i, txt_file in enumerate(unprocessed_txt, 1):
                print(f"\n[{i}/{len(unprocessed_txt)}] –û–±—Ä–∞–±–æ—Ç–∫–∞ TXT: {Path(txt_file).name}")

                emails = self.load_emails_from_file(txt_file)
                original_count = len(emails)

                # –ò—Å–∫–ª—é—á–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Å —Ä–∞–Ω–µ–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏
                if exclude_duplicates:
                    emails_before_dedup = len(emails)
                    emails = emails - already_processed_emails - processed_emails_from_txt
                    removed = emails_before_dedup - len(emails)
                    if removed > 0:
                        print(f"   üóëÔ∏è  –ò—Å–∫–ª—é—á–µ–Ω–æ {removed} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å —Ä–∞–Ω–µ–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ —Å–ø–∏—Å–∫–∞–º–∏")

                if not emails:
                    print("   ‚ö†Ô∏è  –ü–æ—Å–ª–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç")
                    self._update_list_processed_status(Path(txt_file).name, processed=True)
                    continue

                # –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20'
                emails, removed_count = self.clean_prefix_duplicates(emails)
                if removed_count > 0:
                    print(f"   üßπ –û—á–∏—â–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20'")

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
                results = self.check_email_against_blocklists(emails)
                filename_base = f"{Path(txt_file).stem}_incremental"
                self.save_results(filename_base, results)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ—Ç—á–µ—Ç–∞
                cache_data = self._load_processed_files_cache()
                self._save_result_for_report(filename_base, results, txt_file, cache_data,
                                            duplicates_removed=original_count - len(emails),
                                            prefix_duplicates_removed=removed_count)
                self._save_processed_files_cache(cache_data)

                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –Ω–∞–±–æ—Ä –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö
                processed_emails_from_txt.update(emails)

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
                self._update_list_processed_status(Path(txt_file).name, processed=True)
                self.print_statistics()

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º LVP —Ñ–∞–π–ª—ã
        if unprocessed_lvp:
            print(f"\n{'='*60}")
            print(f"üìÑ –û–ë–†–ê–ë–û–¢–ö–ê LVP –§–ê–ô–õ–û–í ({len(unprocessed_lvp)})")
            print(f"{'='*60}")

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ä–∞–Ω–µ–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ email (–∏–∑ –∫–µ—à–∞ + –∏–∑ —Ç–æ–ª—å–∫–æ —á—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö TXT)
            all_processed_emails = already_processed_emails | processed_emails_from_txt

            for i, lvp_file in enumerate(unprocessed_lvp, 1):
                print(f"\n[{i}/{len(unprocessed_lvp)}] –û–±—Ä–∞–±–æ—Ç–∫–∞ LVP: {Path(lvp_file).name}")

                emails_with_metadata = self.load_emails_with_metadata(lvp_file)
                if not emails_with_metadata:
                    print(f"   ‚ö†Ô∏è  –§–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö email")
                    continue

                original_count = len(emails_with_metadata)

                # –ò—Å–∫–ª—é—á–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Å —Ä–∞–Ω–µ–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏
                if exclude_duplicates and all_processed_emails:
                    emails_before_dedup = len(emails_with_metadata)
                    emails_with_metadata = [obj for obj in emails_with_metadata
                                          if obj.email.lower() not in all_processed_emails]
                    removed = emails_before_dedup - len(emails_with_metadata)
                    if removed > 0:
                        print(f"   üóëÔ∏è  –ò—Å–∫–ª—é—á–µ–Ω–æ {removed} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å —Ä–∞–Ω–µ–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ —Å–ø–∏—Å–∫–∞–º–∏")

                if not emails_with_metadata:
                    print("   ‚ö†Ô∏è  –ü–æ—Å–ª–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç")
                    self._update_list_processed_status(Path(lvp_file).name, processed=True)
                    continue

                # –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20'
                email_set = set(obj.email for obj in emails_with_metadata)
                cleaned_emails, removed_count = self.clean_prefix_duplicates(email_set)
                if removed_count > 0:
                    print(f"   üßπ –û—á–∏—â–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20'")
                    emails_with_metadata = [obj for obj in emails_with_metadata if obj.email in cleaned_emails]

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
                results = self.check_emails_with_metadata(emails_with_metadata)
                filename_base = f"{Path(lvp_file).stem}_incremental"
                self.save_results_with_metadata(filename_base, results)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ—Ç—á–µ—Ç–∞ (–≤ —Å—Ç–∞—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
                old_format_results = {
                    'clean': [obj.email for obj in results['clean']],
                    'blocked_email': [obj.email for obj in results['blocked_email']],
                    'blocked_domain': [obj.email for obj in results['blocked_domain']],
                    'invalid': [obj.email for obj in results['invalid']]
                }
                cache_data = self._load_processed_files_cache()
                self._save_result_for_report(filename_base, old_format_results, lvp_file, cache_data,
                                            duplicates_removed=original_count - len(emails_with_metadata),
                                            prefix_duplicates_removed=removed_count)
                self._save_processed_files_cache(cache_data)

                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –Ω–∞–±–æ—Ä –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö
                for obj in emails_with_metadata:
                    all_processed_emails.add(obj.email.lower())

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
                self._update_list_processed_status(Path(lvp_file).name, processed=True)
                self.print_statistics()

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –µ–¥–∏–Ω—ã–π –æ—Ç—á–µ—Ç
        if generate_html:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –í–°–ï —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –∫–µ—à–∞ (–≤–∫–ª—é—á–∞—è —Ä–∞–Ω–µ–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã)
            cache_data = self._load_processed_files_cache()
            # –û—á–∏—â–∞–µ–º all_results –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –∫–µ—à–∞ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
            self.all_results.clear()
            for filename, cached_result in cache_data.items():
                if 'result_data' in cached_result:
                    self.all_results.append(cached_result['result_data'])
            self.generate_html_report("all_incremental_report")

        print(f"\n{'='*60}")
        print(f"üéâ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
        print(f"{'='*60}")
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ TXT: {len(unprocessed_txt)}")
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ LVP: {len(unprocessed_lvp)}")
        print(f"üìä –í—Å–µ–≥–æ: {total_unprocessed} —Ñ–∞–π–ª–æ–≤")

    def check_incremental_batch(self, exclude_duplicates: bool = False, generate_html: bool = False):
        """
        –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ input/ —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        """
        input_files = list(self.input_dir.glob("*.txt"))
        if not input_files:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ txt —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ input/")
            return

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        unprocessed_files = []
        for input_file in input_files:
            filename = input_file.name
            list_metadata = self._get_list_metadata(filename)
            if not list_metadata.get("processed", False):
                unprocessed_files.append(str(input_file))

        if not unprocessed_files:
            print("üéâ –í—Å–µ —Ñ–∞–π–ª—ã —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã —Å–æ–≥–ª–∞—Å–Ω–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏!")
            if generate_html:
                self.generate_html_report("incremental_report")
            return

        print(f"\nüìã –ù–∞–π–¥–µ–Ω–æ {len(unprocessed_files)} –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ {len(input_files)}")

        file_paths = unprocessed_files

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω—É–∂–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å
        files_to_process, cache_data = self.check_incremental_update(file_paths)

        if not files_to_process:
            print("üéâ –í—Å–µ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –∫–µ—à–µ –∏ –Ω–µ –∏–∑–º–µ–Ω—è–ª–∏—Å—å!")
            # –û—Ç–º–µ—á–∞–µ–º —Ñ–∞–π–ª—ã –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
            for file_path in file_paths:
                filename = Path(file_path).name
                self._update_list_processed_status(filename, processed=True)
            if generate_html:
                self.generate_html_report("incremental_report")
            return

        print(f"\nüìã –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(files_to_process)} —Ñ–∞–π–ª–æ–≤ –∏–∑ {len(file_paths)}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ —Å–ø–∏—Å–∫–∏ (–Ω—É–∂–Ω–æ –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –º–µ–∂–¥—É —Å–ø–∏—Å–∫–∞–º–∏)
        all_lists = []
        all_file_paths = []

        for input_file in file_paths:
            emails = self.load_emails_from_file(input_file)
            all_lists.append(emails)
            all_file_paths.append(input_file)

        # –ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –º–µ–∂–¥—É –≤—Å–µ–º–∏ —Å–ø–∏—Å–∫–∞–º–∏ –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        if exclude_duplicates and len(all_lists) > 1:
            duplicates = self.find_duplicates(all_lists)
            if duplicates:
                print(f"\nüîç –ù–∞–π–¥–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –º–µ–∂–¥—É —Å–ø–∏—Å–∫–∞–º–∏:")
                for list_name, dupes in duplicates.items():
                    print(f"   {list_name}: {len(dupes)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –í–°–ï —Ñ–∞–π–ª—ã –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
        processed_lists = []  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤

        for i, input_file in enumerate(all_file_paths):
            filename = Path(input_file).name
            emails = all_lists[i]

            print(f"\nüìã –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {filename}")

            # –ò—Å–∫–ª—é—á–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–ø–∏—Å–∫–∞–º–∏ –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è
            original_count = len(emails)
            removed_dupes = 0  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—á–µ—Ç—á–∏–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –º–µ–∂–¥—É —Å–ø–∏—Å–∫–∞–º–∏
            if exclude_duplicates and i > 0:
                prev_emails = set()
                for processed_list in processed_lists:
                    prev_emails.update(processed_list)

                emails = emails - prev_emails
                removed_dupes = original_count - len(emails)

                if removed_dupes > 0:
                    print(f"   üóëÔ∏è  –ò—Å–∫–ª—é—á–µ–Ω–æ {removed_dupes} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–ø–∏—Å–∫–∞–º–∏")

            if not emails:
                print("   ‚ö†Ô∏è  –ü–æ—Å–ª–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç")
                processed_lists.append(set())  # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç–æ–π –Ω–∞–±–æ—Ä
                continue

            # –û—á–∏—Å—Ç–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20' –≤–Ω—É—Ç—Ä–∏ —Å–ø–∏—Å–∫–∞
            emails, removed_count = self.clean_prefix_duplicates(emails)
            if removed_count > 0:
                print(f"   üßπ –û—á–∏—â–µ–Ω–æ {removed_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º '20' (–±—ã–ª–æ {original_count}, —Å—Ç–∞–ª–æ {len(emails)})")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ —Å–ª–µ–¥—É—é—â–∏—Ö
            processed_lists.append(emails.copy())

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–æ–≤—ã—Ö/–∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            if input_file in files_to_process:
                print(f"   üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –Ω–æ–≤–æ–≥–æ/–∏–∑–º–µ–Ω–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞")
                results = self.check_email_against_blocklists(emails)
                filename_base = f"{Path(input_file).stem}_incremental"
                self.save_results(filename_base, results)
                self._save_result_for_report(filename_base, results, input_file, cache_data, duplicates_removed=removed_dupes, prefix_duplicates_removed=removed_count)

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
                self._update_list_processed_status(filename, processed=True)

                self.print_statistics()
            else:
                print(f"   ‚úÖ –§–∞–π–ª –∏–∑ –∫–µ—à–∞, —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ä–∞–Ω–µ–µ")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∫–µ—à
        self._save_processed_files_cache(cache_data)
        print(f"\nüíæ –ö–µ—à –æ–±–Ω–æ–≤–ª–µ–Ω: {len(cache_data)} —Ñ–∞–π–ª–æ–≤")

        if generate_html:
            self.generate_html_report("incremental_batch_report")


def main():
    parser = argparse.ArgumentParser(
        description="Email Checker - –ø—Ä–æ–≤–µ—Ä–∫–∞ email —Å–ø–∏—Å–∫–æ–≤ –ø—Ä–æ—Ç–∏–≤ –±–ª–æ–∫-–ª–∏—Å—Ç–æ–≤"
    )

    subparsers = parser.add_subparsers(dest='command', help='–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã')

    # –ö–æ–º–∞–Ω–¥–∞ check - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫
    check_parser = subparsers.add_parser('check', help='–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –æ–¥–∏–Ω —Å–ø–∏—Å–æ–∫ email')
    check_parser.add_argument('file', help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å email')

    # –ö–æ–º–∞–Ω–¥–∞ check-metadata - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∞–π–ª —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ (LVP, JSON, CSV)
    metadata_parser = subparsers.add_parser('check-metadata', help='–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∞–π–ª —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ (LVP, JSON, CSV)')
    metadata_parser.add_argument('file', help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏')

    # –ö–æ–º–∞–Ω–¥–∞ check-enriched - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–±–æ–≥–∞—â–µ–Ω–∏–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–∑ LVP
    enriched_parser = subparsers.add_parser('check-enriched', help='–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–±–æ–≥–∞—â–µ–Ω–∏–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–∑ LVP —Ñ–∞–π–ª–æ–≤')
    enriched_parser.add_argument('file', help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å email')

    # –ö–æ–º–∞–Ω–¥–∞ check-lvp - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å LVP —Ñ–∞–π–ª –Ω–∞–ø—Ä—è–º—É—é
    lvp_parser = subparsers.add_parser('check-lvp', help='–ü—Ä–æ–≤–µ—Ä–∏—Ç—å LVP —Ñ–∞–π–ª –Ω–∞–ø—Ä—è–º—É—é —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏')
    lvp_parser.add_argument('file', help='–ü—É—Ç—å –∫ LVP —Ñ–∞–π–ª—É')

    # –ö–æ–º–∞–Ω–¥–∞ check-lvp-batch - batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ LVP —Ñ–∞–π–ª–æ–≤
    lvp_batch_parser = subparsers.add_parser('check-lvp-batch', help='Batch –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö LVP —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ input/')
    lvp_batch_parser.add_argument('--exclude-duplicates', action='store_true',
                                 help='–ò—Å–∫–ª—é—á–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏')
    lvp_batch_parser.add_argument('--generate-html', action='store_true',
                                 help='–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å HTML –æ—Ç—á–µ—Ç –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏')

    # –ö–æ–º–∞–Ω–¥–∞ check-lvp-sequence - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ LVP —Ñ–∞–π–ª–æ–≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
    lvp_seq_parser = subparsers.add_parser('check-lvp-sequence',
                                          help='–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ LVP —Ñ–∞–π–ª–æ–≤ —Å –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º –¥—É–±–ª–∏–∫–∞—Ç–æ–≤')
    lvp_seq_parser.add_argument('files', nargs='+', help='–ü—É—Ç–∏ –∫ LVP —Ñ–∞–π–ª–∞–º')
    lvp_seq_parser.add_argument('--exclude-duplicates', action='store_true',
                               help='–ò—Å–∫–ª—é—á–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–ø–∏—Å–∫–∞–º–∏')

    # –ö–æ–º–∞–Ω–¥–∞ check-sequence - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ø–∏—Å–∫–æ–≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
    seq_parser = subparsers.add_parser('check-sequence',
                                      help='–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ø–∏—Å–∫–æ–≤ —Å –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º –¥—É–±–ª–∏–∫–∞—Ç–æ–≤')
    seq_parser.add_argument('files', nargs='+', help='–ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º —Å email')
    seq_parser.add_argument('--exclude-duplicates', action='store_true',
                           help='–ò—Å–∫–ª—é—á–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —Å–ø–∏—Å–∫–∞–º–∏')

    # –ö–æ–º–∞–Ω–¥–∞ batch - –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ input
    batch_parser = subparsers.add_parser('batch', help='–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ input/')
    batch_parser.add_argument('--exclude-duplicates', action='store_true',
                             help='–ò—Å–∫–ª—é—á–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏')
    batch_parser.add_argument('--generate-html', action='store_true',
                             help='–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å HTML –æ—Ç—á–µ—Ç –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏')

    # –ö–æ–º–∞–Ω–¥–∞ incremental - –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ (TXT only - legacy)
    incremental_parser = subparsers.add_parser('incremental', help='–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ TXT —Ñ–∞–π–ª–æ–≤ (legacy, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ check-all-incremental)')
    incremental_parser.add_argument('--exclude-duplicates', action='store_true',
                                   help='–ò—Å–∫–ª—é—á–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏')
    incremental_parser.add_argument('--generate-html', action='store_true',
                                   help='–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å HTML –æ—Ç—á–µ—Ç –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏')

    # –ö–æ–º–∞–Ω–¥–∞ check-all-incremental - unified incremental –¥–ª—è TXT + LVP
    all_incremental_parser = subparsers.add_parser('check-all-incremental',
                                                   help='Unified incremental –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –í–°–ï–• —Ñ–∞–π–ª–æ–≤ (TXT + LVP) —Å –∫—Ä–æ—Å—Å-–¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π')
    all_incremental_parser.add_argument('--exclude-duplicates', action='store_true',
                                       help='–ò—Å–∫–ª—é—á–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –º–µ–∂–¥—É –≤—Å–µ–º–∏ —Å–ø–∏—Å–∫–∞–º–∏ (TXT –∏ LVP)')
    all_incremental_parser.add_argument('--generate-html', action='store_true',
                                       help='–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –µ–¥–∏–Ω—ã–π HTML –æ—Ç—á–µ—Ç –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏')

    # –ö–æ–º–∞–Ω–¥–∞ report - —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å HTML –æ—Ç—á–µ—Ç
    report_parser = subparsers.add_parser('report', help='–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å HTML –æ—Ç—á–µ—Ç –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–µ—Å—Å–∏–∏')
    report_parser.add_argument('--name', default='report', help='–ù–∞–∑–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –æ—Ç—á–µ—Ç–∞')

    # –ö–æ–º–∞–Ω–¥–∞ smart-filter - —É–º–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è clean-–ª–∏—Å—Ç–∞
    smart_filter_parser = subparsers.add_parser('smart-filter',
                                                help='–£–º–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è clean-–ª–∏—Å—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º')
    smart_filter_parser.add_argument('clean_file', help='–ü—É—Ç—å –∫ clean-—Ñ–∞–π–ª—É (TXT/CSV/JSON)')
    smart_filter_parser.add_argument('--config', default='italy_hydraulics',
                                     help='–ò–º—è –∫–æ–Ω—Ñ–∏–≥–∞ —Ñ–∏–ª—å—Ç—Ä–∞ (default: italy_hydraulics)')
    smart_filter_parser.add_argument('--no-metadata', action='store_true',
                                     help='–ù–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤ CSV/JSON')

    # –ö–æ–º–∞–Ω–¥–∞ smart-filter-batch - batch —É–º–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
    smart_filter_batch_parser = subparsers.add_parser('smart-filter-batch',
                                                       help='Batch —É–º–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤—Å–µ—Ö clean-—Ñ–∞–π–ª–æ–≤')
    smart_filter_batch_parser.add_argument('--config', default='italy_hydraulics',
                                           help='–ò–º—è –∫–æ–Ω—Ñ–∏–≥–∞ —Ñ–∏–ª—å—Ç—Ä–∞')
    smart_filter_batch_parser.add_argument('--pattern', default='output/*_clean_*.txt',
                                           help='Glob –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ clean-—Ñ–∞–π–ª–æ–≤')
    smart_filter_batch_parser.add_argument('--no-metadata', action='store_true',
                                           help='–ù–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ')

    # –ö–æ–º–∞–Ω–¥–∞ status - –ø–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –≤—Å–µ—Ö —Å–ø–∏—Å–∫–æ–≤
    status_parser = subparsers.add_parser('status', help='–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç—É—Å –≤—Å–µ—Ö —Å–ø–∏—Å–∫–æ–≤')
    status_parser.add_argument('--pattern', help='–§–∏–ª—å—Ç—Ä –ø–æ —à–∞–±–ª–æ–Ω—É –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞')
    status_parser.add_argument('--category', help='–§–∏–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏')
    status_parser.add_argument('--country', help='–§–∏–ª—å—Ç—Ä –ø–æ —Å—Ç—Ä–∞–Ω–µ')

    # –ö–æ–º–∞–Ω–¥–∞ import-csv-blocklist - –∏–º–ø–æ—Ä—Ç email –∏–∑ CSV –ª–æ–≥–æ–≤ –≤ –±–ª–æ–∫-–ª–∏—Å—Ç—ã
    import_csv_parser = subparsers.add_parser('import-csv-blocklist',
                                               help='–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å email –∏–∑ CSV –ª–æ–≥–æ–≤ –≤ –±–ª–æ–∫-–ª–∏—Å—Ç—ã')
    import_csv_parser.add_argument('files', nargs='+', help='CSV —Ñ–∞–π–ª—ã –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞')
    import_csv_parser.add_argument('--include-optional', action='store_true',
                                    help='–í–∫–ª—é—á–∏—Ç—å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å—Ç–∞—Ç—É—Å—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–û—Ç–ø–∏—Å–∞–ª—Å—è")')
    import_csv_parser.add_argument('--dry-run', action='store_true',
                                    help='–†–µ–∂–∏–º –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞ (–Ω–µ –∏–∑–º–µ–Ω—è–µ—Ç —Ñ–∞–π–ª—ã)')

    args = parser.parse_args()

    checker = EmailChecker()

    if args.command == 'check':
        checker.check_single_list(args.file)

    elif args.command == 'check-metadata':
        checker.check_single_list_with_metadata(args.file)

    elif args.command == 'check-enriched':
        checker.check_single_list_enriched(args.file)

    elif args.command == 'check-lvp':
        checker.check_lvp_file(args.file)

    elif args.command == 'check-lvp-batch':
        checker.check_lvp_batch(exclude_duplicates=args.exclude_duplicates,
                               generate_html=args.generate_html)

    elif args.command == 'check-lvp-sequence':
        checker.check_multiple_lvp_files(args.files, exclude_duplicates=args.exclude_duplicates)

    elif args.command == 'check-sequence':
        checker.check_multiple_lists(args.files, exclude_duplicates=args.exclude_duplicates)

    elif args.command == 'batch':
        input_files = list(checker.input_dir.glob("*.txt"))
        if not input_files:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ txt —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ input/")
            return

        file_paths = [str(f) for f in input_files]
        checker.check_multiple_lists(file_paths, exclude_duplicates=args.exclude_duplicates)

        if args.generate_html:
            checker.generate_html_report("batch_report")

    elif args.command == 'incremental':
        checker.check_incremental_batch(exclude_duplicates=args.exclude_duplicates,
                                       generate_html=args.generate_html)

    elif args.command == 'check-all-incremental':
        checker.check_all_incremental(exclude_duplicates=args.exclude_duplicates,
                                     generate_html=args.generate_html)

    elif args.command == 'report':
        checker.generate_html_report(args.name)

    elif args.command == 'smart-filter':
        # –£–º–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ clean-—Ñ–∞–π–ª–∞
        from smart_filter_processor_v2 import SmartFilterProcessor
        from pathlib import Path

        processor = SmartFilterProcessor(filter_name=args.config)
        result = processor.process_clean_file(
            Path(args.clean_file),
            include_metadata=not args.no_metadata
        )

        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        print(f"\n{'='*70}")
        print("üìà –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"{'='*70}")
        for key, value in result.get('statistics').items():
            print(f"   {key}: {value}")

    elif args.command == 'smart-filter-batch':
        # Batch —É–º–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è clean-—Ñ–∞–π–ª–æ–≤
        from smart_filter_processor_v2 import SmartFilterProcessor

        processor = SmartFilterProcessor(filter_name=args.config)
        results = processor.process_clean_batch(
            pattern=args.pattern
        )

        print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(results)}")

    elif args.command == 'status':
        checker.show_status(pattern=args.pattern, category=args.category, country=args.country)

    elif args.command == 'import-csv-blocklist':
        # –ò–º–ø–æ—Ä—Ç email –∏–∑ CSV –ª–æ–≥–æ–≤ –≤ –±–ª–æ–∫-–ª–∏—Å—Ç—ã
        from import_blocklist_csv import BlocklistCSVImporter
        from pathlib import Path

        importer = BlocklistCSVImporter()
        filepaths = [Path(f) for f in args.files]
        importer.import_csv_files(
            filepaths,
            include_optional=args.include_optional,
            dry_run=args.dry_run
        )

    else:
        parser.print_help()


if __name__ == "__main__":
    main()