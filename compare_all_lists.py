#!/usr/bin/env python3
"""–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–ø–∏—Å–∫–æ–≤ email –º–µ–∂–¥—É —Å–æ–±–æ–π"""

import os
import re
import xml.etree.ElementTree as ET
from collections import defaultdict
from datetime import datetime
import json

def sanitize_xml(content):
    """–£–¥–∞–ª—è–µ—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ XML-—Å–∏–º–≤–æ–ª—ã"""
    return re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F]', '', content)

def normalize_email(email):
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç email-–∞–¥—Ä–µ—Å"""
    email = email.lower().strip()
    if email.startswith('//'):
        email = email[2:]
    if email.startswith('20'):
        email = email[2:]
    return email

def parse_txt_file(filepath):
    """–ü–∞—Ä—Å–∏—Ç TXT —Ñ–∞–π–ª"""
    emails = []
    try:
        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
            for line in f:
                email = normalize_email(line.strip())
                if email and '@' in email:
                    emails.append(email)
    except Exception as e:
        print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è TXT: {e}")
    return emails

def parse_lvp_file(filepath):
    """–ü–∞—Ä—Å–∏—Ç LVP —Ñ–∞–π–ª"""
    emails = []
    try:
        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()

        content = sanitize_xml(content)
        root = ET.fromstring(content)

        namespaces = {
            '': 'http://schemas.datacontract.org/2004/07/Verifier',
            'i': 'http://www.w3.org/2001/XMLSchema-instance'
        }

        email_paths = [
            './/Email',
            './/{http://schemas.datacontract.org/2004/07/Verifier}Email',
        ]

        for path in email_paths:
            email_elements = root.findall(path, namespaces)
            if email_elements:
                for elem in email_elements:
                    if elem.text:
                        email = normalize_email(elem.text)
                        if email and '@' in email:
                            emails.append(email)
                break
    except Exception as e:
        print(f"  ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è LVP: {e}")

    return emails

def load_file_emails(filepath):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç email –∏–∑ —Ñ–∞–π–ª–∞ (TXT –∏–ª–∏ LVP)"""
    if filepath.endswith('.txt'):
        return parse_txt_file(filepath)
    elif filepath.endswith('.lvp'):
        return parse_lvp_file(filepath)
    return []

def short_name(filename):
    """–°–æ–∫—Ä–∞—â–∞–µ—Ç –¥–ª–∏–Ω–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –æ—Ç—á–µ—Ç–∞"""
    name = os.path.splitext(filename)[0]
    if len(name) > 40:
        return name[:37] + '...'
    return name

def main():
    input_dir = 'input'

    print("="*80)
    print("üìä –°–†–ê–í–ù–ï–ù–ò–ï –í–°–ï–• –°–ü–ò–°–ö–û–í EMAIL –ú–ï–ñ–î–£ –°–û–ë–û–ô")
    print("="*80)

    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
    all_files = []
    for filename in os.listdir(input_dir):
        if filename.endswith(('.txt', '.lvp')):
            filepath = os.path.join(input_dir, filename)
            all_files.append((filename, filepath))

    all_files.sort()

    print(f"\nüìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(all_files)}")
    print(f"  ‚Ä¢ TXT: {sum(1 for f, _ in all_files if f.endswith('.txt'))}")
    print(f"  ‚Ä¢ LVP: {sum(1 for f, _ in all_files if f.endswith('.lvp'))}")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º email –∏–∑ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
    print("\n1Ô∏è‚É£ –ó–∞–≥—Ä—É–∑–∫–∞ email –∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤...")

    file_emails = {}  # {filename: set(emails)}
    file_stats = {}   # {filename: {'total': X, 'unique': Y}}

    for i, (filename, filepath) in enumerate(all_files, 1):
        print(f"  [{i}/{len(all_files)}] {short_name(filename)}...", end=' ', flush=True)

        try:
            emails = load_file_emails(filepath)
            unique_emails = set(emails)

            file_emails[filename] = unique_emails
            file_stats[filename] = {
                'total': len(emails),
                'unique': len(unique_emails),
                'duplicates_internal': len(emails) - len(unique_emails)
            }

            print(f"‚úÖ {len(unique_emails):,} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            file_emails[filename] = set()
            file_stats[filename] = {'total': 0, 'unique': 0, 'duplicates_internal': 0}

    # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π
    print("\n2Ô∏è‚É£ –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏...")

    # –î–ª—è –∫–∞–∂–¥–æ–≥–æ email –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º, –≤ —Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–∞—Ö –æ–Ω –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è
    email_file_count = defaultdict(set)

    for filename, emails in file_emails.items():
        for email in emails:
            email_file_count[email].add(filename)

    # –ü–æ–¥—Å—á–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    duplicate_counts = defaultdict(int)
    for email, files in email_file_count.items():
        count = len(files)
        if count > 1:
            duplicate_counts[count] += 1

    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_emails_all = sum(stats['total'] for stats in file_stats.values())
    unique_emails_all = len(email_file_count)
    emails_in_multiple_files = sum(1 for files in email_file_count.values() if len(files) > 1)

    print("\n" + "="*80)
    print("üìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("="*80)

    print(f"\nüì¶ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(all_files)}")
    print(f"üìß –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {total_emails_all:,}")
    print(f"‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö email: {unique_emails_all:,}")
    print(f"üîÑ Email –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–∞—Ö: {emails_in_multiple_files:,} ({emails_in_multiple_files/unique_emails_all*100:.1f}%)")

    if duplicate_counts:
        print(f"\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:")
        for count in sorted(duplicate_counts.keys(), reverse=True)[:10]:
            print(f"  ‚Ä¢ –í {count} —Ñ–∞–π–ª–∞—Ö: {duplicate_counts[count]:,} email")

    # –¢–æ–ø-10 —Ñ–∞–π–ª–æ–≤ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö email
    print(f"\nüèÜ –¢–æ–ø-10 —Ñ–∞–π–ª–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö email:")
    top_files = sorted(file_stats.items(), key=lambda x: x[1]['unique'], reverse=True)[:10]
    for i, (filename, stats) in enumerate(top_files, 1):
        print(f"  {i:2d}. {short_name(filename):40s} - {stats['unique']:>7,} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    report_file = f'output/lists_comparison_report_{timestamp}.txt'

    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("–î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –°–†–ê–í–ù–ï–ù–ò–Ø –í–°–ï–• –°–ü–ò–°–ö–û–í\n")
        f.write("="*80 + "\n\n")

        f.write(f"–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {len(all_files)}\n")
        f.write(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {total_emails_all:,}\n")
        f.write(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö email: {unique_emails_all:,}\n")
        f.write(f"Email –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–∞—Ö: {emails_in_multiple_files:,}\n\n")

        f.write("="*80 + "\n")
        f.write("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –§–ê–ô–õ–ê–ú\n")
        f.write("="*80 + "\n\n")

        for filename in sorted(file_stats.keys()):
            stats = file_stats[filename]
            f.write(f"{filename}\n")
            f.write(f"  –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {stats['total']:,}\n")
            f.write(f"  –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {stats['unique']:,}\n")
            f.write(f"  –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {stats['duplicates_internal']:,}\n\n")

        f.write("="*80 + "\n")
        f.write("–†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –î–£–ë–õ–ò–ö–ê–¢–û–í\n")
        f.write("="*80 + "\n\n")

        for count in sorted(duplicate_counts.keys(), reverse=True):
            f.write(f"Email –≤ {count} —Ñ–∞–π–ª–∞—Ö: {duplicate_counts[count]:,}\n")

    print(f"\nüíæ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–∞—Ç—Ä–∏—Ü—É –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π –≤ JSON (—Ç–æ–ø-20 —Ñ–∞–π–ª–æ–≤)
    print("\n3Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π (—Ç–æ–ø-20 —Ñ–∞–π–ª–æ–≤)...")

    top20_files = [f for f, _ in sorted(file_stats.items(), key=lambda x: x[1]['unique'], reverse=True)[:20]]

    matrix = {}
    for file1 in top20_files:
        matrix[file1] = {}
        for file2 in top20_files:
            if file1 == file2:
                matrix[file1][file2] = len(file_emails[file1])
            else:
                intersection = len(file_emails[file1] & file_emails[file2])
                matrix[file1][file2] = intersection

    matrix_file = f'output/lists_intersection_matrix_{timestamp}.json'
    with open(matrix_file, 'w', encoding='utf-8') as f:
        json.dump(matrix, f, ensure_ascii=False, indent=2)

    print(f"üíæ –ú–∞—Ç—Ä–∏—Ü–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {matrix_file}")

    # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–π–ª—ã —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ–º
    print("\nüîç –§–∞–π–ª—ã —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ–º (—Ç–æ–ø-10 –ø–∞—Ä):")

    intersections = []
    for i, file1 in enumerate(top20_files):
        for file2 in top20_files[i+1:]:
            intersection_count = len(file_emails[file1] & file_emails[file2])
            if intersection_count > 0:
                percent1 = intersection_count / len(file_emails[file1]) * 100
                percent2 = intersection_count / len(file_emails[file2]) * 100
                intersections.append((file1, file2, intersection_count, percent1, percent2))

    intersections.sort(key=lambda x: x[2], reverse=True)

    for i, (file1, file2, count, p1, p2) in enumerate(intersections[:10], 1):
        print(f"  {i:2d}. {short_name(file1)}")
        print(f"      ‚Üî {short_name(file2)}")
        print(f"      {count:,} –æ–±—â–∏—Ö email ({p1:.1f}% / {p2:.1f}%)")

    print("\n" + "="*80)
    print("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print("="*80)

if __name__ == '__main__':
    main()
