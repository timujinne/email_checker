#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ê–Ω–∞–ª–∏–∑ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π email –∞–¥—Ä–µ—Å–æ–≤ –∏–∑ LVP —Ñ–∞–π–ª–∞ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö
"""

import sqlite3
import xml.etree.ElementTree as ET
import re
import sys
from collections import defaultdict
from pathlib import Path


def sanitize_xml(content):
    """–£–¥–∞–ª—è–µ—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ XML —Å–∏–º–≤–æ–ª—ã"""
    # –£–¥–∞–ª—è–µ–º —É–ø—Ä–∞–≤–ª—è—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã (–∫—Ä–æ–º–µ \n, \r, \t)
    control_chars = ''.join([chr(i) for i in range(0, 32) if i not in (9, 10, 13)])
    translator = str.maketrans('', '', control_chars)
    return content.translate(translator)


def parse_lvp_file(filepath):
    """
    –ü–∞—Ä—Å–∏—Ç LVP —Ñ–∞–π–ª –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç email –∞–¥—Ä–µ—Å–∞ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏

    Returns:
        list of dict: –°–ø–∏—Å–æ–∫ email –∞–¥—Ä–µ—Å–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
    """
    print(f"üìÇ –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞: {filepath}")

    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()

    # –û—á–∏—Å—Ç–∫–∞ XML
    content = sanitize_xml(content)

    # –ü–∞—Ä—Å–∏–Ω–≥ XML
    try:
        root = ET.fromstring(content)
    except ET.ParseError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ XML: {e}")
        return []

    emails = []

    # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π
    namespaces = {
        'ns': 'http://schemas.datacontract.org/2004/07/Verifier',
        'arr': 'http://schemas.microsoft.com/2003/10/Serialization/Arrays'
    }

    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø—É—Ç–∏ –∫ —ç–ª–µ–º–µ–Ω—Ç–∞–º
    items = (
        root.findall('.//ns:ValidatorDataClass.ValidatorDataClassItem', namespaces) or
        root.findall('.//ValidatorDataClass.ValidatorDataClassItem') or
        []
    )

    print(f"üìä –ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –≤ LVP: {len(items)}")

    for item in items:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º email
        email_elem = item.find('.//ns:Email', namespaces) or item.find('.//Email')
        if email_elem is not None and email_elem.text:
            email = email_elem.text.strip().lower()

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–∞—Ç—É—Å
            status_elem = item.find('.//ns:Status', namespaces) or item.find('.//Status')
            status = status_elem.text if status_elem is not None and status_elem.text else 'Unknown'

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ _Data
            metadata = {}
            data_elem = item.find('.//{http://schemas.microsoft.com/2003/10/Serialization/Arrays}KeyValueOfstringstring/..')
            if data_elem is not None:
                for kv in data_elem.findall('.//{http://schemas.microsoft.com/2003/10/Serialization/Arrays}KeyValueOfstringstring'):
                    key_elem = kv.find('{http://schemas.microsoft.com/2003/10/Serialization/Arrays}Key')
                    value_elem = kv.find('{http://schemas.microsoft.com/2003/10/Serialization/Arrays}Value')
                    if key_elem is not None and value_elem is not None:
                        metadata[key_elem.text] = value_elem.text or ''

            emails.append({
                'email': email,
                'status': status,
                'metadata': metadata
            })

    return emails


def normalize_email(email):
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç email –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
    email = email.lower().strip()

    # –£–¥–∞–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å—ã '//' –∏ '20'
    if email.startswith('//'):
        email = email[2:]
    if email.startswith('20') and '@' in email:
        email = email[2:]

    return email


def check_duplicates_in_db(emails, db_path='.cache/processing_cache_final.db'):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–∞–∫–∏–µ email –∞–¥—Ä–µ—Å–∞ —É–∂–µ –µ—Å—Ç—å –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö

    Args:
        emails: list of dict - –°–ø–∏—Å–æ–∫ email —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        db_path: str - –ü—É—Ç—å –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∫—ç—à-–±–∞–∑–∞)

    Returns:
        tuple: (found_in_db, not_in_db, db_stats)
    """
    print(f"\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö...")
    print(f"üìÅ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ë–î: {db_path}")

    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    found_in_db = []
    not_in_db = []

    # –ü–æ–ª—É—á–∞–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ –ë–î
    cursor.execute('SELECT COUNT(*) FROM processed_emails')
    total_in_db = cursor.fetchone()[0]
    print(f"üìö –í—Å–µ–≥–æ email –∞–¥—Ä–µ—Å–æ–≤ –≤ –ë–î: {total_in_db:,}")

    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
    cursor.execute('''
        SELECT source_file, category, COUNT(*) as count
        FROM processed_emails
        GROUP BY source_file, category
        ORDER BY count DESC
    ''')
    source_stats = cursor.fetchall()

    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
    cursor.execute('''
        SELECT category, COUNT(*) as count
        FROM processed_emails
        GROUP BY category
    ''')
    category_stats = {row[0]: row[1] for row in cursor.fetchall()}

    print(f"\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –≤ –ë–î:")
    for category, count in category_stats.items():
        print(f"  ‚Ä¢ {category}: {count:,} ({count/total_in_db*100:.1f}%)")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π email –∏–∑ LVP —Ñ–∞–π–ª–∞
    for item in emails:
        email = normalize_email(item['email'])

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤ –ë–î (–∏—â–µ–º –≤ –æ–±–æ–∏—Ö –ø–æ–ª—è—Ö)
        cursor.execute('''
            SELECT
                email,
                email_normalized,
                source_file,
                category,
                processed_at
            FROM processed_emails
            WHERE email_normalized = ? OR email = ?
            LIMIT 1
        ''', (email, email))

        result = cursor.fetchone()

        if result:
            found_in_db.append({
                'email': email,
                'lvp_status': item['status'],
                'db_email': result[0],
                'db_email_normalized': result[1],
                'db_source_file': result[2],
                'db_category': result[3],
                'db_processed_at': result[4],
                'lvp_metadata': item['metadata']
            })
        else:
            not_in_db.append({
                'email': email,
                'lvp_status': item['status'],
                'lvp_metadata': item['metadata']
            })

    conn.close()

    db_stats = {
        'total_in_db': total_in_db,
        'source_stats': source_stats,
        'category_stats': category_stats
    }

    return found_in_db, not_in_db, db_stats


def print_statistics(lvp_emails, found_in_db, not_in_db, db_stats):
    """–í—ã–≤–æ–¥–∏—Ç –ø–æ–¥—Ä–æ–±–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""

    print("\n" + "="*80)
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ê–ù–ê–õ–ò–ó–ê")
    print("="*80)

    print(f"\nüìÅ LVP —Ñ–∞–π–ª:")
    print(f"  ‚Ä¢ –í—Å–µ–≥–æ email –∞–¥—Ä–µ—Å–æ–≤: {len(lvp_emails):,}")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º –≤ LVP
    status_counts = defaultdict(int)
    for item in lvp_emails:
        status_counts[item['status']] += 1

    print(f"\n  –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º –≤ LVP:")
    for status, count in sorted(status_counts.items(), key=lambda x: x[1], reverse=True):
        print(f"    - {status}: {count:,} ({count/len(lvp_emails)*100:.1f}%)")

    print(f"\nüíæ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö:")
    print(f"  ‚Ä¢ –í—Å–µ–≥–æ email –∞–¥—Ä–µ—Å–æ–≤: {db_stats['total_in_db']:,}")

    print(f"\nüîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏:")
    print(f"  ‚úÖ –ù–∞–π–¥–µ–Ω–æ –≤ –ë–î: {len(found_in_db):,} ({len(found_in_db)/len(lvp_emails)*100:.1f}%)")
    print(f"  ‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –ë–î (–Ω–æ–≤—ã–µ): {len(not_in_db):,} ({len(not_in_db)/len(lvp_emails)*100:.1f}%)")

    # –ê–Ω–∞–ª–∏–∑ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
    if found_in_db:
        source_counts = defaultdict(int)
        category_counts = defaultdict(int)

        for item in found_in_db:
            source = item.get('db_source_file', 'Unknown')
            category = item.get('db_category', 'Unknown')
            source_counts[source] += 1
            category_counts[category] += 1

        print(f"\n  –ò—Å—Ç–æ—á–Ω–∏–∫–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤ –ë–î (—Ç–æ–ø 10):")
        for source, count in sorted(source_counts.items(), key=lambda x: x[1], reverse=True)[:10]:
            print(f"    - {source}: {count:,} ({count/len(found_in_db)*100:.1f}%)")

        print(f"\n  –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
        for category, count in sorted(category_counts.items(), key=lambda x: x[1], reverse=True):
            print(f"    - {category}: {count:,} ({count/len(found_in_db)*100:.1f}%)")

    print("\n" + "="*80)


def save_results(found_in_db, not_in_db, output_dir='output'):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª—ã"""

    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã
    if found_in_db:
        duplicates_file = output_path / 'lvp_duplicates_found.txt'
        with open(duplicates_file, 'w', encoding='utf-8') as f:
            f.write("# Email –∞–¥—Ä–µ—Å–∞ –∏–∑ LVP —Ñ–∞–π–ª–∞, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –µ—Å—Ç—å –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö\n")
            f.write(f"# –í—Å–µ–≥–æ: {len(found_in_db):,}\n\n")
            for item in found_in_db:
                f.write(f"{item['email']}\n")
        print(f"\n‚úÖ –î—É–±–ª–∏–∫–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {duplicates_file} ({len(found_in_db):,} emails)")

        # –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        report_file = output_path / 'lvp_duplicates_report.txt'
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("–î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –û –î–£–ë–õ–ò–ö–ê–¢–ê–•\n")
            f.write("="*80 + "\n")
            f.write(f"–í—Å–µ–≥–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(found_in_db):,}\n")
            f.write("="*80 + "\n\n")
            for item in found_in_db:
                f.write(f"Email: {item['email']}\n")
                f.write(f"  LVP —Å—Ç–∞—Ç—É—Å: {item['lvp_status']}\n")
                f.write(f"  –ë–î –∫–∞—Ç–µ–≥–æ—Ä–∏—è: {item.get('db_category', 'N/A')}\n")
                if item.get('db_source_file'):
                    f.write(f"  –ò—Å—Ç–æ—á–Ω–∏–∫ –≤ –ë–î: {item['db_source_file']}\n")
                if item.get('db_processed_at'):
                    f.write(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω: {item['db_processed_at']}\n")
                f.write("\n")
        print(f"‚úÖ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç: {report_file}")

        # CSV –æ—Ç—á–µ—Ç –¥–ª—è Excel
        csv_file = output_path / 'lvp_duplicates_report.csv'
        with open(csv_file, 'w', encoding='utf-8-sig') as f:
            f.write("Email;LVP_Status;DB_Category;DB_Source_File;DB_Processed_At\n")
            for item in found_in_db:
                f.write(f"{item['email']};{item['lvp_status']};")
                f.write(f"{item.get('db_category', '')};")
                f.write(f"{item.get('db_source_file', '')};")
                f.write(f"{item.get('db_processed_at', '')}\n")
        print(f"‚úÖ CSV –æ—Ç—á–µ—Ç: {csv_file}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ email
    if not_in_db:
        unique_file = output_path / 'lvp_unique_emails.txt'
        with open(unique_file, 'w', encoding='utf-8') as f:
            f.write("# Email –∞–¥—Ä–µ—Å–∞ –∏–∑ LVP —Ñ–∞–π–ª–∞, –∫–æ—Ç–æ—Ä—ã—Ö –ù–ï–¢ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö (–ù–û–í–´–ï)\n")
            f.write(f"# –í—Å–µ–≥–æ: {len(not_in_db):,}\n\n")
            for item in not_in_db:
                f.write(f"{item['email']}\n")
        print(f"‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ emails: {unique_file} ({len(not_in_db):,} emails)")

        # CSV —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –Ω–æ–≤—ã—Ö email
        csv_file = output_path / 'lvp_unique_emails_with_metadata.csv'
        with open(csv_file, 'w', encoding='utf-8-sig') as f:
            f.write("Email;LVP_Status;Column_2;Column_3;Column_7\n")
            for item in not_in_db:
                metadata = item.get('lvp_metadata', {})
                f.write(f"{item['email']};{item['lvp_status']};")
                f.write(f"{metadata.get('Column_2', '')};")
                f.write(f"{metadata.get('Column_3', '')};")
                f.write(f"{metadata.get('Column_7', '')}\n")
        print(f"‚úÖ CSV —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –Ω–æ–≤—ã—Ö emails: {csv_file}")


def main():
    if len(sys.argv) < 2:
        print("Usage: python analyze_lvp_duplicates.py <lvp_file_path>")
        print("\n–ü—Ä–∏–º–µ—Ä:")
        print('  python analyze_lvp_duplicates.py "input/En HC –æ—Ç –ì–ª–µ–±–∞.lvp"')
        sys.exit(1)

    lvp_file = sys.argv[1]

    if not Path(lvp_file).exists():
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {lvp_file}")
        sys.exit(1)

    print("üöÄ –ê–Ω–∞–ª–∏–∑ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π LVP —Ñ–∞–π–ª–∞ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö")
    print("="*80)

    # –ü–∞—Ä—Å–∏–º LVP —Ñ–∞–π–ª
    lvp_emails = parse_lvp_file(lvp_file)

    if not lvp_emails:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å email –∞–¥—Ä–µ—Å–∞ –∏–∑ LVP —Ñ–∞–π–ª–∞")
        sys.exit(1)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    found_in_db, not_in_db, sources = check_duplicates_in_db(lvp_emails)

    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print_statistics(lvp_emails, found_in_db, not_in_db, sources)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    save_results(found_in_db, not_in_db)

    print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")


if __name__ == '__main__':
    main()
